{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c90e8670-dcce-43df-b2d0-559cdc89637e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57345972-bfd6-4357-be53-dfb84a1b2a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumes saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Resume-files\\Resumes-Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import win32com.client as win32\n",
    "\n",
    "# Function to extract text from .docx file\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "# Function to extract text from .doc file using win32com\n",
    "def extract_text_from_doc(doc_path):\n",
    "    word = win32.Dispatch(\"Word.Application\")\n",
    "    word.Visible = False\n",
    "    doc = word.Documents.Open(doc_path)\n",
    "    text = doc.Content.Text\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    return text\n",
    "\n",
    "# Path where your resume files are stored\n",
    "resume_folder = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume-files\\Resumes'\n",
    "\n",
    "# List to store extracted resume data\n",
    "resume_data = []\n",
    "\n",
    "# Iterate through all files in the folder and subfolders\n",
    "for subdir, dirs, files in os.walk(resume_folder):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        if file.endswith('.docx'):  # If it's a .docx file\n",
    "            resume_text = extract_text_from_docx(file_path)\n",
    "            resume_data.append([file, resume_text])\n",
    "        elif file.endswith('.doc'):  # If it's a .doc file\n",
    "            resume_text = extract_text_from_doc(file_path)\n",
    "            resume_data.append([file, resume_text])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(resume_data, columns=['File Name', 'Resume Text'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume-files\\Resumes-Dataset.csv'\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Resumes saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3be9b4d8-f9a9-417e-8d5d-015163048077",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('Resumes-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93cf7536-3658-413e-82d4-b220ae2e8a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Resume Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peoplesoft Admin_AnubhavSingh.docx</td>\n",
       "      <td>Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peoplesoft Admin_G Ananda Rayudu.doc</td>\n",
       "      <td>\\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peoplesoft Admin_Gangareddy.doc</td>\n",
       "      <td>PeopleSoft Database Administrator\\r           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peoplesoft Admin_Murali.docx</td>\n",
       "      <td>Murali\\n\\nExperience Summary \\n\\nI have 6 year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peoplesoft Admin_Priyanka Ramadoss.doc</td>\n",
       "      <td>Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Sri Krishna S_Hexaware.doc</td>\n",
       "      <td>\\tWorkday Integration Consultant\\r\\rName      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Srikanth-Hexaware.docx</td>\n",
       "      <td>Seeking suitable positions in Workday HCM  as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>SSKumar_Hexaware.docx</td>\n",
       "      <td>\\nWORKDAY | HCM | FCM\\nName \\t\\t: Kumar S.S\\nR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Venkateswarlu B_Hexaware.doc</td>\n",
       "      <td>Venkateswarlu.B\\t\\t\\t\\t\\t\\t\\t\\tWorkday Consult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Vinay Kumar_Hexaware.docx</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 File Name  \\\n",
       "0       Peoplesoft Admin_AnubhavSingh.docx   \n",
       "1     Peoplesoft Admin_G Ananda Rayudu.doc   \n",
       "2          Peoplesoft Admin_Gangareddy.doc   \n",
       "3             Peoplesoft Admin_Murali.docx   \n",
       "4   Peoplesoft Admin_Priyanka Ramadoss.doc   \n",
       "..                                     ...   \n",
       "74              Sri Krishna S_Hexaware.doc   \n",
       "75                  Srikanth-Hexaware.docx   \n",
       "76                   SSKumar_Hexaware.docx   \n",
       "77            Venkateswarlu B_Hexaware.doc   \n",
       "78               Vinay Kumar_Hexaware.docx   \n",
       "\n",
       "                                          Resume Text  \n",
       "0     Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...  \n",
       "1   \\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...  \n",
       "2   PeopleSoft Database Administrator\\r           ...  \n",
       "3   Murali\\n\\nExperience Summary \\n\\nI have 6 year...  \n",
       "4   Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...  \n",
       "..                                                ...  \n",
       "74  \\tWorkday Integration Consultant\\r\\rName      ...  \n",
       "75  Seeking suitable positions in Workday HCM  as ...  \n",
       "76  \\nWORKDAY | HCM | FCM\\nName \\t\\t: Kumar S.S\\nR...  \n",
       "77  Venkateswarlu.B\\t\\t\\t\\t\\t\\t\\t\\tWorkday Consult...  \n",
       "78                                                ...  \n",
       "\n",
       "[79 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5b5fcb5-02b7-4520-bac4-a22f411972fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb2b2da-1c4f-46e2-9352-f58a624003be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumes with labels saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes-Dataset-with-Labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import win32com.client as win32\n",
    "\n",
    "# Function to extract text from .docx file\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "# Function to extract text from .doc file using win32com\n",
    "def extract_text_from_doc(doc_path):\n",
    "    word = win32.Dispatch(\"Word.Application\")\n",
    "    word.Visible = False\n",
    "    try:\n",
    "        doc = word.Documents.Open(doc_path)\n",
    "        text = doc.Content.Text\n",
    "        doc.Close(False)  # Ensure document is closed without saving\n",
    "    finally:\n",
    "        word.Quit()  # Ensure Word application is closed\n",
    "    return text\n",
    "\n",
    "# Function to assign labels based on keywords in the resume text\n",
    "def assign_label(text):\n",
    "    text = text.lower()\n",
    "    if 'developer' in text:\n",
    "        return 'Developer'\n",
    "    elif 'admin' in text:\n",
    "        return 'Admin'\n",
    "    elif 'manager' in text:\n",
    "        return 'Manager'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Path where your resume files are stored\n",
    "resume_folder = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume'\n",
    "\n",
    "# List to store extracted resume data\n",
    "resume_data = []\n",
    "\n",
    "# Iterate through all files in the folder and subfolders\n",
    "for subdir, dirs, files in os.walk(resume_folder):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        if file.endswith('.docx'):  # If it's a .docx file\n",
    "            resume_text = extract_text_from_docx(file_path)\n",
    "            resume_data.append([file, resume_text])\n",
    "        elif file.endswith('.doc'):  # If it's a .doc file\n",
    "            resume_text = extract_text_from_doc(file_path)\n",
    "            resume_data.append([file, resume_text])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(resume_data, columns=['File Name', 'Resume Text'])\n",
    "\n",
    "# Automatically assign labels based on keywords in the resume text\n",
    "df['Label'] = df['Resume Text'].apply(assign_label)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes-Dataset-with-Labels.csv'\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Resumes with labels saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5930e1-bcc8-4d38-847f-5eb753f2f544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-docx) (4.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3a3068-ac4e-4794-bd55-9d140c88574d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pywin32 in c:\\users\\dell\\anaconda3\\lib\\site-packages (305.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pywin32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebb084f-7e32-4341-a84a-92ca27a4c1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textract==1.6.3\n",
      "  Downloading textract-1.6.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting argcomplete==1.10.0 (from textract==1.6.3)\n",
      "  Downloading argcomplete-1.10.0-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting beautifulsoup4==4.8.0 (from textract==1.6.3)\n",
      "  Downloading beautifulsoup4-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting chardet==3.0.4 (from textract==1.6.3)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting docx2txt==0.8 (from textract==1.6.3)\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [1 lines of output]\n",
      "  ERROR: Can not execute `setup.py` since setuptools is not available in the build environment.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install textract==1.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de9841c-16fe-455d-a0bc-5d8eec1ccec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete. Data saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import win32com.client  # For .doc files on Windows\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the path to your resumes folder\n",
    "folder_path = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume'\n",
    "\n",
    "# List to store extracted information\n",
    "resume_data = []\n",
    "\n",
    "# Function to extract text from .docx files\n",
    "def extract_text_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "# Function to extract text from .doc files\n",
    "def extract_text_doc(file_path):\n",
    "    word = win32com.client.Dispatch(\"Word.Application\")\n",
    "    doc = word.Documents.Open(file_path)\n",
    "    text = doc.Content.Text\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    return text\n",
    "\n",
    "# Function to extract details using regex or keyword matching\n",
    "def extract_details(text):\n",
    "    # Initialize empty details\n",
    "    details = {\n",
    "        'Skills': 'N/A',\n",
    "        'Experience Level': 'N/A',\n",
    "        'Education Level': 'N/A',\n",
    "        'University': 'N/A',\n",
    "        'Year of Passing': 'N/A',\n",
    "        'Percentage': 'N/A'\n",
    "    }\n",
    "\n",
    "    # Example of regex to find specific details (you can modify these patterns based on your resume structure)\n",
    "    skills_match = re.search(r\"Skills[:\\-]?\\s*(.*)\", text)\n",
    "    experience_match = re.search(r\"Experience Level[:\\-]?\\s*(.*)\", text)\n",
    "    education_match = re.search(r\"Education Level[:\\-]?\\s*(.*)\", text)\n",
    "    university_match = re.search(r\"University[:\\-]?\\s*(.*)\", text)\n",
    "    year_match = re.search(r\"Year of Passing[:\\-]?\\s*(\\d{4})\", text)\n",
    "    percentage_match = re.search(r\"Percentage[:\\-]?\\s*(\\d+\\.?\\d*)%\", text)\n",
    "\n",
    "    # If matches are found, store the extracted data\n",
    "    if skills_match:\n",
    "        details['Skills'] = skills_match.group(1).strip()\n",
    "        text = text.replace(skills_match.group(0), '')  # Remove this part from remaining text\n",
    "    if experience_match:\n",
    "        details['Experience Level'] = experience_match.group(1).strip()\n",
    "        text = text.replace(experience_match.group(0), '')\n",
    "    if education_match:\n",
    "        details['Education Level'] = education_match.group(1).strip()\n",
    "        text = text.replace(education_match.group(0), '')\n",
    "    if university_match:\n",
    "        details['University'] = university_match.group(1).strip()\n",
    "        text = text.replace(university_match.group(0), '')\n",
    "    if year_match:\n",
    "        details['Year of Passing'] = year_match.group(1).strip()\n",
    "        text = text.replace(year_match.group(0), '')\n",
    "    if percentage_match:\n",
    "        details['Percentage'] = percentage_match.group(1).strip() + '%'\n",
    "        text = text.replace(percentage_match.group(0), '')\n",
    "\n",
    "    return details, text  # Return both extracted details and remaining text\n",
    "\n",
    "# Traverse through the folder and subfolders\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        text = \"\"\n",
    "\n",
    "        # Check the file type and extract text accordingly\n",
    "        if file.endswith('.docx'):\n",
    "            try:\n",
    "                text = extract_text_docx(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "        elif file.endswith('.doc'):\n",
    "            try:\n",
    "                text = extract_text_doc(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Extract details from the text\n",
    "        details, remaining_text = extract_details(text)\n",
    "\n",
    "        # Append folder name, file name, extracted details, and remaining resume text\n",
    "        resume_data.append({\n",
    "            'Folder Name': os.path.basename(root),\n",
    "            'File Name': file,\n",
    "            'Skills': details['Skills'],\n",
    "            'Experience Level': details['Experience Level'],\n",
    "            'Education Level': details['Education Level'],\n",
    "            'University': details['University'],\n",
    "            'Year of Passing': details['Year of Passing'],\n",
    "            'Percentage': details['Percentage'],\n",
    "            'Resume Text': remaining_text.strip()  # The remaining text after extracting key details\n",
    "        })\n",
    "\n",
    "# Convert extracted data to a pandas DataFrame\n",
    "df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Save the extracted data to a CSV file\n",
    "output_file = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Extraction complete. Data saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef20039-1f2d-4b23-ba00-8374ba9d1c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text:\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "Processing text:\n",
      "  Anubhav Kumar Singh\t\t\n",
      "\n",
      "  To work in a globally competitive environment on \n",
      "  challenging assignments that shall yield the \n",
      "  twin benefits of the job satisfaction and a steady-paced \n",
      "  professional growth.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " Professional Experience\n",
      "\n",
      " 06/2019 - Current\tHCL\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\tCurrent Role: System Admin Offshore\n",
      "\t\t\tSkills : Shell Scripting, Linux , PeopleSoft Administration , Github\n",
      "\n",
      "Managing PeopleSoft HCM and PeopleSoft FSCM production environments along with support environments installed on Linux and Windows OS.\n",
      "Involved in Day to Day activities such as Project Migration, Database Refresh, System admin changes, Tax updates etc.\n",
      "Troubleshooting of various servers like application servers, Web Servers, Process Scheduler Servers.\n",
      "Applying Tuxedo and WebLogic Middleware CPU patches for various applications.\n",
      "Working on shell scripting used as integration method for exchange of files to external systems\n",
      "Installation and troubleshooting of 2-tier setup as per requirement.\n",
      "Reviewing Vulnerabilities reported by Security Teams.\n",
      "Renewal of SSL in Weblogic.\n",
      "Vulnerability remediation whenever a vulnerability is report by RMIS team.\n",
      "Worked on PUM (PeopleSoft Update Manager) and installation through DPK.\n",
      "Working Knowledge of Ansible and Docker.\n",
      "Developing new Shell scripts and troubleshooting Shell Script failures.\n",
      "\n",
      "\n",
      " 07/2017- 06/2019\tTechMahindra\t\t\t\t\t\t\t\t\t\n",
      "\t\t\tRole/Project: Application Support through Automation/Devops Tools and PeopleSoft Admin\n",
      "\t\t\tSkills : Shell Scripting, Linux , PeopleSoft Administration, Jenkins, Ansible\n",
      "\t\t\t\n",
      "\t\t\tProject 1: People Tools 8.55 Upgrade & HCM 9.2 Application Upgrade\n",
      "\t\t\tProject 2: Migration of Applications from NTT Cloud and On-premises to AWS Cloud\n",
      "\n",
      "Worked on shell scripting for various application requirement.\n",
      "Working on Ansible and Jenkins to automated start/stop and various activities of application.\n",
      "Basic knowledge of Docker.\n",
      "Applying SSL certificates on new released applications.\n",
      "Worked on Elastic Search Configuration in PeopleSoft.\n",
      "Gained knowledge in AWS Resources..\n",
      "Strong understanding of Unix architecture/Command and trouble shooting in Unix/Linux platform.\n",
      "Efficient in using Configuration Management & Deployment Tool like Ansible.\n",
      "Good experience in job scheduling via crontab and IBM Tivoli Workload Scheduler (TWS).\n",
      "Having good knowledge in automation using shell scripting \n",
      "Continuous integration management using Jenkins, installing and configuring Jenkins.\n",
      "Responsible for writing Ansible playbook to perform various task\n",
      "Managed administration tasks installation, configuration, applications, troubleshooting, and performance related issue.\n",
      "Applying Tuxedo and WebLogic CPU patches for various applications.\n",
      "Working on Vulnerabilities reported by Security Teams.\n",
      "Reviewing the platform certification information of products, platforms, database servers, web and application servers, browsers, and other products for PeopleTools 8.55.\n",
      "Server Migration to AWS (Amazon Web Service).\n",
      "Installation of PeopleSoft server components Application Servers, Process Scheduler Servers, Tuxedo, Web logic Servers for New release PeopleTools on Unix/Linux Servers.\n",
      "Applying latest patch to PeopleTools.\n",
      "Installing and configuring Change assistant for various upgrade passes.\n",
      "Creating and running PeopleTools Upgrade Job for PeopleTools 8.55 Upgrade.\n",
      "Setting up Performance monitor.\n",
      "Creating new app, web and process scheduler domains post upgrade on new Linux severs.\n",
      "Troubleshooting common Domain boot problems.\n",
      "Identifying and configuring source and target databases in CA for HCM 9.2 application upgrade.\n",
      "Working with HCM PUM Images.\n",
      "Creating Change packages using PUM and applying to Source/Target databases as per requirement.\n",
      "Creating application upgrade job using change assistant.\n",
      "\n",
      "\n",
      " 09/2015 - 07/2017\tSRDT Pvt Ltd. (SRM GROUP)\n",
      "\t\t\tRole/Project: PeopleSoft application and Database Admin\n",
      "\t\t\tSkills : PeopleSoft Administration, Weblogic, Tuxedo, App designer, PUM, PeopleTools \t\t\t\t\tUpgrade, PeopleSoft Campus Application Upgrade.\t\t\t\n",
      "\n",
      "Maintaining 7 Production Environments with 21 supporting environments installed on Windows server 2008 R2 and Oracle 11g.\n",
      "Possess through knowledge and experience in PeopleSoft architecture, administering PeopleSoft server components Application Servers, Process Scheduler Servers, Tuxedo, Web logic Servers, PIA (PeopleSoft Internet Architecture), Integration Broker, Report Nodes, application issues and technical issues.\n",
      "PeopleSoft Skills with experience in Migrations & Production support of PS Applications\n",
      "Exposure in applying PeopleSoft Bundle Updates through Change Assistant.\n",
      "Exposure in working on both Windows & UNIX/Linux Environments with Oracle database.\n",
      "Working knowledge of integration broker.\n",
      "Refreshed Testing, DEV and Pre-PROD from PROD environments.\n",
      "Experience in Troubleshooting of various servers like application servers, Web Servers, Process Scheduler Servers.\n",
      "Experienced in providing 24/7 support on production and development environments.\n",
      "Installation of Database Servers, Web servers and Application Server and PeopleSoft Application (HRMS 9.2,FSCM9.2, CS9.0, CS 9.2,HRMS 9.2) and People Tool (8.53,8.54, 8.55)\n",
      "Installed and Configured SES (Secure Enterprise Search) for HRMS Instance.\n",
      "Experience in Installing Oracle Policy Automation, Oracle Policy Modelling and creating OPA Database in existing database (Oracle)\n",
      "Implemented Single Sign On between PeopleSoft Applications.\n",
      "Implemented PeopleSoft Interaction Hub to integrate external content and information with PeopleSoft applications.\n",
      "Upgraded People Tool 8.53 to 8.54 for Campus 9.0Production Environment.\n",
      "Upgraded People Tool 8.53 to 8.55 for Finance 9.2 Testing Environment.\n",
      "Upgraded application CS 9.0 to 9.2.\n",
      "Configured PUM (PeopleSoft Update Manager) for every new Image.\n",
      "Applying Tax Updates, BUGS and Tailored Change Packages through PUM.\n",
      "Upgraded Oracle Database 11.2.0.1 to 11.2.0.4 using DBUA. \n",
      "Created Instances on People Tools 8.55 to provide Testing environments.\n",
      "Prepared Upgrade Status reports and sheets.\n",
      "Co-ordinated and provided support for offshore projects.\n",
      "Imported Self Signed Certificate into WebLogic to provide secure port access of Instances.\n",
      "Set up of Terminal Server to provide a Central access of People Tools for Technical/Developers.\n",
      "Created tickets to development team and followed up with them to get the resolution for any error occurred. \n",
      "\n",
      "\n",
      "\t\t\tProjects:\n",
      "\n",
      "\t\tClient: DRDO\n",
      "\t\tProject: Single Sign On\n",
      "\t\tRole: PeopleSoft Admin\n",
      "\t\tEnvironment: People Tool 8.50, HRMS 9.1, FSCM 9.1\n",
      "\n",
      "\t\tDescription:\n",
      "\t\tSingle sign-on (SSO) is a property of access control of multiple related, but independent software \t\t\tsystems. With this property a user logs in with a single ID and password to gain access to a \t\t\tconnected system or systems without using different usernames or passwords.\n",
      "\n",
      "\n",
      "\t\tClient: NetApp\n",
      "\t\tProject: Support and Maintenance\n",
      "\t\tRole: PeopleSoft Admin/L2 Support\n",
      "\t\tEnvironment: PeopleTool 8.49, HRMS 8.9\n",
      "\n",
      "\t\tDescription:\n",
      "\t\tHandled IB related issue.\n",
      "\t\tClear process scheduler cache as per weekly maintenance process.\n",
      "\t\tHandled PSADMIN related activities.\n",
      "\n",
      "\n",
      " 11/2013 - 05/2015\tACS                                                                                                                           \n",
      "\n",
      " Personal Details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "PLACE:\t\t\t\t\t\t\t\t\tG. Ananda Rayudu-mentioned information is true to the best of my knowledge.University.. the customization for the PeopleSoft. Demo, Development, Support, Test, and Production instances.\n",
      "\n",
      "Processing text:\n",
      "Document preparation for the Issues and troubleshooting steps for issues occurred.nce gaining.e APPSRV.CFG file, trace logs in Configuration Manager for SQL, People Code, AE, etc and Enable Trace parameter psappserv.cfg and psprcs.cfg files in application server and Process Scheduler ecome a successful in Oracle PeopleSoft Application DBA activities.\n",
      "\n",
      "Processing text:\n",
      "Murali\n",
      "\n",
      "Experience Summary \n",
      "\n",
      "I have 6 years of experience working in PeopleSoft Administration and performing various infrastructure related activities in PeopleSoft environments. \n",
      "\n",
      "Installed and configured PeopleSoft 9.0,9.1,9.2 Web server, Application server, Database server and Process scheduler \n",
      "server on Windows, UNIX and Linux platforms.\n",
      "Creating Domains for Web server, Application server and Process scheduler server.\n",
      "Applied Patches Manually and applied Maintenance Packs through Change Assistant tool.\n",
      "Experience in DPKs installations.\n",
      "Applying TAX UPDATES and fixes using PUM\n",
      "Migrating projects from one environment to another environment using Application Designer and also through CAPI, STAT tools.\n",
      "Performed Single sign on (SSO)Implementation.\n",
      "Experience in running Compare Reports between pre and Post Migrations.\n",
      "Experience in setting up Client Workstation for Developers and Testers.\n",
      "Involved in Configuration of Integration Broker setting up Between the Modules for sending the Messages.\n",
      "Involved 24/7 production Support to Client.\n",
      "Involved in Running Audit Reports (DDDAUDIT AND SYSAUDIT) for Integrity Checks.\n",
      "Experience in Configuration and Setup the REN server.\n",
      "Configured and Maintained Report Nodes settings.\n",
      "Checked and Clear Cache for the servers.\n",
      "Involved in Troubleshooting of the servers like Application server, web server and Process scheduler server. \n",
      "Worked on Peopletools Upgrade PT8.52 to PT8.55 and 8.55 to 8.57.\n",
      "Installing and configuring Elastic Search 6.1.2\n",
      "\n",
      "Career Profile:\n",
      "\n",
      "Client :Sembcorp , Brazil\n",
      "\n",
      "Description:\n",
      "This project involved active production support in the fields of HRMS 9.2. Additionally also involved in maintenance and enhancement of the system.\n",
      "\n",
      "Responsibility:\n",
      "\n",
      "\n",
      " Installation and setup of People Soft HCM & ELM 9.2 on Oracle.\n",
      " Creating database user, assigning roles & privileges to the users.\n",
      " Maintaining various People Soft instances.\n",
      " Debugging and resolving issues related to application server\\web server\\process    scheduler.\n",
      " Weekly\\monthly database maintains.\n",
      "Performed People tools upgrade from 8.55.14 to 8.57.05.\n",
      "Performing Post refresh Activities.\n",
      "\n",
      "\n",
      "\n",
      "Client :Wipro, IND\n",
      "Platforms : People Tools 8.56, People Soft HCM 9.2.\n",
      "\n",
      "Description:\n",
      "This project involved active production support in the fields of HRMS 9.2. Additionally also involved in maintenance and enhancement of the system.\n",
      "\n",
      "Responsibility:\n",
      " Installation and setup of People Soft HCM 9.2 on Oracle.\n",
      " Creating database user, assigning roles & privileges to the users.\n",
      " Maintaining various People Soft instances.\n",
      " Debugging and resolving issues related to application server\\web server\\process    scheduler.\n",
      " Weekly\\monthly database maintains.\n",
      " Creating and modifying data mover scripts.\n",
      " Migrating projects using CAPI.\n",
      " Applying Patches.\n",
      " Setting up a PeopleSoft Reporting environment for reporting.\n",
      " Interacting with the client for various Production related issues.\n",
      "Applying TAX UPDATES using PUM.\n",
      "Performing Post refresh Activities.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Project Title :People Soft HCM Production Support and Enhancement\n",
      "Client : ASG, USA\n",
      "Platforms : People Tools 8.52,8.54 People Soft HCM 9.0,9.2 DB2\n",
      "AIX 5.1.\n",
      "\n",
      "Description:\n",
      "This project involved active production support in the fields of HRMS 9.0. Additionally also involved in maintenance and enhancement of the system.\n",
      "\n",
      "Responsibility:\n",
      "\n",
      " Installation and setup of People Soft HCM 9.0,9.1 on DB2.\n",
      " Creating database user, assigning roles & privileges to the users.\n",
      " Maintaining various People Soft instances.\n",
      " Debugging and resolving issues related to application server\\web server\\process    scheduler.\n",
      " Weekly\\monthly database maintains.\n",
      " Creating and modifying data mover scripts.\n",
      "Migrating projects using STAT,CAPI.\n",
      " Applying Patches.\n",
      " Setting up a PeopleSoft Reporting environment for reporting.\n",
      " Interacting with the client for various Production related issues.\n",
      "Applying TAX UPDATES using PUM.\n",
      "Performing Post refresh Activities.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technology\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal Details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date:\n",
      "\n",
      "Place:  Hyderabad\n",
      "\n",
      "Processing text:\n",
      "\u0007   bies books, Yoga, Gardening, Surfing.Higher Secondary School,financial application. and financial services company providing services in investment banking, provate banking and asset management and sahred services.ion I work for.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROFILE SUMMARY\n",
      "\n",
      "I have overall 6.8 years’ experience as PeopleSoft Administrator. Installed PeopleTools 8.55 from the scratch including its products. \n",
      "Experience in Peopletools 8.51, 8.54.08, 8.55.07&Application 9.0 and 9.2 (HRMS/FSCM). Deterministic approach towards problem solving & troubleshooting.\n",
      "Proficient in Integration Broker.\n",
      "Upgraded FSCM and HCM applications to PeopleTools 8.55.07 from PeopleTools 8.54.08.\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Graduated B-Tech in Electronics and Communication Engg. from M.V.G.R College of Engineering, Vizianagaram(JNTUK) with an aggregate of 68.93%.\n",
      "Achieved 90% marks in 12th standard. Scored 86% in 10th standard.\n",
      "\n",
      "ACHIEVEMENTS\n",
      "Awarded Bravo in 2015 Q3, 2016 Q1 and Pat on Back in Q2, 2016, Q1, 2017 in Techahindra.\n",
      "Awarded Associate of the month award and Innovator of the month (1 time). Awarded spot and pat on back in Capgemini\n",
      "\n",
      "WORK EXPERIENCE\n",
      "CAPGEMINI (MAY’19 – TILL NOW)\n",
      "Production support for 5 finance environment and their respective non production environments.\n",
      "\n",
      "Project Experience:\n",
      "Project Name \t\t\t\t: AXA\n",
      "Role\t\t\t\t\t: Consultant\n",
      "Environment\t\t\t\t: Windows Server 2012 R2\n",
      "\n",
      "COGNIZANT TECHNOL OGY SOL UT IONS (AUGUS T ' 1 8 – APRIL’19)\n",
      "Voya Financial Insurance US client project which deals with support and managing Finance applications.\n",
      "\n",
      "Project Experience:\n",
      "Project Name \t\t\t\t: Voya Financials\n",
      "Role\t\t\t\t\t: Associate\n",
      "Environment\t\t\t\t: Windows Server 2012 R2\n",
      "\n",
      " TECH MAHINDRA LIMIT ED (JULY ' 1 4 - AUGUS T ' 18)\n",
      "\n",
      "PeopleSoft 9.2 Implemented for HR and FIN application. PeopleSoft 9.2 Implementation project includes 10 PeopleSoft applications, interfaces with third-party applications and interfaces with live production PeopleSoft 9.2 environment in SDLC.\n",
      "\n",
      "Project Experience: Project Name \n",
      "Role Environment\n",
      "\n",
      ": CIO COMMON\n",
      ": Software Engineer\n",
      ": SOLARIS, Windows Server 2008R2\n",
      "\n",
      "\n",
      "RESPONSIBILITIES:\n",
      "Provided administrative supports for PEOPLESOFT tools version 8.51, 8.54, 8.55.25, 8.56.10 and application HRMS 9.0, 9.2 & Financials/SCM 9.0, 9.2 modules on Windows and UNIX OS\n",
      "Creation of indexes for tables from application designer.\n",
      "PeopleSoft Database Setup, troubleshooting issues and other daily PeopleSoft admin activities\n",
      "Configured PeopleSoft application server, process scheduler & web server domains, setup Master Scheduler.\n",
      "Installing Oracle Tuxedo, Weblogic, Java, Application Disk (FSCM and HCM) and Oracle database on UNIX and Windows servers from scratch\n",
      "Installed PeopleTools 8.55 for HCM and FSCM with a demo database. Upgraded FSCM application to Peopletools 8.55 from PeopleTools 8.54.08. Applied patch 8.55.07 in FSCM\n",
      "Configured Report Nodes. Bouncing of App, Web and Process schedulers and clearing cache\n",
      "Performed pre-refresh and post refresh activity during Database cloning activity.\n",
      "Recompilation of COBOL source codes\n",
      "Worked on project migrations using Application Designer and Change Assistant.\n",
      "Applied image 15, 16, 25 and 37 on FSCM 9.2 using PUM and change assistant. Good hands-on experience in application designer, data mover, and change assistant. Well aware of PIA (PeopleSoft Internet Architecture).\n",
      "\n",
      "Configuring Integration broker and report nodes\n",
      "Creating UDM file transfer Interfaces and monitoring them\n",
      "Deploying gnupg keys and certificates in servers.\n",
      "Installed and configured Elastic search. \n",
      "TOOLS USED:\n",
      "PeopleTools 8.54.08, 8.56.10, 8.55.25, Application Designer, Data Mover\n",
      "Toad, Sqldeveloper, Microsoft SQL Management Studio 2014 \n",
      "Oracle 11g, Oracle 12c, Microsoft SQL server 2014\n",
      "Filezilla, Winscp, PCOMM, TWS, Service now, Silva\n",
      "\n",
      "TRAINING & CERTIFICATIONS\n",
      "Oracle Cloud Infrastructure Architect Associate\n",
      "Oracle Cloud Infrastructure Architect Professional\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Prepared copy of production database, tasks involved were to run audit reports DDDAUDIT and SYSAUDIT ler Server.es and Applied related Database patches and Application Patches.O to manage database transactions, and Jolt, TUXEDO's counterpart, to facilitate transaction requests issued from the Internet. Both TUXEDO and Jolt are products of BEA Systems\n",
      "\n",
      "Processing text:\n",
      " PeopleSoft Admin\n",
      "VARKALA VIKAS\n",
      "\n",
      "Career Objective:\n",
      "\n",
      "I have total 4.2 Years’ Experience in PeopleSoft Admin and PeopleSoft DBA. I hope to enhance my skill set while adding value to the business, to enable implementation of solutions, which aid the company’s objectives, understanding and anticipating the needs, interests and motivations of the clients and to deliver on time, budget and to quality, delivering value through improving agility, quality and reliability\n",
      "\n",
      "Professional Summary:\n",
      "\n",
      "Having 4.2 years of experience in PeopleSoft implementation, Support, People Tools Upgrades, configuration, migrations, maintenance and administration of Application Server Domains, Process Scheduler Servers, Web Server Domains, PUM and Elastic search.\n",
      "Involved in various Tools and Application Upgrades.\n",
      "Experience in driving Infrastructure Hardware Upgrades, Disaster Recovery Activities.\n",
      "Configured https and secure web server (SSL) administration.\n",
      "Monitor system by developing and maintaining monitoring Shell scripts\n",
      "Experience in Oracle Database Administration for 11gR2, 12cR1 and 12cR2\n",
      "Experience in Health Check for all the PeopleSoft Environments\n",
      "Experience in PeopleSoft Database Refreshes from Production to Development and Testing Environments\n",
      "Experience in Performance and Tuning of Application Servers, Web Servers\n",
      "Experience in Windows Administration\n",
      "Implemented PeopleSoft Internet Architecture (PIA) on Demo, Test, Development and Production instances.\n",
      "Extensively involved in resolving Performance issues.\n",
      "Experience in PeopleSoft Installations of PeopleTools 8.56,8.57 HCM 9.2, WebLogic 12cr2 Tuxedo 12cR2 and People Books 8.56,8.57 Windows 2012R2\n",
      "In depth experience on PeopleSoft Update Manager (PUM) for applying PeopleTools patches, Application Bundles on PeopleTools and HRMS 9.2 and FSCM 9.2 Applications\n",
      "In Depth Experience in Integration Broker setup.\n",
      "Experience in Secure Socket Layer (SSL) implementation on PeopleSoft.\n",
      "Proficiency in creation and configuration and administration of Application Server Domains, Process scheduler Domains, Web Server Domains\n",
      "Experience in Reconfiguration of Application Server Domains, Process Scheduler Server Domains and Web Server domains.\n",
      "Experience in Project Migrations using Application Designer and Data Migrations using Data Mover\n",
      "Experience in generating Pre-compare reports and Post Compare Reports between various environments.\n",
      "\n",
      "Experience in setting up client Work Station for developers and testers.\n",
      "Experience in resolving developer issues like resetting passwords, locking and unlocking user accounts.\n",
      "Maintain the workflow of PeopleSoft users.\n",
      "Worked on applying Patches, Bundles and Tax Updates using Change Assistant and\n",
      "PeopleSoft Update Manager (PUM)\n",
      "Installing and Configuring Change Assistant to apply bundles and tax-updates.\n",
      "Involved in setup configuration of Integration Broker in Financials and HCM Applications.\n",
      "Maintaining integrity and internal consistency of the database using DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Experience on clearing the cache of all servers such as Application Server Domains, Web Server Domains and Process Scheduler servers on a regular basis.\n",
      "Monitor the log files to find out bottleneck of the status of servers\n",
      "Maintaining and troubleshooting various servers like Application Server domains, Process Scheduler Domains and Web Server Domains\n",
      "Regularly involved in doing Database Cloning and Refreshing on PeopleSoft Instances.\n",
      "Experience in Installing COBOL Software and compilation.\n",
      "Experience in Tuning of Application Server Domains, Process Scheduler Domains and Web Server Domains.\n",
      "In Depth Experience in PeopleSoft Database Performance and Tuning\n",
      "Experience in Data Guard (DR) support\n",
      "Experience in Database patching.\n",
      "Experience in PeopleSoft Database Refreshes using RMAN.\n",
      "Good team player and a proven individual contributor\n",
      "\n",
      "\n",
      "Area of Technical Skills:\n",
      "\n",
      "Educational Qualification:\n",
      "B.SC from Osmania university in 2017.\n",
      "\n",
      "Professional experience:\n",
      "Worked as PeopleSoft Administrator/ PeopleSoft DBA with Progile infotech Pvt LTD from July 2017 to till date.\n",
      "Project Experience and Achievement’s:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Client\t:\tHartford Insurance Group, Hartford, CT.\n",
      "Project\t:\tInstall, Configure and Production Support of PeopleSoft Applications and Databases.\n",
      "Environment\t:\tPeople Tools 8.57,8.56,8.55 HRMS9.2, FSCM9.2, Oracle 12c,\n",
      "Tuxedo 12cR2, Oracle WebLogic 12cR2, Windows Server 2012 R2, Oracle Enterprise Linux 5,6.\n",
      "Role\t:\tPeopleSoft Admin/PeopleSoft DBA\n",
      "Duration\t:\tJuly 2017 to till date\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Monitoring the day-to-day working of the system.\n",
      "Build Verification Test – To check proper installation and running of all PeopleSoft components, processes and reports.\n",
      "Object Migration between different instances involving compare reports, building objects etc.\n",
      "Involved in Implementation of PeopleSoft Internet Architecture (PIA) including Application Servers, Web Servers and Batch Servers.\n",
      "Handled Security Management tasks like creating new user profiles, roles, permission lists and granting privileges.\n",
      "Handled Application Management tasks like Applying Patches & Fixes.\n",
      "Configured workstation for PeopleSoft developers on their VM's for accessing PeopleTools like Application designer, Data Mover, Administrating Application Server and Process Scheduler Server using PSAdmin utility\n",
      "\n",
      "Migration of all PeopleSoft projects to DEV, TEST and PROD instances.\n",
      "Analysis of production issues raised by clients and providing solutions.\n",
      "Report Node configurations.\n",
      "Worked on Project Migrations and Data Migrations.\n",
      "Generating Compare Reports.\n",
      "Downloading Patches, Tax updates & applied to the environments and maintains the customizations for the PeopleSoft.\n",
      "Experience in applying Patches, Bundles and Tax Updates using Change Assistant and\n",
      "PeopleSoft Update Manager (PUM)\n",
      "Installing and Configuring Change Assistant to apply Change packages and tax-updates.\n",
      "Appling Patches for Demo, Dev, Test and Production Environments.\n",
      "Configuring and monitoring Process Scheduler and troubleshooting various issues related.\n",
      "\n",
      "Involved in the Performance of the databases and application by creating multiple domains across the instances\n",
      "Troubleshooting  of  Application  Server  Domains,  Process Scheduler Domains\tand\tWeb Server Domains\n",
      "Configure Https and secure web server (SSL) administration\n",
      "Setup load Balancer configuration and application server clustering setups / Master Process scheduler set up for high availability systems\n",
      "Performed data migration using data pump and data mover utilities\n",
      "Load balancing of Application server & Web server.\n",
      "Setup Application Security using User Profiles, Roles and Permission lists.\n",
      "Refreshing PeopleSoft test environment for synchronisation to production.\n",
      "Maintaining   integrity   and   internal   consistency   of   the   database\tusing DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Involved in 24/7 Production Support to clients.\n",
      "Checked and cleared the application server cache on a regular basis as a maintenance process.\n",
      "Installed People Books and configured the Web Server to access People Books.\n",
      "Configured and maintained Report Nodes and Settings.\n",
      "Generating compare reports between various environments.\n",
      "Documenting all support issues with their resolutions and feedback.\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "Processing text:\n",
      "Involved in Logical Backups using Data Pump Technology.ups.nd HRMS9.2 using PeopleSoft PUM.ains. the instances.ons and profiles to users. file systems, application servers, web servers and batch servers.d batch servers.\n",
      "\n",
      "Processing text:\n",
      ".   menting all support issues with their resolutions and feedback.le Books.ntenance process. AUDIT reports periodically.ilability systemsn Server Domains, Process Scheduler Servers, Web Server Domains., Process Scheduler Servers, Web Server Domains, PUM  and SES.rstanding and anticipating the needs, interests and motivations of the clients and to deliver on time, budget and to quality, Delivering value through improving agility, quality and reliability\n",
      "\n",
      "Processing text:\n",
      "PeopleSoft Administration\n",
      " \n",
      "Vivekanand Sayana                                                                                                                                                                                                           \t\n",
      "\n",
      "Career Objective: \n",
      "\n",
      "With my valid expertise of 7.5 years in PeopleSoft, I hope to enhance my skill set while adding value to the business, to enable implementation of solutions, which aid the company’s objectives, understanding and anticipating the needs, interests and motivations of the clients and to deliver on time, budget and to quality, delivering value through improving agility, quality and reliability\n",
      "\n",
      "Professional Summary:\n",
      "\n",
      "Over 7.5 years of experience in PeopleSoft implementation, Support, configuration, migrations, maintenance and administration of Application Server Domains, Process Scheduler Servers, Web Server Domains, PeopleTools Upgrades, Application Updates, PUM, SES and Elastic Search. \n",
      "Experience in integration activities between various PeopleSoft Financials, HRMS, EPM and FSCM environments. \n",
      "Extensively involved in resolving Performance issues.\n",
      "Experience in driving Infrastructure Hardware Upgrades, Disaster Recovery Activities. \n",
      "Experience in Health Check for all the PeopleSoft Environments\n",
      "Experience in PeopleSoft Database Refreshes from Production to Development and Testing Environments\n",
      "Experience in Performance and Tuning of Application Servers, Web Servers\n",
      "Performed 3 full life cycle implementations in PeopleSoft.\n",
      "Implemented PeopleSoft Internet Architecture (PIA) on Demo, Test, Development and Production instances.\n",
      "Experience in PeopleSoft Implementation on PeopleTools 8.56, FSCM 9.2, Web Logic 12.2.1, Tuxedo 12.2.2 and Oracle 12c R2 on Oracle Enterprise Linux 7 and Windows 2012 R2.\n",
      "Experience in PeopleSoft Installations of PeopleTools 8.55, HCM 9.2, WebLogic 12.1.3,\n",
      "Tuxedo 12.1.3 and People Books 8.55 on Oracle Enterprise Linux 6 and Windows 2012R2\n",
      "Experience in PeopleSoft Installations of PeopleTools 8.54, HCM 9.2, Weblogic 12.1.2, Tuxedo 12.1.0 and People books 8.54 on windows 2012 R2 and Oracle Enterprise Linux 6.\n",
      "Experience in PeopleSoft Installations of PeopleTools 8.53, FSCM 9.2, Weblogic 10.3.6, Tuxedo 10.3 and People Books 8.53 on windows 2008 R2 and Oracle Enterprise Linux 5.4\n",
      "Experience in PeopleSoft Installations of PeopleTools 8.50, HCM 9.1,Weblogic 10.3, Tuxedo 10.3, Oracle 10g R2 and People Books 8.50 on Windows Server 2003 and Oracle Enterprise Linux 5.\n",
      "In depth experience on PeopleSoft Update Manager (PUM) for applying PeopleTools patches, Application Bundles on PeopleTools 8.53, 8.54 and HRMS 9.2 and FSCM 9.2 Applications, Using DPK’s to deploy PUM latest Images and DPK’s to Install, Middle tier, App Tier and PeopleTools.\n",
      "In Depth Experience in Integration Broker Troubleshooting.\n",
      "Proficiency in creation and configuration and administration of Application Server Domains, Process scheduler Domains, Web Server Domains \n",
      "Experience in Reconfiguration of Application Server Domains, Process Scheduler Server Domains and Web Server domains.\n",
      "Experience in Project Migrations using Application Designer and Data Migrations using Data Mover\n",
      "Experience in generating Pre-compare reports and Post Compare Reports between various environments.\n",
      "Experience in setting up client Work Station for developers and testers.\n",
      "Experience in resolving developer issues like resetting passwords, locking and unlocking user accounts.\n",
      "Maintain the workflow of PeopleSoft users.\n",
      "Worked on applying Patches, Bundles and Tax Updates using Change Assistant and PeopleSoft Update Manager (PUM)\n",
      "Installing and Configuring Change Assistant to apply bundles and tax-updates.\n",
      "Involved in setup configuration of Integration Broker in Financials and HCM Applications.\n",
      "Maintaining integrity and internal consistency of the database using DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Experience in load balancing of Application server domains and Process Scheduler Servers.\n",
      "Experience on clearing the cache of all servers such as Application Server Domains, Web Server Domains and Process Scheduler servers on a regular basis.\n",
      "Monitor the log files to find out bottleneck of the status of servers\n",
      "Experience in Troubleshooting of Data mover while installing PeopleSoft.\n",
      "Maintaining and troubleshooting various servers like Application Server domains, Process Scheduler Domains and Web Server Domains\n",
      "Experience in Tuning of Application Server Domains, Process Scheduler Domains and Web Server Domains.\n",
      "Strong communication, collaboration, team building and inter-personal skills\n",
      "Good team player and a proven Individual contributor\n",
      "\n",
      "Area of Technical Skills:\n",
      "\n",
      "Educational Qualification:\n",
      "\n",
      "MBA (HR & Marketing) from KBN College, Nagarjuna University, Vijayawada in 2011.\n",
      "\n",
      "B.Sc (Bachelor of Science) from SRR & CVR College, Nagarjuna University, Vijayawada in 2009.\n",
      "Professional experience:\n",
      "\n",
      "Worked as PeopleSoft Systems Administrator in Capgemini Technology Services India Limited from Feb 2020 to Sept 2020.\n",
      "Worked as PeopleSoft Systems Administrator in Cognizant Technology Solutions India Pvt Ltd from Oct 2017 to Sept 2019.\n",
      "Worked as Associate - PeopleSoft Administrator with A&A Innovative Solutions Pvt. Ltd from Jan 2013 to Oct 2017.\n",
      "\n",
      "Project Experience and Achievement’s\n",
      "\n",
      "Client\t\t\t: \tDisney (Fox Entertainment) & Allegis \n",
      "\n",
      "Environment \t\t:\tHCM, FSCM & ELM 9.2, People Tools 8.56, Oracle 12c, \n",
      "                                                WebLogic 12.2.1, Tuxedo 12.2.2, Red Hat Enterprise Linux 6.      \n",
      "\n",
      "Role\t\t\t:           Sr. PeopleSoft Admin/PeopleSoft DBA \n",
      "                                                \n",
      "Duration                     :           Feb 2020  to Sept 2020\n",
      "\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Involved in PeopleTools upgrade from PeopleTools 8.55 to 8.57\n",
      "Involved in Application update from FSCM 9.2.017 to FSCM 9.2.032\n",
      "Strong experience on PeopleSoft PUM server installation and troubleshooting.\n",
      "Applying fixes, patches and bundles for PeopleSoft FSCM92 and HRMS92 using PeopleSoft PUM. \n",
      "Worked intensively on performance tuning of PIA architecture based on load testing and up scaling architecture to support the expected load\n",
      "Created a dedicated Integration Broker gateway as message volume was high and for easy maintenance. \n",
      "Redesigned and Configured High availability and load balancing for existing PeopleSoft \n",
      "Internet Architecture. \n",
      "Responsible for the daily maintenance and troubleshooting of complex hosted solutions\n",
      "Monitoring the day-to-day working of the system.\n",
      "Handled Application Management tasks like Applying Patches & Fixes.\n",
      "Load balancing of Application server & Web server, Performed Database Refreshes, Imports, Exports and Backups.\n",
      "Object Migration between different instances involving compare reports, building objects etc. \n",
      "Monitoring Application servers, web servers and process scheduler errors\n",
      "Check the reports for status Blocked, queued, processing, no success etc. Error Log Attached, Check the Reports Ran to Success\n",
      "Perform Remote call test\n",
      "Check the integration broker\n",
      "Check the Server Disk space, Load level, PeopleSoft ping under acceptable level\n",
      "Status of Housekeeping activities (Checking and Cleaning up the logs)\n",
      "Daily perform Project Migrations and Data Migrations.\n",
      "Generate Compare Reports between various environments.\n",
      "Checked and cleared cache on all servers such as Application Servers, Web Servers, and Process Scheduler Servers on a regular basis as a maintenance process.\n",
      "Maintain the workflow of PeopleSoft users.\n",
      "Download Updates and Fixes and apply to the environments and maintain the customizations for the PeopleSoft.\n",
      "Download PeopleSoft Update Image and Apply to the Applications.\n",
      "Applied Patches and Tax Updates.\n",
      "Installed and Configured Change Assistant to apply PUM image. \n",
      "Maintaining integrity and internal consistency of the database using DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Performed Jolt failover and load balancing of Application Server Domains and Process Scheduler Servers Domains.\n",
      "Involved in the Performance of the databases and application by creating multiple domains across the instances.\n",
      "Monitor the log files to find out bottleneck of the status of servers\n",
      "Troubleshoot of Data mover while installing PeopleSoft.\n",
      "Troubleshooting of Process Scheduler servers if the jobs are stacked on a Queue.\n",
      "Maintain and troubleshoot various servers like Application Servers, Process Scheduler Servers and Web Servers.\n",
      " Involved in doing Refreshing on PeopleSoft instances weekly twice or thrice.\n",
      "Documenting all support issues with their resolutions and feedback.\n",
      "\n",
      "\n",
      "Client\t\t\t: \tInter-Continental Hotels Group\n",
      "\n",
      "Environment \t:\tFSCM 9.2, People Tools 8.56, Oracle 12c, \n",
      "                                                WebLogic 12.2.1, Tuxedo 12.2.2, Red Hat Enterprise Linux 6.      \n",
      "\n",
      "Role\t:           Sr. PeopleSoft Admin/PeopleSoft DBA \n",
      "                                                \n",
      "Duration                     :           Oct 2017 to Sept 2019\n",
      "\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Involved in PeopleTools upgrade from PeopleTools 8.54 to 8.55\n",
      "Involved in Application update from FSCM 9.2.006 to FSCM 9.2.016\n",
      "Strong experience on PeopleSoft PUM server installation and troubleshooting.\n",
      "Applying fixes, patches and bundles for PeopleSoft FSCM92 and HRMS92 using PeopleSoft PUM. \n",
      "Perform Remote call test\n",
      "Check the integration broker\n",
      "Check the Server Disk space, Load level, PeopleSoft ping under acceptable level\n",
      "Status of Housekeeping activities (Checking and Cleaning up the logs)\n",
      "Daily perform Project Migrations and Data Migrations.\n",
      "Generate Compare Reports between various environments.\n",
      "Checked and cleared cache on all servers such as Application Servers, Web Servers, and Process Scheduler Servers on a regular basis as a maintenance process.\n",
      "Maintain the workflow of PeopleSoft users.\n",
      "Download Updates and Fixes and apply to the environments and maintain the customizations for the PeopleSoft.\n",
      "Download PeopleSoft Update Image and Apply to the Applications.\n",
      "Applied Patches and Tax Updates.\n",
      "Installed and Configured Change Assistant to apply PUM image. \n",
      "Maintaining integrity and internal consistency of the database using DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Performed Jolt failover and load balancing of Application Server Domains and Process Scheduler Servers Domains.\n",
      "Involved in the Performance of the databases and application by creating multiple domains across the instances\n",
      "Monitor the log files to find out bottleneck of the status of servers\n",
      "Setup Master/Slave load balance for pub/sub services\n",
      "Worked intensively on performance tuning of PIA architecture based on load testing and up scaling architecture to support the expected load\n",
      "Created a dedicated Integration Broker gateway as message volume was high and for easy maintenance. \n",
      "Redesigned and Configured High availability and load balancing for existing PeopleSoft \n",
      "Internet Architecture. \n",
      "Responsible for the daily maintenance and troubleshooting of complex hosted solutions\n",
      "Monitoring the day-to-day working of the system.\n",
      "Handled Application Management tasks like Applying Patches & Fixes.\n",
      "Load balancing of Application server & Web server, Performed Database Refreshes, Imports, Exports and Backups.\n",
      "Object Migration between different instances involving compare reports, building objects etc. \n",
      "Monitoring Application servers, web servers and process scheduler errors\n",
      "Check the reports for status Blocked, queued, processing, no success etc. Error Log Attached, Check the Reports Ran to Success\n",
      "Troubleshoot of Data mover while installing PeopleSoft.\n",
      "Troubleshooting of Process Scheduler servers if the jobs are stacked on a Queue.\n",
      "Maintain and troubleshoot various servers like Application Servers, Process Scheduler Servers and Web Servers.\n",
      " Involved in doing Refreshing on PeopleSoft instances weekly twice or thrice.\n",
      "Generating weekly status reports on all support issues to delivery manager\n",
      "Documenting all support issues with their resolutions and feedback.\n",
      "\n",
      "\n",
      "Client\t\t\t: \tBaylor Scott and White\n",
      "\n",
      "Environment\t:           HRMS 9.2, People Tools 8.55, Oracle 12c, \n",
      "                                                WebLogic 12.1.2, Tuxedo 12.1.1, Red Hat Enterprise Linux 6.      \n",
      "                       \n",
      "Role\t:           Sr. PeopleSoft Admin/PeopleSoft DBA \n",
      "                                                \n",
      "Duration                     :           Jun 2013 to Oct 2017\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Strong experience on PeopleSoft PUM server installation and troubleshooting.\n",
      "Applying fixes and patches bundles for PeopleSoft FSCM92 and HRMS92 using PeopleSoft PUM. \n",
      "Setup Master/Slave load balance for pub/sub services\n",
      "Worked intensively on performance tuning of PIA architecture based on load testing and up scaling architecture to support the expected load\n",
      "Created a dedicated Integration Broker gateway as message volume was high and for easy maintenance. \n",
      "Redesigned and Configured High availability and load balancing for existing PeopleSoft \n",
      "Internet Architecture. \n",
      "Responsible for the daily maintenance and troubleshooting of complex hosted solutions\n",
      "Monitoring the day-to-day working of the system.\n",
      "Handled Application Management tasks like Applying Patches & Fixes.\n",
      "Load balancing of Application server & Web server, Performed Database Refreshes, Imports, Exports and Backups.\n",
      "Object Migration between different instances involving compare reports, building objects etc. \n",
      "Monitoring Application servers, web servers and process scheduler errors\n",
      "Check the reports for status Blocked, queued, processing, no success etc. Error Log Attached, Check the Reports Ran to Success\n",
      "Perform Remote call test\n",
      "Check the integration broker\n",
      "Check the Server Disk space, Load level, PeopleSoft ping under acceptable level\n",
      "Status of Housekeeping activities (Checking and Cleaning up the logs)\n",
      "Daily perform Project Migrations and Data Migrations.\n",
      "Generate Compare Reports between various environments.\n",
      "Checked and cleared cache on all servers such as Application Servers, Web Servers, and Process Scheduler Servers on a regular basis as a maintenance process.\n",
      "Maintain the workflow of PeopleSoft users.\n",
      "Download Updates and Fixes and apply to the environments and maintain the customizations for the PeopleSoft.\n",
      "Download PeopleSoft Update Image and Apply to the Applications.\n",
      "Applied Patches and Tax Updates.\n",
      "Installed and Configured Change Assistant to apply PUM image.\n",
      "Perform setup of Integration Broker between various environments for HRMS and FSCM. \n",
      "Maintaining integrity and internal consistency of the database using DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Performed Jolt failover and load balancing of Application Server Domains and Process Scheduler Servers Domains.\n",
      "Involved in the Performance of the databases and application by creating multiple domains across the instances\n",
      "Monitor the log files  to find out bottleneck of the status of servers\n",
      "Troubleshoot of Data mover while installing PeopleSoft.\n",
      "Troubleshooting of Process Scheduler servers if the jobs are stacked on a Queue.\n",
      "Maintain and troubleshoot various servers like Application Servers, Process Scheduler Servers and Web Servers.\n",
      " Involved in doing Refreshing on PeopleSoft instances weekly twice or thrice.\n",
      "Generating weekly status reports on all support issues to delivery manager\n",
      "Documenting all support issues with their resolutions and feedback.\n",
      "\n",
      "Processing text:\n",
      "\u0007PeopleSoft HCM 8.80, People Tools 8.48.er user requirement.animalsetailer in the United States, with corporate offices in San Diego and San Antonio. Petco sells 9.2, PeopleTools to 8.56.16 and Oracle 12c DB.\n",
      "\n",
      "Processing text:\n",
      "=========================================================================================== 2014 .ths. be resolved within stipulated timeline.isher Report, Form etc.\n",
      "\n",
      "Processing text:\n",
      "Team lead activities like resource planning and management, quarterly appraisal discussion, estimations and reporting etc.as per the requirements.l as Hierarchy roll-ups for specific trees. It has a workflow mechanism that automatically routes the request through various approval channels based on pre-defined rules. The system holds mappings between Book data in GBM and more than 50 transaction systems that are connected with GBM. The primary use of GBM is to serve as a Golden Source of information for all books and related attributes which originates from GBM defined across all applications globally.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Having 4.6 years of experience in PeopleSoft application enhancement, implementation, Data conversion, Support and Upgrade projects. Well experienced on People tools and having Functional knowledge HCM and FSCM Applications.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Bachelor of Technology (B-Tech) from JNTU-K\n",
      "   Currently Working as a People Soft Consultant in Randstad, Hyderabad\n",
      "\n",
      "\n",
      "PeopleSoft Consultant – Randstad, Hyderabad, Andhra Pradesh, India (June 2020 to till date)\n",
      "Project:  Randstad (Enhancements)\n",
      "Client:    Randstad Staffing \n",
      "Responsibilities:\n",
      "Analyze the requirement documents to understand the customer business requirement.\n",
      "Provide the technical approach for each FDD assign me.\n",
      "Customize the system applications and designed many objects from scratch.\n",
      "Write people code to implement the business logic.\n",
      "Design custom Application engine programs to process the data.\n",
      "Design Application engine programs to send notifications.\n",
      "Responsible to prepare unit test cases and technical design documents.\n",
      "Responsible to support SIT and UAT.\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code, Component Interface, Application Packages), PeopleSoft HCM, Oracle, Windows.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technical Associate – Verizon, Hyderabad, Andhra Pradesh, India (Dec 2018 to May-2020)\n",
      "Project:  Verizon Wireless (Development)\n",
      "Client:    Verizon\n",
      "Responsibilities:\n",
      "Analyze the requirement documents to understand the customer business requirement.\n",
      "Provide the technical approach for each FDD assign me.\n",
      "Customize the system applications and designed many objects from scratch.\n",
      "Write people code to implement the business logic.\n",
      "Design custom Application engine programs to process the data.\n",
      "Design Application engine programs to send notifications.\n",
      "Implemented component interface program to load data into people soft.\n",
      "Used file layout in inbound programs.\n",
      "Responsible to prepare unit test cases and technical design documents.\n",
      "Responsible to support SIT and UAT.\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code, Component Interface, Application Packages), PeopleSoft FSCM 9.1, Oracle, Windows.\n",
      "\n",
      "\n",
      "Software Engineer – HSBC, Hyderabad, India (Aug 2016 to Nov 2018)\n",
      "Project:  HSBC (Upgrade Project)\n",
      "Client:    HSBC Bank\n",
      "Responsibilities:\n",
      "Analysis and Understand the Source and Target system business process.\n",
      "Compare the objects between source and targets and identify the changes.\n",
      "Retrofit all the objects based on compare reports.  \n",
      "Unit testing and prepare unit Test cases on each retrofit.\n",
      "Design and Development new modifications required by customer.\n",
      "Prepared Technical design documents on each retrofit and enhancement.\n",
      "Add new text catalogues for various languages.\n",
      "Responsible for overseeing the Quality procedures related to the project. \n",
      "Responsible for move objects from Development to SIT Environment\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code), PeopleSoft HCM 9.1, DB2, Windows, UNIX.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Having 4.6 years of experience in PeopleSoft application enhancement, Support and Upgrade projects. Well experienced on People tools and having Functional knowledge HCM and FSCM Applications.\n",
      "\n",
      "\n",
      "\n",
      "Master of computer applications, Vinayaka Missions University, Chennai, Tamilnadu, India (3year program- 2010).\n",
      "\n",
      "Senior Consultant – Randstad, Hyderabad, Andhra Pradesh, India (June 2020 to till date)\n",
      "\n",
      "Project:  Randstad (Enhancements)\n",
      "Client:    Randstad Staffing \n",
      "Responsibilities:\n",
      "Analyze the requirement documents to understand the customer business requirement.\n",
      "Provide the technical approach for each FDD assign me.\n",
      "Customize the system applications and designed many objects from scratch.\n",
      "Write people code to implement the business logic.\n",
      "Design custom Application engine programs to process the data.\n",
      "Design Application engine programs to send notifications.\n",
      "Responsible to prepare unit test cases and technical design documents.\n",
      "Responsible to support SIT and UAT.\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code, Component Interface, Application Packages), PeopleSoft HCM, Oracle, Windows.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sr. Technical Associate – Verizon, Hyderabad, Andhra Pradesh, India (Dec 2018 to May-2020)\n",
      "\n",
      "Project:  Verizon Wireless (Development)\n",
      "Client:    Verizon\n",
      "Responsibilities:\n",
      "Analyze the requirement documents to understand the customer business requirement.\n",
      "Provide the technical approach for each FDD assign me.\n",
      "Customize the system applications and designed many objects from scratch.\n",
      "Write people code to implement the business logic.\n",
      "Design custom Application engine programs to process the data.\n",
      "Design Application engine programs to send notifications.\n",
      "Implemented component interface program to load data into people soft.\n",
      "Used file layout in inbound programs.\n",
      "Responsible to prepare unit test cases and technical design documents.\n",
      "Responsible to support SIT and UAT.\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code, Component Interface, Application Packages), PeopleSoft FSCM 9.1, Oracle, Windows.\n",
      "\n",
      "Senior Software Engineer – HSBC, Hyderabad, India (Aug 2016 to Nov 2018)\n",
      "\n",
      "Project:  HSBC (Upgrade Project)\n",
      "Client:    HSBC Bank\n",
      "Responsibilities:\n",
      "Analysis and Understand the Source and Target system business process.\n",
      "Compare the objects between source and targets and identify the changes.\n",
      "Retrofit all the objects based on compare reports.  \n",
      "Unit testing and prepare unit Test cases on each retrofit.\n",
      "Design and Development new modifications required by customer.\n",
      "Prepared Technical design documents on each retrofit and enhancement.\n",
      "Add new text catalogues for various languages.\n",
      "Responsible for overseeing the Quality procedures related to the project. \n",
      "Responsible for move objects from Development to SIT Environment\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code), PeopleSoft HCM 9.1, DB2, Windows, UNIX.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      " \n",
      "\n",
      "CAREER OBJECTIVE\t\t\n",
      "\n",
      "Pursuing Peoplesoft Executive role, having an overall experience of 3.6 Years in Financial Supply Chain Management and processes include Modification, Testing, and Supporting in PeopleSoft FSCM modules.\n",
      "\n",
      " PROFESSIONAL SKILL\t\t\n",
      "\n",
      "Functional: Purchasing, Inventory, Billing, Sound knowledge Account Payable, Sound knowledge in Peoplesoft Security\n",
      "Technical: PS Query, Basic knowledge in Peoplesoft Security, Application Designer, Peoplecode, SQL\n",
      "TOOLS: People Tools, ORACLE SQL Developer\n",
      "Database: ORACLE\n",
      "\n",
      "PROFESSIONAL SUMMARY\n",
      "Project # 1\n",
      "Module:   Accounts Payables \n",
      "Client\t: Accounts Team Aptara \n",
      "\n",
      "Role\t: Developer\n",
      "Technologies Used\t: Crystal Reports, People Tools, Application Designer, Reporting Tools\n",
      "\n",
      "\n",
      "Application Designer: By using this tool we have created page which contains run control record and that page add in the component and register the component so that its reflected in the PIA(pure internet architecture)\n",
      "People Tools:          we have created a permission list by the help of people Tools and that permission                list to a separate role so that selected user can access the page.\n",
      " we have also created a process to run the crystal through this tools so that the output will visible through process monitor.\n",
      "Reporting Tools:      we have created PS queries by the help of Reporting Tools for main report and for sub report in the crystal report.\n",
      "Crystal Reports:      by this tool we can used the PS queries, formula fields, running Total fields to get the required output\n",
      "\n",
      "Project # 2\n",
      "Module:   Purchasing\n",
      "Client\t: Admin Team\n",
      "\n",
      "Role\t: Developer\n",
      "Technologies Used\t: People Tools\n",
      "\n",
      "As for the client requirement for requisition purpose we have to create a new origin for admin so that any requisition raise through that origin it’s only for Admin purpose.\n",
      "to get the requisition approval flow for admin we have created the origin for admin and add that origin in the route control profile by the help of People Tools. And that route control profile\n",
      "added in the approver user ids to get the work done.\n",
      "\n",
      "\n",
      ".\n",
      "• Tracking the Defects to Closure and Defects Verification.\n",
      "• Status meetings with Client.\n",
      "• Creating Peoplesoft User id as per the User requirement\n",
      "• creating Origin, route control profile, Roles for requisition.\n",
      "• Handling Requisition, Purchase Order, Receipt and Inventory related issue.\n",
      "• creating Billing specialist etc. as per the requirement from the user, also resolve the bug (e.g. if invoice not get printed etc.).\n",
      "• Handling journal error issues (e.g. its might be combo error, amount difference, open period error or zero line error)\n",
      "\n",
      "​FUNCTIONAL SUMMARY\n",
      "\n",
      "Oracle PeopleSoft Application (Finance) 8.9\n",
      "Modules Handled: Resource Management of FSCM\n",
      "Purchasing\n",
      "Inventory\n",
      "Billing\n",
      "Sound knowledge in Account Payable\n",
      "Sound knowledge of PeopleSoft security\n",
      "\n",
      "TECHNICAL SUMMARY\n",
      "\n",
      "Primary Skills: PS Query, Application Designer (Field, Record, Page, Component, Menu), SQL\n",
      "Secondary Skills: Peoplecode\n",
      "TOOLS: People Tools, ORACLE SQL Developer\n",
      "Database: ORACLE\n",
      "\n",
      "EDUCATION\t\t\t\t\t\n",
      "B.Tech in Electrical and Electronics Engineering, Indus college of engineering, Biju Patnaik University of Technology, Orissa from0\n",
      "\n",
      "PERSONAL VITAE\n",
      "\n",
      "Date of Birth\t: 10th Jan 1991\n",
      "Languages \t: English, Hindi, Odia\n",
      "Nationality\t: Indian\n",
      "Gender\t\t: Male\n",
      ".\n",
      "\n",
      "DECLARATION\n",
      "\n",
      "I do hereby declare that the information given above is true and correct to my knowledge and belief.\n",
      "\t\t\t\t\t\t\n",
      "Date:                                         \t\t\t\t\t\t    \t    Priyabrata Hota.\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Done few customizations to delivered App Engine process AP-APY2015, which can be used for Create Payments for Vouchers.uirements.teract with On-site team to clarify requirements.\n",
      "\n",
      "Processing text:\n",
      "Tanna Sujatha \n",
      "\n",
      "\n",
      "\n",
      "OBJECTIVE\n",
      "Seeking a challenging role in the area of IT to work in an organization where I can utilize my functional knowledge to provide the best solutions to the business.\n",
      "\n",
      "PROFESSIONAL SUMMARY:\n",
      "\n",
      "Functional Expertise in the below PeopleSoft Finance modules\n",
      "Purchase\n",
      "Account Payables\n",
      "Experienced in working with Reporting tools like PS-query.\n",
      "End-End functional knowledge of AP & PO modules and handled various change requests from the user.\n",
      "\n",
      "SYNOPSIS\n",
      "Energetic and result oriented professional with 3.6 years of experience in IT. Extended expertise in PeopleSoft Financials 9.2 in the area of design, maintenance and production support. Deep understanding of technology with focus on delivering business solutions. Presently working as Sr. System Engineer\n",
      "Excellent decision-making skills with a positive approach.\n",
      "Dedicated and highly ambitious to achieve personal goals as well as the organizational goals.\n",
      "Ability to build new territories and expand opportunities towards the achievement of stated targets.\n",
      "\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "BTECH from KAUSHIK COLLEGE OF ENGINEERING, Visakhapatnam in 2015 with an academic percentage of 63%.\n",
      "\n",
      "PUC from NARAYANA junior college Visakhapatnam in 2011 with an academic percentage of 74.2%.\n",
      "\n",
      "S.S.C from ZP High School, BURJA in 2009 with an academic percentage of 71.1%.\n",
      "\n",
      "SOFTWARE PROFICIENCY\n",
      "\n",
      "PeopleSoft Functional:\tPurchase, Account Payables, Vendor Management\n",
      "Databases:\tOracle SQL Developer.\n",
      "Reporting Tools:\tPS Query \n",
      "\n",
      "WORK HISTORY\n",
      "Company: Datum Technologies                                                   (Mar’17-Present) \n",
      "Designation: Sr. System Engineer\n",
      "\n",
      "PROJECTS HANDLED\n",
      "\n",
      "Project- #1:\n",
      "(Jul’17 –Present)\n",
      "Project Name: Datum (PeopleSoft FSCM Maintenance and Support)\n",
      "Client:\tDATUM\n",
      "Role:\tSr. System Engineer\n",
      "Duration:\tJul’17– Present\n",
      "Team Size:\t6members\n",
      "\n",
      "Description:\n",
      "This is a maintenance and Production Batch Support project. Maintenance involves working on the tickets which needs customization, Setup and enhancements for creating or modifying the PeopleSoft objects. Production support involves monitoring the batch jobs scheduled.\n",
      "Roles and Responsibilities:\n",
      "Monitoring of Batch jobs and resolving the job failures on time.\n",
      "Unit testing and documentation as per organizational requirement.\n",
      "Documentation of process flow as per the business requirement.\n",
      "Involved in interactions with users for requirement/change gathering, UATs etc. Handling various requests from the user.\n",
      "\n",
      "\n",
      "PERSONAL DETAILS\n",
      "Date of Birth:\t1st July, 1994\n",
      "Languages:\tEnglish, Telugu\n",
      "Gender:\tFemale\n",
      "Marital Status:\tMarried\n",
      "Nationality\tIndian\n",
      "Present Address:\tPocharam, Hyderabad, Telangana, India.\n",
      "\n",
      "I hereby declare that the information furnished above is true to the best of my knowledge.\n",
      "\n",
      "Sujatha Tanna\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "C O N T A C T :\n",
      "\n",
      "Address: Manyata Tech Park,\n",
      "Nagavara, Bangalore 560045\n",
      "\n",
      "LinIn: subha-santosh-b16698139\n",
      "\n",
      "S K I L L S :\n",
      "\n",
      "PeopleSoft Finance FSCM ARIBA\n",
      "JAVA Full Stack Development SQL\n",
      "Power BI\n",
      "\n",
      "I N T E R E S T S :\n",
      "\n",
      "Learning new Technologies. Planting Hybrid Species.\n",
      "Cooking. Travelling Singing.\n",
      "\n",
      "S T R E N G T H S :\n",
      "\n",
      "Time Management. Responsible for my deliverables.\n",
      "Leadership qualities.\n",
      "\n",
      "L A N G U A G E S :\n",
      "\n",
      "Japanese.\n",
      "French (Started Learning).\n",
      "SRI SUBHA SANTOSH KUMAR JOSYULA\n",
      "A S S O C I A T E C O N S U L T A N T\n",
      "P R O F E S S I O N A L S U M M A R Y :\n",
      "\n",
      "I am having more than 3.2 years of experience in assistance and development for projects like ARIBA and PEOPLESOFT FINANCE . I have successfully completed TOOLS PATCH and TOOLS UPGRADE PROJECT with 0% refuse validations. I am the main Point of contact in Non Regression Testing and User Acceptance Testing. I am responsible to find solutions which makes customer satisfaction.\n",
      "\n",
      "W O R K E X P E R I E N C E :\n",
      "\n",
      "ASSOCIATE CONSULTANT\n",
      "CapGemini - AXA | June 2018 - Till Date\n",
      "Working on modules like Accounts Payable. Accounts Receivable and General Ledger, Expenses, User Profile Self Service (USS), Security along with Application Designer and SQL server .\n",
      "Organised customer information and account data for business planning and customer service purposes.\n",
      "Received 97% positive customer survey results. Worked on People Code and Packaging activities.\n",
      "Successfully monitored the Process Monitoring for failed jobs.. Collectively worked with the team to maintain 100% SLA. Developed and implemented many JAVA scripts to make the changes as per client's requirement.\n",
      "\n",
      "\n",
      "E D U C A T I O N :\n",
      "\n",
      "BACHELOR OF TECHNOLOGY, ELECTRONICS AND COMMUNICATION\n",
      "Vishnu Institute of Technology - JNTUK | 2014 - 2018 Average : 75%\n",
      "\n",
      "\n",
      "A W A R D S A N D\n",
      "C E R T I F I C A T I O N S :\n",
      "\n",
      "Basic Certified Power BI Desktop Manager - Coursera 2021 Agile Software Development - 2021\n",
      "Rising Star Award -CapGemini - Q4-2020\n",
      "BEST TEAM AWARD | PeopleSoft Finance Team  | 2019 and 2020\n",
      "OCA-8 JAVA DEVELOPER\n",
      "Microsoft Office Specialist.\n",
      "Japanese Language Basic Certification.\n",
      "\n",
      "Processing text:\n",
      "Name: Ravali P \n",
      "\n",
      "                                                                             Curriculum Vitae \n",
      "                                          Specialization: BE (computer science and Engg)   \n",
      "\n",
      " \n",
      "To utilize my technical skills for achieving the target and developing the best performance in organization. \n",
      " \n",
      " \n",
      "\n",
      " \n",
      " \t \n",
      " \n",
      "MANUAL TESTING SKILLS \n",
      " \n",
      "   Strong knowledge in SDLC concepts. \n",
      "   Extensive knowledge in White Box Testing. \n",
      "   Good knowledge in Functional testing, Integration testing, \n",
      "   Extreme Knowledge on System Testing \n",
      "   Good knowledge in Adhoc Testing, Reliability testing.    Good Knowledge on Exploratory Testing    Good knowledge in STLC concepts. \n",
      "   Good knowledge in Test cases and Test scenarios. \n",
      "   Good knowledge in globalization testing, compatibility testing.    Through Knowledge on Regression Testing    Good  knowledge in Test plan.\n",
      " \n",
      "   \n",
      "     AGILE METHDOLOGY \n",
      " \n",
      "   Good knowledge on Scrum Methodology.    Expertise in Sprint Planning Meeting. \n",
      "   Good knowledge on Scrum Meeting \n",
      "   Extreme knowledge on Sprint Retrospective Meeting \n",
      "   Good knowledge on Product Backlog Meeting and Bug Triage Meeting. \n",
      "   Extreme Knowledge on Normalization \n",
      " \n",
      " \n",
      " \n",
      "JAVA SKILLS \n",
      " \n",
      "   Good knowledge on Method Overloading and Method Overriding. \n",
      "   Good understanding on Static and NonStatic. \n",
      "   Good understanding on Variables. \n",
      "   Good knowledge on Constructor. \n",
      "   Good knowledge in Abstraction. \n",
      "   Good knowledge in Encapsulation. \n",
      "   Good knowledge in Inheritance. \n",
      "   Good knowledge in Collections. \n",
      " \n",
      " \n",
      " \n",
      " \t \n",
      " \n",
      " \n",
      "TRAINING OR COURSES:- \t \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      "     \n",
      "  INDUSTRIAL EXPOSURE:- \t \n",
      " \n",
      " ACHIEVEMENTS:- \t \n",
      "     \t  I’m certified in ‘Cyber Security’ Training at SJBIT in Bengaluru \n",
      "     \t  I’m certified in Volleyball Olympics in Distict level  \n",
      "      ASSIGNEMENTS \n",
      " \n",
      "   I have identified 100 Functional Test cases on Flipkart.com \n",
      "   I have identified 200 Integration Test cases on WhatsApp \n",
      "   I have identified 200 Integration Test cases on  Amazon.com \n",
      "   I have found 100 defects while doing FT, Usability, Camaptibility, Globalization Testing \n",
      " \n",
      " STRENGTHS \n",
      " \n",
      "\n",
      " \n",
      "DATE OF BIRTH:                                     04/11/1995 \n",
      " \n",
      "GENDER:                                                     Female              \n",
      "FATHER NAME:                                     Fasala Reddy N \n",
      "LANGUAGES KNOWN:                         English, Telugu,Kannada,Hindi \n",
      " \n",
      " \n",
      "NATIONALITY:                                        Indian. \n",
      " \n",
      "ADDRESS:                                                 Thirumaladevarahalli(v),Parthihalli(p)                                                                Kodigenahalli(H),Madhugiri(T),Tumkur(D)                                                           state: Karnataka \n",
      " \n",
      "\n",
      " \n",
      "I hereby declare that all the above-mentioned information is true to the best of my knowledge. \n",
      "                                                                                                                                              \n",
      "                                                                                                                                             Your’Sincerely \n",
      "                                                                                                                                                    Ravali P                                               \n",
      "Place: Bangalore                                                                                          \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \t \n",
      "\n",
      "Processing text:\n",
      "  \n",
      "SUSOVAN  BAG   \n",
      "Seeking  a  challenging  position  in  the  field  of  science  and  technology  to  utilize  my  skills  for  organization  and  individual  growth  and  to  enhance  my  knowledge  from  my  academic  learning  to  give  my  best  to  the  organization.   \n",
      "  \n",
      "SKILLS  \n",
      "CCNA -   Routing  &  Switching  subnetting  \n",
      "Programming:  C,   C++,Java,  HTML,CSS,  SQL   \n",
      "  \n",
      "OOPS,  Algorithms,  Data  Structures,DBMS,  Networking  \n",
      "\tOS  (Linux): Linux \t  System  Administration  with  Troubleshooting  \n",
      "  \n",
      "SOFT  SKILLS  \n",
      "\t Leadership, \t  Collaboration,  Good  communication  and  customer  Handling  skills.  \n",
      "   \n",
      "LANGUAGES  \n",
      "\t  English(Fluent), \t  Hindi(Fluent),  Bengali(Native),  Telugu  \n",
      "  \n",
      "  \n",
      "PROJECTS   \n",
      "  \n",
      "SMART  AGRICULTURE   \n",
      "Built  a  product  for  farmers  using  IoT  as  a  solution     \n",
      "AUTOMATIC  WATER  MOTOR  CONTROLLER  (2019 -   2020)    \n",
      "IoT,  android  and  API  technologies  combined  to  automate  work  of  water  motor  controllers  using  sensors.   \n",
      "  \n",
      "BOOKSTORE  MANAGEMENT  INTERFACE: C PP  (2018  -  2019)    \n",
      "Manage  the  purchase  and  return  of  books  in  a  books  store.    \n",
      "HOTEL  MANAGEMENT  SYSTEM(DEC - 2018)  \n",
      "Designed  a  front  end  module  for  the  hotel  management  system  website  using  HTML,CSS  .  \n",
      "  \n",
      "ONLINE  MOVIE  TICKET  BOOKING    \n",
      "Designed  a  fully  functioning  website  using  HTML,CSS,Javascript.`  \n",
      "  \n",
      "EDUCATION  BACKGROUND   \n",
      "\tLovely  Professional  University \t Punjab, \t  India.  \n",
      "B-Tech  in  computer  science  and   Engineering                                                                        7.22  gpa,  2020.    \n",
      "\t   HOBBIES :Web  Surfing,  Cricket,Carrom,Chess .  \t  \n",
      " \t  \t  \n",
      "/\n",
      "/\n",
      "\n",
      "Processing text:\n",
      "Kanumuru Deepak Reddy\n",
      "\n",
      "\n",
      "\n",
      "CAREER OBJECTIVE:\n",
      "\n",
      "To secure a position in a reputed organization where I can efficiently contribute my knowledge and skills to the growth of the organization and build my professional career.\n",
      "\n",
      "ACADEMIC QUALIFICATIONS:\n",
      "\n",
      "\n",
      "\n",
      "PROJECT:\n",
      "\n",
      "Title\t:Density based Traffic Control System USING ARDUINO.\n",
      "\n",
      "Duration:4 months.\n",
      "\n",
      "Description: Traffic congestion is a severe problem in most of the cities across the world and it has become a nightmare for the citizens. It is caused by delay in signal, inappropriate timing of traffic signalling etc. The delay of traffic light is hard coded and it does not depend on traffic. Therefore, for optimising traffic control, there is an increasing demand in systematic quick automatic system. This project is designed to develop a density based dynamic traffic signal control. The signal timing changes automatically on sensing the traffic density at the junction. The microcontroller used in this project is ARDUINO. The system contains IR sensors & ultrasonic sensors (transmitter and receiver) which will be mounted on the either side of the road on poles. It gets activated and receives the signal as the vehicles passes close by it.\n",
      "\n",
      "EXPERIENCE:                                        \n",
      "  \n",
      "I am carrying an experience of  2 years  from MetroLabs Services Pvt Ltd.\n",
      "\n",
      "   ROLES AND RESPONSIBILITIES :\n",
      "\n",
      "Over 2 years of extensive experience as a Front End Developer with solid understanding of website and application designing, development of different modules using ReactJS.\n",
      "Professional understanding of Software development life cycle (SDLC) as well as various phases such as Analysis Design, Development and Testing.  \n",
      "\n",
      "\n",
      "Experienced in developing User Interface using HTML5, CSS3, Bootstrap, JavaScript,  DOM, ReactJS.\n",
      "\n",
      "\n",
      "Experience in DOM as I used it in interacting with objects in HTML documents.  \n",
      "\n",
      "Experience in working with Express creating Restful API, URL routing, creating and handling HTTP CRUD \n",
      "\n",
      "Good experience in using React JS components, Forms, Events, Keys, Router, Redux Store, action creator and reducer etc.\n",
      "\n",
      "Good experience in developing draggable grid layout using react-grid-layout package.\n",
      "\n",
      "Good knowledge on building tables/grid using react-table and ag-grid library and office-fabric-ui.  \n",
      "\n",
      "Experience in maintaining APIs and existing applications.\n",
      "\n",
      "Write code that is cross-platform and cross-device compatible.\n",
      "\n",
      "Converted PSD files into pure hand-written HTML and CSS pages \n",
      "Effectively represent the voice of the user to influence and improve design decisions\n",
      "Consult with the cross-functional team throughout development, testing, and rollout to ensure designs are understood, implemented, and communicated appropriately\n",
      "Website hosting is one of the major role in my working period and according with client modifications, deletions etc.\n",
      "\n",
      "Good communication skills, both verbal and written.\n",
      "\n",
      "TECHNICAL EXPERTISE:\n",
      "\n",
      "Web Technologies   \t:  Html5, Css3, JavaScript, Responsive Designs,\n",
      "  Bootstrap, ReactJS, JSON\n",
      "  \n",
      "Development Tools \t:   Visual Studio Code\n",
      "Operating Systems   \t:  Windows 10\n",
      "\n",
      "PERSONAL DETAILS:\n",
      "\n",
      "Date of Birth\t:\t15, August,1997.\n",
      "Father’s Name\t:\tMr. K.Sudhakar Reddy,\n",
      "Permanent Address\t:\tH.no:5-8-171/3, Bmr Nagar, Naidupet.\n",
      "Languages known\t:\tTelugu, Hindi & English.\n",
      "Hobbies\t:\tPlaying cricket, Watching news.\n",
      "\n",
      "STRENGTHS:\n",
      "\n",
      "Punctuality\n",
      "Positive attitude\n",
      "Leadership\n",
      "Teamwork\n",
      "\n",
      "LANGUAGES KNOWN:\n",
      "\n",
      "Telugu\n",
      "Hindi\n",
      "English\n",
      "\n",
      "\n",
      "\n",
      "DECLARATION:\n",
      "\n",
      "I hereby declare that all the above mention details are true to best my knowledge.\n",
      "\n",
      "\n",
      "\n",
      "Place:\n",
      "Date:\t\t\t\t\t\t\t\t\t\tK.Deepak Reddy\n",
      "\n",
      "Processing text:\n",
      "HARIPRIYA BATTINA \n",
      "Experience as UI Developer in Reactjs, JavaScript. \n",
      "Phone: +91 9908576950 \n",
      "Gmail: haripriyabattini@gmai.com \n",
      "Location: Visakhapatnam \n",
      "JOB OBJECTIVE ● Looking for a challenging role to put my experience in various aspects of technology with an objective to be a leading source of information and guidance concerning th\n",
      "technological requirements. \n",
      "● Want to be a part of a reputed organization that allows me to effectively use my \n",
      "technical skills in the real world for overall growth of organization and my \n",
      "professional career. \n",
      "WORK EXPERIENCE EDUCATION \n",
      "1. Associate UI Developr \n",
      "Company: Blue Yonder, Hyderabad. \n",
      "● Work Done On “COPERNICUS” Project. \n",
      "● The Main Moto of this project is, it is GTM (Go To Market) Portal which is specially designed for demo teams to shower case Blue Yonder Products and Features for Customers and Partners \n",
      "● Technologies: HTML, CSS, React JS. \n",
      "● IDE: VS Code. \n",
      "● Methodologies: Agile. \n",
      "JOB RESPONSIBILITIES: \n",
      "● Involved Designing in Web Pages using HTML, CSS, JavaScript, React JS. ● Actively Handling the user stories raised through JIRA Tool. \n",
      "● Analyzing the stories by going through the application, Identifying the solution and also providing the functionalities. \n",
      "● Used JIRA as the bug tracking system to track and maintain the history of bugs on an everyday basis. \n",
      "● B.Tech in Information technology from Anil Neerukonda Institute of Technology and Sciences (Affiliated to Andhra University), Visakhapatnam, in the year 2018 with 6.7 CGPA. \n",
      "● Intermediate in MPC from NRI junior college, Visakhapatnam, in 2014 with a percentage of 72.2%. \n",
      "● SSC from A.P.S.W.R school Pedapadu, Srikakulam in 2012 with CGPA 7.8.\n",
      "ACADEMIC PROJECT \n",
      "TECHNICAL SKILLS STRENGTHS \n",
      "ACHIEVEMENTS DECLARATION \n",
      "Project name : ONLINE RESTAURANT RESERVATION SYSTEM \n",
      "Project Duration : 3 months. \n",
      "Description : \"Online Restaurant Reservation System\" is a web application. This system is developed to automate day to day activities of restaurants. It is a kind of business that serves the people all over the world with ready food. \n",
      "Technology used : java, HTML, MYSQL \n",
      "● Programming Languages : C, Reactjs, JavaScript, SQL Server. \n",
      "● Software Packages : MS Office. \n",
      "● Web Technologies : HTML, CSS. \n",
      "● Operating System : Windows, Ubuntu. \n",
      "● Positive attitude. \n",
      "● Believe in punctuality \n",
      "● Teamwork \n",
      "● Responsible towards work \n",
      "● Extended my services as poster Coordinator in the RADIAN 2k18 event. ● Extended my services in coordinator in farewell day 2018 \n",
      "Isolely declare that the above-mentioned facts are true to the best of my knowledge. Date: ……………………… \n",
      "Place: Hyderabad. (Hari priya B)\n",
      "\n",
      "Processing text:\n",
      "KAMALAKAR REDDY. A \n",
      "Linked In: https://www.linkedin.com/in/kamalakar-reddy-777682196/ \n",
      "PROFESSIONAL SUMMARY \n",
      "● 3 years of experience in UI Development of Enterprise Applications, Web Applicationsrelated technologies. \n",
      "● Experience in Development, Coding, Maintenance,Design, Implementation of Web applications using HTML5, CSS3, JavaScript, j Query, React JS, Redux. \n",
      "● Well versed in designing websites, Web Applications. \n",
      "● Well versed in different Project Management Tools e.g. JIRA, GIT, Bit bucket. ● Tested cross browser design issues and fixed major layout bugs for supported browsers. ● Self-motivated with good communication and interpersonalskills. \n",
      "● Ability to work independently and multitasking without negative impact to timelines orquality. \n",
      "WORK EXPERIENCE \n",
      "MARCH 2021 – TILL DATE \n",
      "ROLE : : UI DEVELOPER \n",
      "ENLUME TECHNOLOGIES, HYDERABAD. \n",
      "AUGUST 2018 – MARCH 2021 \n",
      "ROLE : SOFTWARE ENGINEER \n",
      "FORTUNAPIX PRIVATE LIMITD, HYDERABAD. \n",
      "PROJECTS \n",
      "TITLE : Monarch Tractor \n",
      "DESCRIPTION: Monarch Tractor impacts the environment exactly as intended, without side effects. This Application helpful for farmers to get tractor alerts, updates on weather conditions, Analysis, Data collection. MT platform acts as a full data collection and analysis suit. TECHNOLOGIES: HTML, Css3, Bootstrap, React Js, JavaScript. \n",
      "TITLE : lernbook \n",
      "DESCRIPTION: Fortunapix works for Digitalization of schools by providing modern digital education system in Govt. schools of Antigua and Barbuda, and Caribbean islands. This project digitalize and animates the education content for different grades in a school. \n",
      "TECHNOLOGIES: Html, Css3, React Js, Bootstrap, Jqery. \n",
      "url: http://demo.fortunapix.com/kkel/\n",
      "EDUCATION \n",
      "2017 - 2018 \n",
      "WEB DESIGNING & DEVELOPMENT COURSE \n",
      "AT ARENA ANIMATION DILSUKNAGAR, HYDERABAD. \n",
      "2010 - 2013 \n",
      "BACHELOR OF COMPUTERS \n",
      "AT G.PULLAREDDY DEGREE & PG COLLEGE, HYDERABAD. \n",
      "TECHNICAL SKILLS \n",
      "JAVASCRIPT LIBRARYS : ReactJs, Redux. \n",
      "CSS FRAMEWORK : Bootstrap. \n",
      "ENVIRONMENT : Photoshop, Visual Studio. \n",
      "WEBTECHNOLOGIES : HTML 4, CSS3, Sass. \n",
      "OPERATINGSYSTEMS : Windows, Mac, Ubuntu. \n",
      "SCRIPTINGLANGUAGES : JavaScript, jQuery. \n",
      "METHODOLOGIES : Agile. \n",
      "ACTIVITIES & INTERESTS \n",
      "∙ Cooking \n",
      "∙ Playing Cricket \n",
      "∙ Listening Music \n",
      "∙ Other Social Activities \n",
      "PERSONAL PROFILE \n",
      "FATHER’SNAME : MURAHARI REDDY. A \n",
      "GENDER : Male \n",
      "MARITALSTATUS : Single \n",
      "NATIONALITY : Indian \n",
      "KNOWN LANGUAGES : Telugu, English, and Hindi. \n",
      "LOCATION : Madhapur, Hyderabad \n",
      "DECLARATION \n",
      "I do hereby declare that all the above information furnished by me are true and correct to the best of my knowledge. \n",
      "Place : Hyderabad (KAMALAKAR REDDY .A) Date :\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Naveen Sadhu\n",
      "\n",
      "\n",
      "Title: software developer\t\t\t\t                  \n",
      "Location: Hyderabad, India\t\t\t                                \n",
      "\n",
      "Professional Summary\n",
      "1 year of overall IT experience in Html, Sql, Reactjs and Nodejs.\n",
      "Experience in working with Application development and testing tool\n",
      "Hard working and enthusiastic.\n",
      "Excellent communication, interpersonal, analytical skills, and strong ability to perform as part of team.\n",
      "Exceptional ability to learn new concepts.\n",
      "\n",
      "Education\n",
      "Bachelor of Technology in Computer Science and Engineering from Marri Laxman Reddy Institute of Technology and Management (Affiliated to JNTUH).\n",
      "Skills\n",
      "\n",
      "Professional Experience\n",
      "Current Project \n",
      "Client\t\t  : Inline4, USA\n",
      "\n",
      "Organization     : Edvenswa tech Pvt. Ltd\n",
      "\n",
      "Technology\t  : MERN stack, HTML,CSS,BOOTSTRAP\n",
      "\n",
      "Description\n",
      "\n",
      "The project goal is to provide whenever the user wants to do servicing for his bike he can go directly to this application and he can book slot for his bike servicing. Why because whenever the customer is in problem he can directly book the service so that the service provider will take the bike for servicing..\n",
      "\n",
      "\n",
      "Contribution\n",
      "Understand and implement the features \n",
      "Negotiate scope and resolving conflicting priorities.\n",
      "Translate requirements into meaningful stories that the team can deliver against.\n",
      "Application deployment.\n",
      "Developed the optimized code as per the requirement.\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal Details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Yours sincerely  \n",
      "            (Naveen Sadhu)\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "PC buildingg Sci-Fi movies \u0001   Gamingearn. \u0001   Leadership qualities and team spirit.ibre optics.wireless LAN and broadcasting. Using MATLAB, simulation of wireless channel modelling, MIMO channel modelling, MIMO channel capacity, PAPR reduction techniques are presented.ons to their client. a spring boot based on the REST-API endpoint. The React.js application consumes it with the help of AG Grid shown using beautiful UI.\n",
      "\n",
      "Processing text:\n",
      " \n",
      "PRAGNYA PATTNAIK\n",
      " \n",
      " \n",
      " \n",
      " Expertise: \n",
      " \n",
      "Having around 2 years of experience in UI development using Html5, CSS3, JavaScript, Bootstrap, React JS. \n",
      "Good knowledge in Java Script, JQuery, Ajax, React JS, TypeScript, Angular 10. \n",
      "Working on AGILE METHODOLGY\n",
      "Flexible to every Environment, Honest and believe in Hard work. \n",
      "Good Communications and Analytical skills. \n",
      "Maintain focus on high quality deliverables while working under pressure in Production environment. \n",
      "Management of the ticketing system on the production environment and resolution of the tickets with different priorities with appropriate solutions. \n",
      "Excellent interpersonal communicator and focused on building strong client/customer relationships. \n",
      "Proven ability to work efficiently in both Independent and team work environments. \n",
      "Ability to work optimally under scheduled deadlines and deliver high quality output. \n",
      " \n",
      "Technical Skills: \n",
      " \n",
      " \n",
      " \n",
      " Educational Profile: \n",
      " \n",
      "MCA from IGNOU (Indira Gandhi National Open University) 2018, Odisha. \n",
      " \n",
      "   Working Profile: \n",
      " \n",
      "Working as a Web Developer for Smart Edge India Pvt Ltd, (November 2019 to till date). \n",
      "\n",
      " \n",
      " Professional Experiences: \n",
      "\n",
      "Project 1: \n",
      " \n",
      "Project Description:- \n",
      "Golden amoon is a resort and hotel. They provides services for hotel booking, spa, conventional centre and conference hall booking system. Customers can check the availability for all services through web as well as in mobile. They can give their payment through online payment by internet banking, Debit card or in Credit Card. We developed both web and android based application which can help customers to get the services features easily and make client also for doing profitable business. \n",
      "Responsibilities: \n",
      "Understanding requirements. \n",
      "Working on UI implementation for the customers. \n",
      "Customizing React JS .\n",
      "Developed the front-end web page by using HTML5, CSS3, Bootstrap and  JQuery. \n",
      "Created CSS Websites Compatible of Google Chrome. \n",
      " \n",
      " Project 2: \n",
      "\n",
      "Project Description:- \n",
      "G2evolution is a service based company. They provide services for School Management, Ecommerce, Business Consulting, Mobile App Development, Search Engine Optimization (SEO). \n",
      "Responsibilities: \n",
      "Conversion of PSD designs into HTML5 (Responsive layouts). \n",
      "Involved in fixing the issues. \n",
      "Designing Attractive Layout. \n",
      "\n",
      "PERSIONAL DETAILS:\n",
      "\n",
      "             Name\t\t           :        PRAGNYA  PATTNAIK\n",
      "\tGender\t\t           :        Female\n",
      "\tNationality\t           :        Indian\t\n",
      "\tLanguages known       :         English & Hindi & ODIYA\n",
      "\t\n",
      "(I hereby declare that the above written particulars are true to the best of my knowledge and belief)\n",
      "\n",
      " \n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      " 204,Sri geethika prestige,road number 10,bandari layout,nizampet,Hyderabad,500090.\n",
      "\n",
      "Having 3 years of experience in developing UI-Applications. ◉ Proﬁcient and excellent hands on experience with JavaScript,HTML5,CSS3,Boostarp,React Js. ◉ Good knowledge in designing web pages using CSS3 and Bootstrap. ◉ Strong knowledge in using Object Oriented Programming concepts in JavaScript. ◉ Working knowledge of DOM models and Strong skills of usability and accessibility with HTML,CSS. ◉ Providing support to the UI Design team,form an UI architecture/frame works perspective. ◉ Experience in Boostarp (responsive web design),and React Js frameworks.. ◉ Experience in the Healthcare domain.Involved in all phases of the software development life cycle such as developing,integrating,Implementing and Debugging of web based. ◉ Excellent interpersonal abilities,communication skills,time management and team skills with an intention to work hard to meet project deadlines under stressful environment.\n",
      "\n",
      "Apr 2017 - Feb 2019\n",
      "Software Engineer\n",
      "Individual contributor responsible for designing front end applications using web technologies like HTML5,CSS3 and JavaScript.\n",
      "Responsible for creating Modules using react is,converting HTML into components.\n",
      "Responsible for creating responsive web pages using Bootstrap.\n",
      "\n",
      "\n",
      "\n",
      "Apr 2016 - Mar 2017\n",
      "Software Engineer\n",
      "Individual contributor responsible for completing assigned tasks on time and proactively taking up new tasks.\n",
      "Responsible for building optimized code using JavaScript and debugging for any issues.\n",
      "Understanding the software requirements speciﬁcation @project functionality.\n",
      "Responsible for designing reactive web pages using HTML and CSS.\n",
      "Responsible for doing research on new implementations and ﬁnding out if it ﬁts the current requirement.\n",
      "Participate in daily meetings and give day wise updates to the team.\n",
      "\n",
      "2011-2015\n",
      "Sri Krishna Devaraya College(JNTU)\n",
      "\n",
      "2009-2011\n",
      "\n",
      "Inter,MPC\n",
      "\n",
      "HTML5,CSS3,JavaScript,React js, Bootstrap.\n",
      "\n",
      "E-Services is the project initiated by GOA government.The E-Services portal aims to provide the facility for citizens to submit online forms for the services identiﬁed by the state to be delivered online and through Lok seva kandra(LSKs).\n",
      "\n",
      "\n",
      "\n",
      "CRM processes that help identify and target their best customers.Providing services and products that are exactly what your customers want.CRM processes that help from individualized relationships with\n",
      "Customers(to improve customer satisfaction)and provide the highest level of customer service to the most proﬁtable customers.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "Thirupathamma Balla\n",
      "\n",
      "SUMMARY:\n",
      "\n",
      "2.8 year of IT experience as React Developer. \n",
      "Worked on technologies like React, JavaScript. \n",
      "Experience in developing business applications for the Internet using React.\n",
      "Experience in Object Oriented Programming concepts. \n",
      "Strong Analytical Ability skills.\n",
      "Enthusiastic, eager to meet challenges and quick to learn and assimilate new   concepts and ideas.\n",
      "Ability to work efficiently, either independently or on a team with minimal supervision and without ever missing a deadline.\n",
      "Brief Profile\n",
      "\n",
      "Summary of Skills & Experience\n",
      "\n",
      "Work Experience\n",
      "\n",
      "Technical Skills:\n",
      "\n",
      "Languages \t\t:\tC.\n",
      "Web Technologies\t:\tReact, Bootstrap, Javascript and JSON.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Education\n",
      "\n",
      "\n",
      "\n",
      "Project Details\n",
      "\n",
      "\n",
      "\n",
      "Responsibilities   \t:\n",
      "Responsible to develop reusable React components\n",
      "Responsible for reviewing other developers' code as part of peer-code-review.\n",
      "Responsible to write unit test cases in React\n",
      "Responsible for testing the components in the staging server.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Thirupathamma Balla.\n",
      "\n",
      "Processing text:\n",
      "                                                                                                                                      Vinay Reddy     should register through signup page and login and order the raw materials. And who wants menu and what is Healthy Chef Creations just they can open the home page and see their details.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Ui-Developer/ React JS Developer \n",
      "NAME: KRISHNA \n",
      "PROFESSIONAL SUMMARY:\n",
      "Over all 3.2 years of Extensive experience as a React JS/Web- Developer and 1 year of Experience as React JS Software Developer.\n",
      "Extensive experience in developing web pages using HTML, XML, CSS, JavaScript, React JS, Redux, JSON.\n",
      "Experience in all phase of SDLC like Requirement Analysis, Implementation and Maintenance, and extensive experience with Agile and SCRUM.\n",
      "Extensive knowledge in developing single - page applications (SPAs).\n",
      "Good Expertise in analyzing the Document Object Model (DOM) Layout, DOM Functions, and Java Script functions, Cascading Styles across cross-browser using Fire Bug, Developer Tool Bar.\n",
      "Expertise in React JS framework to develop the SPA.\n",
      "Experienced in React JS and working with React Flux architecture.\n",
      "Experienced in working with redux architecture using complex Object-Oriented concepts in improving the performance of the websites.\n",
      "Experience in using React JS components, Forms, Events, Keys, Router, plus Redux, Animations.\n",
      "Expertise in video coding by using HTML5, CSS3 and JavaScript.\n",
      "Expertise in RESTful, SOAP web services to integrate between Application to Application\n",
      "Experience with front-end development with back-end system integration.\n",
      "TECHNICAL SKILLS:\n",
      "Web Technologies: HTML, CSS3, XML, JavaScript, JSON, React JS, Node.js, GitHub.\n",
      "\n",
      "QUALIFICATION:\n",
      "B-Tech from JNTU-Kakinada University - 2016\n",
      "PROFESSIONAL EXPERIENCE:\n",
      "I have experience as React JS Developer with 3.2 years of experience in the IT Industry and currently working in BOSCH.\n",
      "Current Project: AGSP (Auto Guar age Solution Project)\n",
      "Role: UI Developer/ React JS Developer\n",
      "Responsibilities:\n",
      "Design, develop and test HTML5, CSS3, Bootstrap, JavaScript and React.JS that meets accessibility and web browser standards for website.\n",
      "Developed user interface by using the React JS, Flux for SPA development. \n",
      "Used React-Router to turn application into Single Page Application\n",
      "Worked in using React JS components, Forms, Events, Keys, Router, Animations and Flux concept.\n",
      "Used React flux to polish the data and for single directional flow.\n",
      "Used Object Oriented Programming concepts to develop UI components that could be reused across the Web Application.\n",
      "Extensively used Git for version controlling and regularly pushed the code to GitHub.\n",
      "Used JIRA as the bug tracking system to track and maintain the history of bugs/issues on everyday basis.\n",
      " Environment: HTML5, CSS3, JavaScript, Bootstrap, React JS, Redux, JSON, Git hub, JIRA\n",
      "Previous Project:  SITE WORK PROJECT\n",
      "Role: UI Developer/ React JS Developer\n",
      "Responsibilities:\n",
      "Worked on an Agile (Scrum) Development Team to deliver regular updates to business team and project managers.\n",
      "Involved designing in web pages using HTML 5, CSS3, JavaScript, Bootstrap, React.js, Redux , \n",
      "Worked on React JS Virtual Dom and React views, rendering using components which contains additional components called custom HTML tags.\n",
      "Implemented various screens for the front end using React.js and used various predefined components from NPM (Node Package Manager) and redux library.\n",
      "Worked in using React JS components, Forms, Events, Keys, Router, Animations, and Flux concept.\n",
      "Responsible for React UI and architecture. Building components library, including Tree, Slide-View, and Table Grid.\n",
      "Implemented stable React components and stand-alone functions to be added to any future pages.\n",
      "Used React JS for tinplating for faster compilation and developing reusable components.\n",
      "Used React-Auto complete for creating Google maps location search on the webpage.  Environment: HTML5, CSS3, Bootstrap, GitHub and Jenkins.\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Ui-Developer/ React JS Developer \n",
      "NAME: KRISHNA \n",
      "\n",
      "PROFESSIONAL SUMMARY:\n",
      "Over all 3.2 years of Extensive experience as a React JS/Web- Developer and 1 year of Experience as React JS Software Developer.\n",
      "Extensive experience in developing web pages using HTML, XML, CSS, JavaScript, React JS, Redux, JSON.\n",
      "Experience in all phase of SDLC like Requirement Analysis, Implementation and Maintenance, and extensive experience with Agile and SCRUM.\n",
      "Extensive knowledge in developing single - page applications (SPAs).\n",
      "Good Expertise in analyzing the Document Object Model (DOM) Layout, DOM Functions, and Java Script functions, Cascading Styles across cross-browser using Fire Bug, Developer Tool Bar.\n",
      "Expertise in React JS framework to develop the SPA.\n",
      "Experienced in React JS and working with React Flux architecture.\n",
      "Experienced in working with redux architecture using complex Object-Oriented concepts in improving the performance of the websites.\n",
      "Experience in using React JS components, Forms, Events, Keys, Router, plus Redux, Animations.\n",
      "Expertise in video coding by using HTML5, CSS3 and JavaScript.\n",
      "Expertise in RESTful, SOAP web services to integrate between Application to Application\n",
      "Experience with front-end development with back-end system integration.\n",
      "TECHNICAL SKILLS:\n",
      "Web Technologies: HTML, CSS3, XML, JavaScript, JSON, React JS, Node.js, GitHub.\n",
      "\n",
      "QUALIFICATION:\n",
      "B-Tech from JNTU-Kakinada University - 2016\n",
      "PROFESSIONAL EXPERIENCE:\n",
      "I have experience as React JS Developer with 3.2 years of experience in the IT Industry and currently working in BOSCH.\n",
      "Current Project: AGSP (Auto Guar age Solution Project)\n",
      "Role: UI Developer/ React JS Developer\n",
      "Responsibilities:\n",
      "Design, develop and test HTML5, CSS3, Bootstrap, JavaScript and React.JS that meets accessibility and web browser standards for website.\n",
      "Developed user interface by using the React JS, Flux for SPA development. \n",
      "Used React-Router to turn application into Single Page Application\n",
      "Worked in using React JS components, Forms, Events, Keys, Router, Animations and Flux concept.\n",
      "Used React flux to polish the data and for single directional flow.\n",
      "Used Object Oriented Programming concepts to develop UI components that could be reused across the Web Application.\n",
      "Extensively used Git for version controlling and regularly pushed the code to GitHub.\n",
      "Used JIRA as the bug tracking system to track and maintain the history of bugs/issues on everyday basis.\n",
      " Environment: HTML5, CSS3, JavaScript, Bootstrap, React JS, Redux, JSON, Git hub, JIRA\n",
      "Previous Project:  SITE WORK PROJECT\n",
      "Role: UI Developer/ React JS Developer\n",
      "Responsibilities:\n",
      "Worked on an Agile (Scrum) Development Team to deliver regular updates to business team and project managers.\n",
      "Involved designing in web pages using HTML 5, CSS3, JavaScript, Bootstrap, React.js, Redux , \n",
      "Worked on React JS Virtual Dom and React views, rendering using components which contains additional components called custom HTML tags.\n",
      "Implemented various screens for the front end using React.js and used various predefined components from NPM (Node Package Manager) and redux library.\n",
      "Worked in using React JS components, Forms, Events, Keys, Router, Animations, and Flux concept.\n",
      "Responsible for React UI and architecture. Building components library, including Tree, Slide-View, and Table Grid.\n",
      "Implemented stable React components and stand-alone functions to be added to any future pages.\n",
      "Used React JS for tinplating for faster compilation and developing reusable components.\n",
      "Used React-Auto complete for creating Google maps location search on the webpage.  Environment: HTML5, CSS3, Bootstrap, GitHub and Jenkins.\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\u000b",
      "Date: \t\t\t\t\t\t\t\t(Anjani Priyadarshini)oned particulars are true to my knowledge.sign Guide lines. Developing and maintaining a project Plan. Working with mentor to ensure the project meets its business needs and delivery in time. and music taste, while we design our moto-marine products to be element ready solutions for marine audio, motorcycle audio and UTV audio systems.let, and desktop platforms.\n",
      "\n",
      "Processing text:\n",
      "Kotani Durga Prasad\n",
      "\n",
      "\n",
      "Objective:\n",
      "\n",
      "Aspirant for a position in an organization where I can contribute my skills for organization’s success and synchronize with new technologies while being resourceful, innovative and flexible.\n",
      "\n",
      "Professional Summary:\n",
      "3.1 years of experience as a Software Engineer.\n",
      "Highly creative web designer and front end developer with experience of working on a diverse range of projects from small business websites to large scale websites with a global user base.\n",
      "Excellent knowledge in HTML, HTML5, CSS3, Bootstrap frameworks. Strong hands on experience in hand coding web technologies.\n",
      "Good Knowledge in Designing & Developing the Web pages based on SEO (Search Engine Optimization), W3C Standards and Cross-Browser Compatibility.\n",
      "Very good knowledge in client side programming with JavaScript, jQuery. Working knowledge in React JS.\n",
      "Experience in developing fully Responsive Websites using media queries and flexible layouts.\n",
      "Ability to create pixel to pixel matching web pages.\n",
      "Unmatchable degree of creativity as well as technical production skills. Excellent verbal communication skills including the ability to convey ideas and information clearly, concisely and persuasively.\n",
      "Flexibility, good judgment and attention to the detail essential.\n",
      "Education Details:\n",
      "B.Tech (Computer Science Engineering) from Gudlavalleru Engineering College.\n",
      "Intermediate from Sri Chaitanya Junior College.\n",
      "High School from Viswakavi High School.\n",
      "Professional Experience:\n",
      "\n",
      "Working as Software Engineer in Amaravati Tech Services, Vijayawada from August 2018 to Till Date.\n",
      "\n",
      "Technical Skills:\n",
      "Key Skills:\tHTML5, CSS3, JavaScript, JQuery, Json, Bootstrap and Responsive Design.\n",
      "Frameworks:\tReact Js.\n",
      "OS:\tWindows\n",
      "Dev Tools:\tMicrosoft Visual Studios\n",
      "Oﬃce Tools:\tMicrosoft Oﬃce Suite, Edit Plus, NotePad++\n",
      "\n",
      "Projects:\n",
      "\n",
      "Agro Services:\n",
      "\n",
      "Description:\n",
      "\n",
      "This is E-commerce based Web Application. selling & buying agriculture equipment Pesticides, seeds. Providing these services to client.\n",
      "\n",
      "Role and Responsibilities:\n",
      "\n",
      "Used UI Router for implementing routing in the application.\n",
      "Implemented Validations using pre-defined Validations of React JS Framework. Implemented Validation by using Custom directives in React Js.\n",
      "Used Http services & Pagination. Have an overview, understanding about diﬀerent features of React JS like dependency injection, digest and apply web cycle, two-way data binding. Done curd operation using re-source services.\n",
      "Involved in development, design and implementation of front end part of the application.\n",
      "Developed the User Interactive web pages in a professional manner by using web technologies like HTML5, CSS3 as per company standards.\n",
      "Used Bootstrap and React JS in eﬀective web design. Responsible for creating the look and feel of the public website.\n",
      "Used Ajax, JSON with jQuery for request data and response processing. . Used broadcast, emit & on to share data between diﬀerent modules Interacting with customer along various phases of the project.\n",
      "\n",
      "UI Technologies Used\n",
      "\n",
      "HTML5, CSS3, JavaScript, Bootstrap, JQuery, React JS.\n",
      "\n",
      "My Map Tag:\n",
      "\n",
      "Description:\n",
      "\n",
      "My Map Tag connects people and places, by providing the fastest, easiest way to share directions that eliminate the wasted time and frustration of getting lost. It is an online Directory Service for identifying Places important to you (such as your home, oﬃce, business, etc.),   which is designed for mobile use and optimized to take advantage of the capabilities of smart phones. My Map Tags hold much more information about a Place than just the address. They include things like photos, special instructions, directional helps (such as landmarks and route guide lines), contact details, descriptive information, and of course the GPS coordinates that show you the exact location on a map. The Tags are private and secure and controlled by the Map Tag owner. Individual Map Tags are not accessible to anyone, unless authorized by owner.\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "HTML Development.\n",
      "Fixing alignment Issues and Creating Drop down menus using jQuery.\n",
      "\n",
      "UI Technologies Used:\n",
      "\n",
      "HTML5, CSS3, JavaScript, Bootstrap, JQuery\n",
      "\n",
      "Byron:\n",
      "\n",
      "Description:\n",
      "\n",
      "Byron vision is to serve proper hamburgers the way they should be. It started oﬀ in 2007 in London to do a simple thing well, and do it properly as there weren’t any restaurants oﬀering hamburgers like those at the Silver Top at that moment. Byron site shows menu information, including a price and description for each of the dishes, location information for restaurants in the chain, provide news and stories about the brand and the ability to sign up to receive marketing information from Byron.\n",
      "The site was built using the latest technology, with the experience on capable devices utilizing HTML5 transitions and functionality where needed. Where HTML5 functionality is  not  supported by the device the experience will be degraded to provide usability according to the device capabilities.\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "HTML Development\n",
      "Developing Drop down menus using jQuery\n",
      "Developing dynamic background using JQuery mobile.\n",
      "\n",
      "UI Technologies Used:\n",
      "\n",
      "HTML5, CSS3, JQuery.\n",
      "\n",
      "Personal Details:\n",
      "\n",
      "Nationality: Indian\n",
      "Sex: Male\n",
      "Marital Status: Unmarried\n",
      "Languages Known : English, Hindi, Telugu\n",
      "\n",
      "Declaration:\n",
      "\n",
      "I hereby declare that the information furnished above is true to the best of my knowledge and belief.\n",
      "\n",
      "Date:\n",
      "Place: Vijayawada\tK.Durga Prasad\n",
      "\n",
      "Processing text:\n",
      "Venkatalakshmi Pedireddy\n",
      "Software Developer\n",
      "Experience 3 Years\n",
      "\n",
      "\n",
      "Visakhapatnam, India\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WORK EXPERIENCE\n",
      "Developer\n",
      "Schemax Expert Techno Crafts Pvt. Ltd\n",
      "05/2018 - Present,\tVisakapatnam\n",
      "Achievements/Tasks\n",
      "Worked on both front end and back end\n",
      "Responsible for development and management of the project\n",
      "\n",
      "\n",
      "EDUCATION\n",
      "SSC\n",
      "Z. P. G. H. School\n",
      "08/2011 - 03/2012,\t8.5 CGPA\n",
      "\n",
      "\n",
      "Board Of Intermediate, AP\n",
      "Sri Prakash Junior College\n",
      "08/2012 - 03/2014,\t81.1%\n",
      "\n",
      "\n",
      "B.tech\n",
      "Sri Prakash College Of Engineering\n",
      "08/2014 - 03/2018,\t73.33%\n",
      "SKILLS\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "PERSONAL PROJECTS\n",
      "Purchases Management (03/2021 - 04/2021)\n",
      "It is used for tracking purchases, Pending Payments, Discounts Based on Users (Retailer/Distributor)\n",
      "\n",
      "Corona Awareness Website (03/2020 - 04/2021)\n",
      "To Provide Awereness on Covid https://batvidcoronaawareness.000webhostapp.com\n",
      "\n",
      "\n",
      "\n",
      "PROJECTS\n",
      "Material Management System (08/2018 - 01/2019)\n",
      "MMS is tracking Procurement Material from Indents to Transfers. and to maintain stock for material of the plant - Technologies Used - YII Frame Work, Angular Js, MySql\n",
      "\n",
      "Warehouse Management System (02/2019 - 03/2019)\n",
      "WMS is to Maintain the stock, Sale, Purchase, Dispatch - Technologies Used - YII Frame Work, Angular Js, MySql\n",
      "\n",
      "Board Of Intermediate Support (03/2019 - 04/2019)\n",
      "BOI is to support and track the Employees attendance, Payments to employees -Technologies Used Joomla Frame Work, Mysql\n",
      "\n",
      "Sales (04/2019 - 08/2020)\n",
      "Sales is to track the purchases of two wheeler, three wheeler and transfer between branches - Technologies Used- Nx Repo, React Js, Nest Js, Type ORM, Mysql, Swagger\n",
      "\n",
      "Apparel Management (09/2020 - 04/2021)\n",
      "Apparel Management Is a large Project is used to track Orders, Sewing, Cutting, Embroidery, productivity of Employees tracking for the plant Technologies Used- Nx Repo, React Js, Nest Js, Type ORM, Mysql, Swagger\n",
      "\n",
      "Enterprice resource planning (05/2021 - Present)\n",
      "Erp is used to track the orders, Packing/RM Procurement, Production, logistics -Technologies Used- Nx Repo, React Js, Nest Js, Type ORM, Mysql, Swagger\n",
      "\n",
      "\n",
      "\n",
      "LANGUAGES\n",
      "\n",
      "Telugu\n",
      "Native or Bilingual Proﬁciency\n",
      "English\n",
      "Full Professional Proﬁciency\n",
      "\n",
      "\n",
      "\n",
      "INTERESTS\n",
      "\n",
      "Processing text:\n",
      "KAMBALA SAI SURENDRA   \n",
      " \n",
      "\tMandepeta \t \n",
      "  \n",
      " \n",
      "SUMMARY \n",
      " \n",
      " \n",
      "Project#1 \n",
      "  \n",
      " \n",
      "mA  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Project#2 \n",
      "EDUCATION \t  \t \n",
      "JNTU, KAKINADA \n",
      " \n",
      "2015 – 2018 \n",
      " \n",
      "B.Tech in Computer Science and Engineering \n",
      "Obtained a percentage of 63.80% \n",
      " \n",
      "LEELA KRISHNA BABUJI POLYTECHNIC, RAVULAPALEM \n",
      " \n",
      "2011 – 2014 \n",
      " \n",
      "Diploma Computer Engineer \n",
      "Obtained a percentage of 68.03 % \n",
      "ZP High School,Tapeswaram \n",
      " \n",
      "2001 – 2011 \n",
      " \n",
      "Matriculation \n",
      "Obtained a percentage of 62 % \n",
      " \n",
      "TECHNICAL \t  PROFICIENCIES \n",
      "\tDEVELOPMENT: \tReact Js, Redux, HTML, CSS, Bootstrap, jQuery, JavaScript. \n",
      "\tIDE EXPERIENCE: \tVisual Studio Code (VSCODE). \n",
      " \n",
      "\tLANGUAGES: \tJAVA. \n",
      "OPERATING SYSTEM: Windows XP ,7,8,10. \n",
      " \n",
      "ACADEMIC \t  PARTICIPATIONS \n",
      "Appreciated certificate in “CYBERTHON-2K18” from East Godavari conducted by “APITA”.  \tWorked as COORDINATOR in College Annual Fest. \n",
      "Participated in “Paper Presentation” on “Ethical Hacking” in EPROZYNE2K15 conducted at Pragati Engineering College. \n",
      "Participated in “Poster Presentation” on “Google Glass” in EPROZYNE-2K16 conducted at Pragati Engineering College. \n",
      " \n",
      "\tPERSONAL \t  \n",
      "DETAILS \n",
      " \n",
      " \n",
      "DECLARATION \n",
      " \n",
      "I hereby solemnly affirm that all the details provided above are always true to the best of my knowledge and belief and that, I shall carry myself in a manner that lends dignity to the organization and worthy enough of the person. \n",
      "\n",
      "Processing text:\n",
      "MAREEDU LOKESH BABU\n",
      "PROFESSIONAL OVERVIEW\n",
      "   Around 2  years of experience in software design, development, implementation and maintenance of applications using, HTML, CSS, JavaScript, JQuery, PHP, MySQL, React js , Node Js.\n",
      "Knowledge in Object Oriented PHP Programming.\n",
      "Knowledge in versioning control like GIT.\n",
      "Involved in Responsive web development using Bootstrap.\n",
      "Strong Analytical, Problem solving skills, Presentation skills and  good team player.\n",
      "I can work with independently.\n",
      "\n",
      "\n",
      "SCHOLASTICS\n",
      "                B.Tech (Computer Science Engineering.) from VKR ,VNB & AGK  College of Engineering and Technology,  Gudiwada, affiliated to JNTUK with 76.4% in 2019.\n",
      "TECHNICAL SKILLS\n",
      "Web Technologies\t                :\tHTML, CSS, BOOTSTAP,JAVASCRIPT, JQUERY, \n",
      "                                                                             PHP, React js , Node js.                                                                              \n",
      "Database\t                               :\tMYSQL\n",
      "Operating System\t                :\tWindows\n",
      "IDE\t\t\t\t :\tVisual Studio, NetBeans\n",
      "Code repository Tools                      :             GIT\n",
      "Web Servers\t\t\t :             Apache\n",
      "Installers                                             :             XAMPP\n",
      "PROJECTs\n",
      "Project #1: \n",
      "Name\t\t :             RMC (Redimix Concrete)\n",
      "Duration               :             Sept 2019  - Till now\n",
      "        Team Size\t :\t5\n",
      "        Environment\t :\tHTML, CSS, Bootstrap, MySQL, React js ,Node js.\n",
      "\n",
      "Description:\n",
      "                It is a product built for Instant Redimix Concrete(RMC). This product is  related to construction industry which supplies   redimix concrete  based on customer requirement. . Take orders from Customers, Business or a mix of both.It manages all your sales, stock, accounting, shipping and customer data from a single place. Inventory control improves tracking and control other inventory activities and stock movements.\n",
      "\n",
      "Responsibilities\n",
      "Active Participation in development with timely delivery as per the deadlines.\n",
      "Designed website using HTML and CSS .\n",
      "Programming and coordinating with Team \n",
      "Responsibilities include database design, code profiling and extensive documentation.\n",
      "Review and perform the design validation by working with client.\n",
      "Implemented on validations with required fields dynamically.\n",
      "   Coordinating with team and client for weekly status calls.\n",
      "   .Close follow up with the testing team in resolving issues.\n",
      "    Review with end user on key functionalities of the system and work on improvements of the application technically.\n",
      "\n",
      "Career Profiles\n",
      "Software Developer at Maganti IT Solutions,Vijayawada  from  5th August  2019\n",
      "\n",
      "\n",
      "    DATE:                                                                                                                    Mareedu Lokesh Babu\n",
      "    PLACE:                                                                                                                   SIGNATURE:\n",
      "\n",
      "Processing text:\n",
      "MAREEDU LOKESH BABU\n",
      "\n",
      "PROFESSIONAL OVERVIEW\n",
      "   Around 2  years of experience in software design, development, implementation and maintenance of applications using, HTML, CSS, JavaScript, JQuery, PHP, MySQL, React js , Node Js.\n",
      "Knowledge in Object Oriented PHP Programming.\n",
      "Knowledge in versioning control like GIT.\n",
      "Involved in Responsive web development using Bootstrap.\n",
      "Strong Analytical, Problem solving skills, Presentation skills and  good team player.\n",
      "I can work with independently.\n",
      "\n",
      "\n",
      "SCHOLASTICS\n",
      "                B.Tech (Computer Science Engineering.) from VKR ,VNB & AGK  College of Engineering and Technology,  Gudiwada, affiliated to JNTUK with 76.4% in 2019.\n",
      "TECHNICAL SKILLS\n",
      "Web Technologies\t                :\tHTML, CSS, BOOTSTAP,JAVASCRIPT, JQUERY, \n",
      "                                                                             PHP, React js , Node js.                                                                              \n",
      "Database\t                               :\tMYSQL\n",
      "Operating System\t                :\tWindows\n",
      "IDE\t\t\t\t :\tVisual Studio, NetBeans\n",
      "Code repository Tools                      :             GIT\n",
      "Web Servers\t\t\t :             Apache\n",
      "Installers                                             :             XAMPP\n",
      "PROJECTs\n",
      "Project #1: \n",
      "Name\t\t :             RMC (Redimix Concrete)\n",
      "Duration               :             Sept 2019  - Till now\n",
      "        Team Size\t :\t5\n",
      "        Environment\t :\tHTML, CSS, Bootstrap, MySQL, React js ,Node js.\n",
      "\n",
      "Description:\n",
      "                It is a product built for Instant Redimix Concrete(RMC). This product is  related to construction industry which supplies   redimix concrete  based on customer requirement. . Take orders from Customers, Business or a mix of both.It manages all your sales, stock, accounting, shipping and customer data from a single place. Inventory control improves tracking and control other inventory activities and stock movements.\n",
      "\n",
      "Responsibilities\n",
      "Active Participation in development with timely delivery as per the deadlines.\n",
      "Designed website using HTML and CSS .\n",
      "Programming and coordinating with Team \n",
      "Responsibilities include database design, code profiling and extensive documentation.\n",
      "Review and perform the design validation by working with client.\n",
      "Implemented on validations with required fields dynamically.\n",
      "   Coordinating with team and client for weekly status calls.\n",
      "   .Close follow up with the testing team in resolving issues.\n",
      "    Review with end user on key functionalities of the system and work on improvements of the application technically.\n",
      "\n",
      "Career Profiles\n",
      "Software Developer at Maganti IT Solutions,Vijayawada  from  5th August  2019\n",
      "\n",
      "\n",
      "    DATE:                                                                                                                    Mareedu Lokesh Babu\n",
      "    PLACE:                                                                                                                   SIGNATURE:\n",
      "\n",
      "Processing text:\n",
      "MD KHIZARUDDIN RAUF \n",
      " \t EXPERIENCE \n",
      "     \n",
      "⇨ Currently working in PickupBiz Solution Private Limited, Pune from January 2021 to till date \n",
      "⇨ 9 Months of working as an Intern on UI React JS - Software Developer \n",
      "⇨ Having sound experience and exposure on UI development using React JS, Bootstrap, HTML 5, CSS, React Hooks, and Redux etc. \n",
      "⇨ Ability to work under any given environment \n",
      "⇨ Demonstrated good communication and Analytical skills \n",
      "⇨ Team building skills, emphasizing versatility and adaptability \n",
      "⇨ Dedication and drive as a hard-working individual \n",
      "⇨ Ability to manage multiple tasks in a pressured environment \n",
      "                                                                           \n",
      "Application Development & UI Designing – \n",
      " Coordinated with the development team of 10 to discuss user interface ideas and applications. - Reviewed application requirements and interface designs to ensure compatibility with existing applications.  \n",
      " \n",
      "UI Components Designing & Application Interface Coding –  \n",
      "Identified web-based user interactions and developed highly responsive user interface components via React concepts. - Translated designs & wireframes into high-quality code and wrote application interface via JavaScript following React.js workflows. \n",
      " \n",
      "Code Debugging & Front-end Architecture –  \n",
      "Troubleshoot interface software and debugged application codes to improve functionality and performance. - Developed and implemented front-end architectures to support user interface concepts with accuracy. \n",
      " \n",
      " \n",
      " \n",
      "Career seeking \n",
      " \n",
      "Seeking assignments in an organization that allows me to utilize my skills and can nurture them so that I can contribute highly in the growth of the organization individually as well as in Team, while being resourceful, innovative and flexible. \n",
      " \n",
      " \n",
      "EDUCATION \n",
      "                                                                                                                                                               12/2020 \n",
      " SWAMI RAMANAND TEERTH MARATHWADA UNIVERSITY NANDED \n",
      " BSC. KANDHAR, NANDED, MAHARASHTRA. \n",
      " \n",
      " \n",
      " \n",
      "PERSONAL DOSSIER \n",
      " \n",
      "Total Experience:9 Months as an Internship. \n",
      "Nationality: \n",
      "Indian \n",
      " \n",
      "DOB:  \n",
      "1-06-1998 \n",
      " \n",
      "Marital Status : \n",
      "Unmarried \n",
      " \n",
      "Languages: \n",
      "English, Hindi, Marathi, Urdu \n",
      " \n",
      "Hobbies:  \n",
      "Learning New Technologies like Node JS, MySQL, MongoDB, Playing Cricket. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "SKILLS \n",
      "UI Designing \t• Application Designing \n",
      "Wireframe and design Pattern translation \t• Performance Improvement \n",
      "Webpage Designing \t• Project Delivery \n",
      "Coding \t• Debugging \n",
      "Front-End Architecture \t• Feature Designing • Webpage Optimization \t• Client Surviving \n",
      "2 \n",
      "PROJECTS \n",
      " \n",
      "WORKED ON HIGHLY RESPONSIVE REACT JS PROJECTS AND DESIGNED COMPONENTS USING JAVASCRIPT, BOOTSTRAP, REACT-REDUX AND REACT HOOKS. \n",
      " \n",
      " FOLLOWING ARE SOME PROJECTS WHICH I WORKED ON. \n",
      " \n",
      " E-SUPERMARKET  WEB APP . \n",
      " \n",
      " PDAC APP. \n",
      " \n",
      " E – DICTIONARY. \n",
      " \n",
      " EMPLOYEE SEARCH. \n",
      " \n",
      "EMI CALCULATOR. \n",
      " \n",
      "PIANO. \n",
      " \n",
      " \n",
      " \t \t \t \t \n",
      "I hereby declare that the above information is true to best of my knowledge. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Place: Nanded \n",
      " \n",
      "Date:                                                                                            MD KHIZARUDDIN RAUF \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "3 \n",
      "\n",
      "Processing text:\n",
      "\n",
      "Name: M. Prabakaran \n",
      "Title: UI Developer\n",
      "PROFESSIONAL SUMMARY\n",
      "●2.4+ years of Professional IT experience as a software developer having knowledge on different UI based \tApplication.\n",
      "●Hands on experience in HTML, CSS, JS, ReactJS. \n",
      "●Hands on experience in handling UI interaction, Design methodology.\n",
      "●Handling In-App purchase, uploading and maintaining apps in play store.\n",
      "●Hands on experience with customization over base-product depends on client requirement. ●Cohesive team worker, having strong analytical, problem solving and interpersonal skills.\n",
      "EDUCATION\n",
      "●\tCompleted on 2017 Bachelor of Technology (ECE), PRIST University, Tamil Nadu.\n",
      "●\tCompleted on 2012 Higher Secondary, Mount Park Hr Sec School, Thiyagadurgam, Tamil Nadu.\n",
      "●\tCompleted on 2010 SSLC, Krishnasamy Hr Sec School, Cuddalore, Tamil Nadu.\n",
      "SKILLS \n",
      "PROJECT DETAILS\n",
      "Project 1\n",
      "Page | 1 \n",
      "\n",
      "\n",
      "Project 2\n",
      "Project 3\n",
      "Basic Details: \n",
      "Page | 2 \n",
      "\n",
      "Processing text:\n",
      "\n",
      "Pranish Sonone\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Career summary:\n",
      "\n",
      "\n",
      "Experience of 1 years & 2 months working as Jr. React Developer which includes over 1 year of experience in React JS.\n",
      "Hands on experience in developing web pages using ReactJS, Redux, JavaScript, HTML5,  CSS3.\n",
      "Extensive knowledge of ES6.\n",
      "Analysis and design of reports and user interfaces with  reporting.\n",
      "Good communication, collaboration with proficiency at grasping new technical concepts quickly and\n",
      "utilize the same in a productive manner.\n",
      "Good team player with strong interpersonal skills.\n",
      "\n",
      "\n",
      "Technical skills:\n",
      "\n",
      "Web Technologies: ReactJS,  JavaScript, ES6, HTML5, CSS3.\n",
      "\n",
      "Work experience:\n",
      "\n",
      "Currently working with Saffire Softtech, Pune from August 2020 to till date as Jr. React Developer.\n",
      "\n",
      "Projects:\n",
      "\n",
      "Project 1: Ecommerce Portal\n",
      "Role – React JS Developer\t\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Develop UI as per requirement and mockup using react .\n",
      "Create pages for different screen resolutions using CSS and Material UI.\n",
      "Develop components as per the clients requirement.\n",
      "\n",
      "\n",
      "Project 2: Developing Company Website\n",
      "Role- React JS Developer\n",
      "Roles and Responsibilities:\n",
      "Involved in developing react components for website.\n",
      "Worked in developing various functionalities.\n",
      "Involved in designing website by using CSS and material UI\n",
      "\n",
      "\n",
      "\n",
      "Educational Qualification:\n",
      "\n",
      "\n",
      "Personal Profile:\n",
      "\n",
      "Date of Birth: 8th Oct 95\n",
      "\n",
      "Marital Status: Single\n",
      "\n",
      "Language Known: English, Hindi & Marathi\n",
      "\n",
      "\n",
      "Declaration:\n",
      "\n",
      "I hereby declare that all the above information and particulars are true to the best of my knowledge.\n",
      "\n",
      "Place: Pune\tPranish Sonone\n",
      "\n",
      "Processing text:\n",
      "Ranga Gaganam  \n",
      " \n",
      " \n",
      "Having 1+ years of successful IT experience in all phases of Software Development Life Cycle (SDLC) as a React.JS Developer and JavaScript. \n",
      " \n",
      " \n",
      "Experience in design and configuration for implementation, development, maintenance and support as a React.JS Developer to meet business needs. \n",
      "Good working knowledge on React Hooks, JavaScript, HTML. \n",
      "Developing new user-facing features using React.js \n",
      "Building reusable components and front-end libraries for future use. \n",
      "Strong proficiency in JavaScript, including DOM manipulation. \n",
      "Thorough understanding of React.js and its core principles \n",
      "Familiarity with newer specifications of ECMA Script \n",
      "A proactive learner for adopting emerging trends and addressing industry requirements to achieve the organizational objectives. \n",
      "Good communication, presentation and interpersonal skills. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "PROJECT : \n",
      " \n",
      "\tTitle \t: E care Management System \n",
      "\tOrganizer \t: Metrolabs Services Pvt ltd. \n",
      "\tDesignation \t: Junior UI Developer \n",
      "\tTechnologies \t: REACTJS, HTML5, CSS3, JAVASCRIPT \n",
      " \n",
      "Summary:- \n",
      " \n",
      " In this application there are several modules like Employee, Patients,  Admission,Lab management,prescription Pharmacy management,OT  Management..      \n",
      " \n",
      " My Roles & Responsibilities: \n",
      "Developed the UI components for the web application. \n",
      "Developed signup page for this project , for the login authentications use  the firebase. \n",
      "E care management software is a react application it is used for hospitals to manage all the services and information \n",
      "In this application there are different stake holders like accountant, admin,Doctor,Lab,Technician and Physical.. \n",
      "\n",
      "\n",
      "Processing text:\n",
      "SHAIK ABDUL SHARUK   \n",
      "2 years’ Experience in Wipro \n",
      "Career Objective: \tA challenging pursuit in a reputed organization where I can utilize my skills and strengths and conjunction with common goal and objective for mutual growth \n",
      "LinkedIn Profile:                 https://www.linkedin.com/in/sharuk-abdul-99b754197 \n",
      "GitHub Profile:                   https://github.com/sharukabdul \n",
      "Email Address:                    sharukabdul786@gmail.com \n",
      " \t \n",
      "\n",
      " \t \n",
      "EXPERIENCE: \n",
      " \n",
      "Wipro \tMar-2019 to Feb-2021 \n",
      "Senior Associate \n",
      "JOB RESPONSIBILITIES: \n",
      "Worked on auto machine Waymo Self driving car     \n",
      "Operating the autonomous vehicles by labelling the objects    \n",
      "Test the real time scenario captured by the lidar data     \n",
      "As per the lidar data we need to test and label the object \n",
      " \t \n",
      "\n",
      " \t \n",
      "TECHNICAL SKILLS: \n",
      " \n",
      "\n",
      " \t \n",
      "GITHUB PROJECTS: \n",
      " \n",
      "Blog Application (React JS) To-do List Built in React-Redux    https://github.com/sharukabdul/Todo-List \n",
      "A simple to-do list App built with React, Redux This App is built with following features: \n",
      "User can add, delete and mark complete a to-do item. \n",
      "Redux library is used for state management. \n",
      "Highlight’s to-do status in \"red\" if it crosses completion date. \n",
      " \n",
      " \n",
      " \t \t \n",
      "\n",
      " \t \t \n",
      "\n",
      " \t \n",
      "LANGUAGES: \n",
      "English, Hindi and Telugu \n",
      " (Read, Write and Speak) \n",
      " \t \n",
      "\n",
      " \t \n",
      "DECLARATION: \n",
      "I hereby declare that all the above furnished information is correct and true to best of my knowledge.  \n",
      "Place:  \n",
      "Date: \n",
      " \n",
      "Shaik Abdul Sharuk \n",
      " \n",
      "\n",
      "Processing text:\n",
      "ANIL KUMAR MADDUKURI  \t\t\n",
      "SQL & MSBI Developer   \n",
      "\n",
      "\t\n",
      "\n",
      "Summary\n",
      "\n",
      "2.4 years of experience in MS SQL Server (SSMS) and creating SSIS packages, SSRS Reports by using Microsoft Business Intelligence (MSBI) tools.\n",
      "Expertise in various types of Joins and Sub Queries for writing complex queries involving multiple tables.\n",
      "Handled data manipulation and data consistency by creating Views, Triggers, and Synonyms.\n",
      "Hands on experience in creation, optimization and debugging Stored Procedure and Functions.\n",
      "Familiar in writing queries using CTE, Temporary Tables and Table Variables.\n",
      "Good experience in using Set Operators like Union, Union All, Except and Intersect to assist required data.\n",
      "Experience in manipulate the data from multiple table and report to the client using Aggregate Functions, Windows Functions and String Functions.\n",
      "Worked extensively on Data Extraction, Transformation and Loading (ETL) process in SQL Server Integration Services.\n",
      "Used containers such as for each loop container and sequence container to load the data from multiple source file to Database tables.\n",
      "Expertise in using tasks like  Data flow Task, Execute SQL task ,Control Flow task Execute package task, Execute Process task, Bulk insert Task,  Sends Mail task and FTP Task and Script task at the control flow level .\n",
      "Experience in using Data conversion,OLEDB command, Row count, Union All, Derived Column, Merge, Merge Join, Fuzzy lookup, Conditional Split and various other Transformation to manipulate data in SSIS package at the Data Flow Level for moving typical data from source to destination.\n",
      "Implemented SSIS Loggings, check-points Break points and package configurations source system to another source system and ETL operations.\n",
      "Good experience in developing Table Reports, Sub Reports, Matrix Reports, Drill down Reports, Drill through Reports using SQL Server Reporting Services.\n",
      "Involved in Linked reports, Cache reports, and Snapshot reports in report manager level.\n",
      "Expertise in performing backup and restore the database.\n",
      "Created Indexes like Clustered Index and Non-Clustered Index to improve the performance.\n",
      "\n",
      "Technical Skills\n",
      "Languages\t           :  SQL, T-SQL\n",
      "RDBMS\t           :  SQL Server 2016/2012/2008 \n",
      "ETL Tools\t           :  SQL Server Integration Services (SSIS)\n",
      "Reporting Tools         :  SQL Server Reporting Tools (SSRS)\n",
      "\n",
      "Professional Experience\n",
      "Currently working as Software Engineer in Imagine Technology and Services Pvt. Ltd \n",
      "       Since 2019 to till date.\n",
      "Project Experience\n",
      "Project\t\t\t:  Health Insurance\n",
      "Client\t\t\t:  Aetna, USA\n",
      "Environment\t\t:  MS SQL SERVER 2016, SSIS, SSRS, Visual Studio 2015 \n",
      "Duration\t\t:  April 2019 to Till Date\n",
      "\n",
      "Description: \n",
      "This project is developed for Aetna Insurance. This is an American managed health care company sells traditional and consumer directed health care insurance and related services, Such as medical, dental, long-term care, and disability plans, primarily through employer-paid (fully or partly) insurance and benefit programs. The main goal of this project Implementing Customer Information into Database and Developing mechanism to revert data from database. \n",
      "Responsibilities: \n",
      "\n",
      "Create/update indexes, views, Stored Procedures, user defined functions, common table expressions (CTEs) and Triggers. \n",
      "Develop SSIS Packages by extracting data from diversified sources like Excel, CSV, flat file, Text and load into staging area.\n",
      "Use transformations like Aggregate, Conditional Split, Derived Columns, Row Count, Merge and Merge Join, Multicast, Slowly Changing Dimension to manipulate data in data flow level\n",
      "Implement event handlers for the packages, maintain log information and provide checkpoints in SSIS level. \n",
      "Design packages in control flow levels based on tasks like Data Flow Task, Execute SQL Task, FTP tasks and used For Each Loop Container, Sequential Container.\n",
      "Generate reports in the form of Matrix, Table by using SSRS from SQL Server Database and included various reporting features such as drilldown, drill through, sub reports. \n",
      "Involved in setting up SQL Server Agent Jobs for periodic Backups with backup devices, database maintenance plans and recovery.\n",
      "Maintained / managed database agent jobs, check for failures and resolve failure issues.\n",
      "Used SQL Profiler and query tuning Wizard to troubleshoot problems and queries.\n",
      "\n",
      "Education\n",
      "B.Tech - Velagapudi siddhartha engineering college,Vijayawada\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Aradhana Tripathi\n",
      "\n",
      "Current Location: Gachibowli, Hyderabad\n",
      "\n",
      "Profile Summary:\n",
      "\n",
      "An accomplished data driven analytical professional have more than 4 years of working experience in information technology & Service industry.\n",
      "Currently working as SQL Database Developer and have 3 years of experience in database design, development, analysis and support of using MS SQL Server, MySQL (MariaDB) and Athena (AWS) in development, testing and production environments.\n",
      "Extensive experience in writing complex queries, creating Tables, Views, Union, Triggers, Stored Procedures, User Defined Functions (UDF’s), System Defined Functions, and other T- SQL statements, Constraints and Indexes using various DDL and DML Commands.\n",
      "Experience in using sub-queries and joins to simplify complex queries involving multiple tables.\n",
      "Experience in working on amazon relational database (AWS RDS).\n",
      "Have basic understanding on using analytical tools and technologies such as SAS, R, Bigdata (Hadoop, Hive, HQL query) etc.\n",
      "Had experience in requirement gathering, stakeholder management, account management and business insights visualization preparing dashboard using tableau and Excel.\n",
      "Technical Skills:\n",
      "\n",
      "Languages: SQL, SAS, R, Python\n",
      "DBMS: MS SQL Server, T-SQL, AWS RDS (Athena), MariaDB (Version of MySQL)\n",
      "IDE: SQL Server Management Studio (SSMS), RazorSQL, HeidiSQL, RStudio\n",
      "Visualization Tools: R, Tableau, Excel\n",
      "Domain: Media & Publication, BFSI, Retail\n",
      "Employment History:\n",
      "\n",
      "Currently working with Condé Nast (https://www.condenast.com/) as SQL Database Developer through Jigyasa Analytics, LLC Since Aug 2019.\n",
      "Worked with Tech Mahindra as Business Associate from Apr 2015 to Jan 2017.\n",
      "Worked with People Tech Group as IT Consultant from Jun 2013 to Mar 2015.\n",
      "Project Details:\n",
      "\n",
      "Project: Migration of On-Premises SAS Regression Models to Athena (AWS)\n",
      "Client:  Conde Nast\n",
      "Role: MS SQL developer\n",
      "Project Description: This project is about migration of logistic regression models in SAS to Athena (AWS) and development of new code in SQL Server then Athena (AWS). The purpose of Migration is to take advantage of AWS cloud features like cost optimization, scalability and high availability.\n",
      "Roles & Responsibilities: \n",
      "Developing and designing SQL code for models in MS SQL Server.\n",
      "Developing and designing SQL code for models in MySQL (MariaDB).\n",
      "Final implementation of model in production environment Athena (AWS).\n",
      "Created reusable code in Athena to automate model scoring.\n",
      "Writing query to push data on S3.\n",
      "Model Validation in Stagging environment.\n",
      "Technical Platform: MS SQL Server 2014, MySQL, HeidiSQL, RazorSQL, SAS, Athena (AWS), Excel etc.\n",
      "\n",
      "Project: Retail Sales Portal Development\n",
      "Client:  One of the leading retail Client\n",
      "Role: MS SQL developer\n",
      "Project Description: This project is all about online ecommerce data comprises the details about customer id, country, customer came from source of traffic, which channel used for transactions. Number of purchases made on particular product & services, frequency of visits. Also given the information about total sales, gross profit, net profit made certain period of time and discount offers to customers. Each of these details used to do data analysis that subsequently helps management in decision making.\n",
      "Roles & Responsibilities: \n",
      "Understanding existing functionality and database design.\n",
      "Database design, creating normalize tables using constraints, functions.\n",
      "Develop complex SQL queries, views, triggers, stored procedures.\n",
      "Maintaining data quality and integrity.\n",
      "Technical Platform: MS SQL Server 2014\n",
      "\n",
      "Academic Project - IIIT Bangalore (Jun 2018 to Jul 2019):\n",
      "\n",
      "Project: Human Resource Database Management Systems\n",
      "Project Description: Human Resource Database Management System creates stores and manages all the data needed to describe the personal and their framework within an organization. It includes definition of various levels of hierarchy in an organization, the salary structure pertaining to every element in this hierarchy, the description of every department functioning in the organization and the overall employee database which integrates elements in all the aforementioned.\n",
      "Roles & Responsibilities: \n",
      "Database design and development.\n",
      "Effective data handling.\n",
      "Effective data retrieval and maintenance.\n",
      "Created features to implemented database security.\n",
      "Technical Platform: MS SQL Server, MS Excel, Tableau\n",
      "\n",
      "Project: CredX Risk Analytics\n",
      "Project Description:  Business objective is to help CredX to identify the right customer using predictive models. Used past data of bank’s applicants to determine the factors affecting credit risk and create strategies to mitigate the acquisition risk. \n",
      "Roles & Responsibilities: \n",
      "Business Understanding, Data cleaning and preparation\n",
      "Building predictive models (Logistic regression, random forest, decision tree etc).\n",
      "Deploy the best fitted model.  \n",
      "Technical Platform: RStudio, MS SQL Server, Excel etc.\n",
      "\n",
      "Academic Qualification \n",
      "\n",
      "Post Graduate Diploma in Data Science from IIIT - Bangalore’19, CGPA 3.2/4\n",
      "MCA, Computer Applications & Information Technology and Sciences from AKS University.\n",
      "\n",
      "Processing text:\n",
      "BUDDHA VAMSI                                                            \n",
      "\n",
      "CAREER OBJECTIVE:\n",
      "\n",
      "Have 2.11 years of IT experience as Database Engineer and currently working in Fluentgrid Limited Visakhapatnam from August 2018 as Database Engineer.\n",
      " Having good hands on SQL, PLSQL at various databases like Oracle, MS Sql Server.\n",
      "Expertise in creating/modifying Tables, Views, Stored Procedures, Functions and indexes.\n",
      "Having knowledge on Triggers, Temporary tables, CTE Recursive Methods.\n",
      "Expertise in writing transformations (ETL) using Business Intelligence tools like Pentaho Kettle.\n",
      "\n",
      "\n",
      "\n",
      "ACADEMIC PROFILE:\n",
      "\n",
      "\n",
      "TECHNICAL SKILLS:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ACHIEVEMENTS AND AWARDS:\n",
      "\n",
      "Two day workshop on SIIMAD(Symbyosis Innovation and Intelligene for Moblie Application Development) at Miracle engineering college ----- Mar 2013\n",
      "International workshop on SSE(security and software engineering) at DIET ---- Feb 2013\n",
      "International workshop on BITD(Business Intelligence and Test Driven Development) ---- Dec 2012\n",
      "Cyber Forensics workshop at NIT warangal ----- Aug 2012\n",
      "Ethical Hacking conducted by Cybercure solutions ----- Aug 2012\n",
      "\n",
      "Two day workshop on cloud computing technology at DIET----Jan 2015\n",
      "\n",
      "I   Achieve IBM Bluemix certificate  in cloud computing technology for creating app in cloud\n",
      "I actively participated in DIET-NSS UNIT\n",
      "\n",
      "PERSONAL PROFILE:\n",
      "Name \t\t:  Buddha Vamsi\n",
      "Father’s Name\t:  B.Dharma Raju\n",
      "Mother’s Name      :  B.Jaya Lakshmi \n",
      "DOB\t\t\t :  22-08-1994\n",
      "Sex\t\t\t : male    \n",
      "Marital Status\t : Single\n",
      "Nationality\t\t :  Indian\n",
      "Languages Known\t :  English, Telugu\n",
      "Hobbies \t\t :  Playing Cricket\n",
      "\n",
      "DECLARATION:\n",
      "\n",
      "              I hereby declare that the above information's are true to best of my knowledge.\n",
      "     \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "Processing text:\n",
      "KAMBALLA PRADEEP                                                                   \n",
      "SYNOPSIS\n",
      "\n",
      "Looking forward to aspire a challenging career, where in enhancing my technical   knowledge and work hardly towards the growth of the organization.\n",
      "SUMMARY\n",
      "\n",
      "Having 2.8 years of Professional Software development experience in the areas of developing and supporting applications based on Microsoft SQL Server.\n",
      "Proficient in Relational Database Management Systems (RDBMS).\n",
      "Expertise in Transact-SQL (DDL, DML, DCL) and in Design and Normalization of the database tables.\n",
      "Experience in implementing business logic using Triggers, Indexes, Views and Stored Procedures.\n",
      "Extensive knowledge of advance query concepts (e.g. group By, having clause, union so on).\n",
      "Experience with tools like SQL Server management studio and SQL Server2008r2/2012 Integration (SSIS).\n",
      "Experience in Creating and Updating Clustered and Non-Clustered Indexes to keep up the SQL Server Performance.\n",
      "Self-motivated and ability to learn and grasp new technologies and domain knowledge.\n",
      "Excellent analytical, communication and interpersonal skills. Proficient in technical writing and presentations and a good team player.\n",
      "Experienced in authoring and deploying SQL Server Integration Services (SSIS) packages.\n",
      "Good Experience in optimizing the queries by creating various clustered, non-clustered indexes and indexed views\n",
      "Extensive experience with SQL Server and T-SQL in constructing Procedures, triggers, Tables, Table variables, user defined functions, views, indexes, CTE, temp tables, relational database models.\n",
      "\n",
      "Education Details\n",
      "                        Graduated in B.sc  from Sri Venkateshwara University, Tirupathi,2018.\n",
      "WORK EXPERIENCE\n",
      "\n",
      "Currently working as a software Engineering in Coginic Technologies pvt Ltd., from JUN-2018 to 04th feb 2021 in Hyderabad.\n",
      "TECHNICAL SKILLS\n",
      "\n",
      "\n",
      "Project Details:\n",
      "Project 1:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                       \n",
      "\n",
      "\n",
      "Processing text:\n",
      "B. Tech (Electronics and Communications Engineering ) in 2015na. with date functions. Developed Stored Procedures and using joins, sub queries, functions and views.ss based on their country level applied roles to restrict data to specific region. the reports are pointing either to cube or to relational DB. The major taskis to understand the requirement of report then replicate it in power bi. As both the tools are entirelydifferent, many challenges are handled to achieve the same.Best Customer Report, Best Product sold report, Best Promotion report, etc.\n",
      "\n",
      "Processing text:\n",
      " \n",
      "                                        Resume\n",
      "Name     :  Neeraj Mishra\n",
      "\n",
      "\n",
      "Having 3 year  6 Month of Experience on Oracle Developer.\n",
      "Experience in Oracle 11g, 12c, SQL and PL/SQL programming.\n",
      "Experience in Creation of Tables, Indexes using SQL and PL\\SQL.\n",
      "Extensively worked on Backend Programming using PL/SQL\n",
      " Stored Procedures, Functions, Packages, triggers, Exception Handling.\n",
      "Expertise in creating Oracle Tables, Views, Joins.\n",
      "Experience in Writing SQL Queries, Understanding Requirements.\n",
      "Knowledge on implementing securities using Roles, Privileges and Grants.\n",
      "Good Knowledge on Recursive Query Techniques, Pseudo Column implementations, SET Operators, Understanding Transaction Control, Materialized Views.\n",
      "Extensively worked with DDL, DML and TCL statements.\n",
      "Ability and willingness to learn new technology and acclimatize to any work culture.\n",
      "Able to adapt quickly to the environment and willing to work in shifts.\n",
      "\n",
      "\n",
      "\n",
      "I have completed B.E from RGPV Bhopal in 2013.\n",
      "\n",
      "\n",
      "I am working in oracle developer in Fabex tech solution pvt Ltd from 2017 Till.\n",
      "\n",
      "Operating system             :  Windows \n",
      "Database                            :  Oracle 11g, 18c.\n",
      "Programming Languages:  SQL, PL/SQL, UNIX \n",
      "Technical Skill                    :  Oracle Sql , PL/SQL\n",
      "Tools                                    :  SQL Developer, CRM, Sql* loader\n",
      "Environment                      :   Oracle 11g, Window\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "#           Project Name:  BOLT (Back Office Legacy Transition)\n",
      "Technology     :  SQL, PL/SQL, Oracle\n",
      "Tool\t             :  SQL, Plsql Developer, CRM, Sql*loader\n",
      "Role                  :   Sql & PLSql developer\n",
      "Environment :   Oracle 11g, Windows\n",
      "Team Size        :  8\n",
      "Duration          :  March 2019 to till \n",
      "\n",
      "Description:  BOLT, Back Office Legacy Transition is an application which processes all the orders coming Into D&B through various order entry systems. BOLT is the heart of the back-office application. It is the prime application that is responsible for offers, pricing, transaction, billing and invoicing and doing the revenue recognition. Transaction records from several other systems come into BOLT and get processed. BOLT also Sends feeds to several other systems such as AR, Quantum, and GL etc.\n",
      "\n",
      "Roles &Responsibilities:\n",
      "Involved in writing complex SQL Queries, PLSQL code to implement the business requirements.\n",
      "Perform DML, DDL Operations as per the Business Requirements.\n",
      "Involved in the Development Backend Code, Altered Tables to Add New Columns, Constraints, Sequences and Indexes as per Business Requirements.\n",
      "Resolved Production issues by modifying backend codes as and when required.\n",
      "Involved in Creating the Procedures, Functions, Trigger and Views.\n",
      "All these details we are updating in our database throw the help of sql*loader.\n",
      "Worked with Joins, Sub-Queries/Co-related Sub-queries .\n",
      "Detailed analysis of the change request or project requests received from the users or back end applications, development and implementation of the changes.\n",
      "Experience in Client interaction.\n",
      "\n",
      "\n",
      "#   Project Name:   M-ONE services\n",
      "    Technology    :  SQL, P L/SQL, Oracle \n",
      "    Tool\t                :  SQL, Plsql Developer, CRM, Sql*loader\n",
      "    Role                 :   sql & plsql developer\n",
      "   Environment  :   Oracle 11g, Windows\n",
      "   Team Size        :  8\n",
      "   Duration          :   Oct 2017 to Feb 2019\n",
      "Description:  M-ONE is a web application, exclusively designed for the client MOT. They produce Website Designs and Products to Internet Users. In the process they offer Complete Graphic Design, Website Design and Development, Web Hosting & Maintenance, e Solutions, Various types of Online Requests, etc.\n",
      "  It consists of Services & Admin Module. Services Module deals with maintenance of the user information. MOT provides services to the users based on the information which is maintained in this module from the Database.\n",
      "\n",
      "Roles & Responsibilities:\n",
      "Gathering the requirements from the business users and analyzing them to implement.  Analysis of the Problem Statement and Requirement Gathering.\n",
      "Working upon production incidents, analyzing & resolving them.\n",
      "Working on Change / Business Requirements.\n",
      " Extensively used the Procedures, Functions, Views, Materialized views, Packages.\n",
      "Triggers and Indexes etc to fulfill the business requirements. \n",
      "Used SQL* Loader to load data into different tables.\n",
      "Coordinated with DBA in improving Database Performance. \n",
      "Enhancement of current functionality to improve system performance \n",
      " \n",
      "\n",
      "\n",
      "I hereby declare that the information furnished above is true and correct to the best of my knowledge.\n",
      "\n",
      "Date:\t                                                                                                                       Néeraj Mishra\n",
      "Place:                                                                                                                         Bangalore \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "SQL DEVELOPER\n",
      "Name: -   Bandi prem sai\n",
      "\n",
      "\n",
      "Willing to work under a challenging and professional environment with exposure to new Technologies as a T-SQL in the area of SQL SERVER 2012/2016 with Enterprise Portal and where there is ample scope for Organizational growth as well as individual growth.\n",
      "\n",
      "\n",
      "2.6 years of experience in Microsoft SQL Server environment, with thorough knowledge of SQL Server 2012/2016 databases. \n",
      "Expertise in scripting T-SQL queries, Stored Procedures, User Defined Functions and Triggers.\n",
      "Hands on experience in performing Error Handling and performance tuning in Stored Procedure.\n",
      "Good experienced in creating and using Temporary table, Table Variable and CTE’s (Common table Expressions)\n",
      "Used Sub-Queries, Derived table and Joins to simplify complex queries involving multiple tables.\n",
      "Expertise in creating, maintaining database objects like Indexes, Functions, views, UDF’s, constraints.\n",
      "Good experience in using Ranking Functions, Date Functions, String Functions and Aggregate Functions\n",
      "Good Knowledge in Transactions, Isolation level, Concurrency Problems\n",
      "Very good experience in building the Relationship using Constraints.\n",
      "Good Knowledge in Creating Jobs to automate process using SQL Server Agent.\n",
      "Good Knowledge on new features in SQL Server 2016, 2019.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "B.C.A from Sri Venkateswara University,Tirupathi.\n",
      "\t\n",
      "\n",
      "Worked At TECHASOFT PVT LTD as Software Engineer, Bangalore since OCT-2018 to till date.\n",
      "\n",
      "\n",
      " Project II:-\n",
      "\n",
      "\tProject Name: -   Haematology Solutions\n",
      "\tClient Name \t : -   BRAVO PHARMA\n",
      "\tDomain\t : -    Health Care \n",
      "\tDuration            : -    Feb/2019 – Till date\n",
      "\tRole\t\t : -    SQL Developer \n",
      "\t\n",
      "\tDescription      :- \n",
      "\t\tBravo Pharma cares for the protection and enhancement of human health and well-being on all levels. The spectrum of our activities ranges from supporting education in life sciences and strengthening start-ups in health technologies, offering novel solutions for diagnostics and personalized treatment to production and sales of pharmaceuticals.\n",
      "\tResponsibilities:- \n",
      "Developed and optimized database structures, stored procedures, views, and user-defined functions for the Application.\n",
      "Created some T-SQL queries, Stored Procedures.\n",
      "Design and create SQL tables, indexes. \n",
      "Responsible for Query optimization and Performance tuning. Performing query plans and making sure each and every query is using appropriate useful indexes.\n",
      "Design and create SQL tables, indexes. \n",
      "Responsible for Query optimization and Performance tuning. Performing query plans and making sure each and every query is using appropriate useful indexes.\n",
      "Created Constraints mainly Primary Key and Foreign key.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project I:-\n",
      "\n",
      "\tProject Name: -   Integrated Simple Commerce Solution\n",
      "\tClient Name \t : -   CODI\n",
      "\tDomain\t : -    E- Commerce \n",
      "\tDuration            : -    Nov/2018 – Feb/2019\n",
      "\tRole\t\t : -    SQL Developer \n",
      "\t\n",
      "\tDescription      :- \n",
      "\t\tIntegrated Simple Commerce Solution is an Ecommerce application to sell products (such as Laptop, Printers etc.) through online. Integrated Simple Commerce Solution built with high end technology and it is integrated with many upstream and downstream systems to handle the business and full fill customer needs. Integrated Simple Commerce Solution having millions of customers around 16 countries and provides an easy way to find and buy the products.\n",
      "\tResponsibilities:- \n",
      "Developed and optimized database structures, stored procedures, views, and user-defined functions for the Application.\n",
      "Created some T-SQL queries, Stored Procedures.\n",
      "Design and create SQL tables, indexes. \n",
      "Responsible for Query optimization and Performance tuning. Performing query plans and making sure each and every query is using appropriate useful indexes.\n",
      "Design and create SQL tables, indexes. \n",
      "Responsible for Query optimization and Performance tuning. Performing query plans and making sure each and every query is using appropriate useful indexes.\n",
      "Created Constraints mainly Primary Key and Foreign key.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "PLACE: Hyderabad\t\t\t\t\t\t\t                    (Priyanka L)\ttrue to the best of my knowledge and beliefop container, Derived column, Conditional split, Data conversion, Sort, Merge, and Multicast.Billing), OT Modules etc. Cedars caters primarily to the professionals of Medical, visionary doctors, Nursing, Pharmacy, Physiotherapy, Paramedical, Allied Health, and the related fields. Major Service Offerings are in the fields of Healthcare and Medical Micro job and Journals Publishing, And Research & Publication Consultation and Assistance. We have been a part of your lives and have dispensed quality medical information related to all fields and diseases.\n",
      "\n",
      "Processing text:\n",
      "                                       SQL SERVER DEVELOPER\n",
      "\n",
      "\n",
      "P. Syam Kumar              \t\t\t          \t\t\n",
      "\n",
      "\n",
      "Professional summary:\n",
      "\n",
      "Having 2.3+ years of professional experience in IT industry. Involved in Microsoft SQL SERVER 2008, 2012, 2017 and have trained on ETL tools of SSIS.\n",
      "Good in designing objects of Tables with Constraints, Views.\n",
      "Experience in writing SQL Joins and Set Operators for data pulling and combining from multiple tables.\n",
      "Experience in using system functions (String functions, Date functions, Aggregate functions, Rank functions) to meet business requirement.  \n",
      "Experience with SQL Server in constructing Subqueries, Common Table Expressions (CTE), Temp Tables, and Table Variable with proper naming convention.\n",
      "Good working experience in T-SQL Concepts Stored Procedures, User Defined Functions, while loops, Cursors and Triggers.\n",
      "Knowledge on TCL , Error Handling and using of Magic Tables.\n",
      "Knowledge in creating Indexes and Performance Tuning\n",
      "Worked on data flow transformations like Look up, Sort, Data conversion, union-all and SCD’s.\n",
      "Good in Data Bases Backups, Restores, and Changing Synonyms.\n",
      "Trained on data extraction, transformation and loading (ETL) using SQL server integration services (SSIS) tool using different kinds of Sources and Destinations.\n",
      "Design the packages using Control Flow, Extract the data from source using of different transformations.\n",
      "\n",
      "Technical Profile:\n",
      "\n",
      "Databases\t\t          : SQL Server 2008, 2012, 2017\n",
      "IDE\t\t\t          : MS Visual Studio 2013, SSMS.  \n",
      "Other Tools \t\t          : MS Office Suite (Excel, Word, Notepad).\n",
      "ETL Tool\t\t          : SQL Server Integration Services (SSIS).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Company’s Information:\n",
      "\n",
      "Currently working as Software Engineer in Volaris Group-Tarantula India Pvt.Ltd from April 2019 to till date.\n",
      "\n",
      "Educational Qualification:\n",
      "\n",
      "M.C.A from S.V. University, Tirupathi from 2014- June 2017.\n",
      "\n",
      "Project summary:\n",
      "\n",
      "Project\n",
      "\n",
      "\tProject/ Client\t\t: ATC - American Tower Company.\n",
      "Role\t\t\t: SQL Developer.\n",
      "Team size\t\t: 10.\n",
      "Duration\t\t: April 2019 to till date in Tarantula.\n",
      "\n",
      "Description:\n",
      "\n",
      "ATC is publicly held company, owner and operator of wireless and broadcast communication infrastructure in several countries. The application is built in Software as a Service (SAAS) proposition. It acts as a medium between OpCo and TowerCo to manage mobile towers. The solution comprises innovative workflow-integrated end-to-end software applications. The provided application is completely based on windows authentication.\n",
      "\n",
      "Responsibilities:\n",
      " \n",
      "Involved in developing the new enhancements for the Application.\n",
      "Analyzing the change request (CR’s) requirements and discussed with managers and leads on Functionality.\n",
      "Involved in Production releases for database.\n",
      "Involved in impact analysis, requirement gathering, effort discussions and effort preparations for the new requirement. \n",
      "Involved to create views, writing complex stored procedures, Functions, Tables, using SQL Server 2012.\n",
      "Involved in Configuration of the Jobs as per the requirement and run the reports for QA checking purpose.\n",
      "Worked with integration services for transferring data from sources like flat file, CSV file, Excel file.\n",
      "Project deployment in all environments (Test, UAT, Live).\n",
      "\n",
      "\n",
      "\n",
      "Coordinating the Developing activities with the development team And QA team.\n",
      "Participate in discussions involving the application creation and understand the requirements and provide the back-end functionality for the applications.\n",
      "\n",
      "\n",
      "\n",
      "Declaration:\n",
      "\n",
      "I hereby declare that the information and facts stated above are true and correct to the best of my knowledge and belief.\n",
      "\n",
      "                    \t\t\t\t\t\t\t                    \n",
      " (P. Syam Kumar)\t\n",
      "\n",
      "Processing text:\n",
      " RAJU PAVANA KUMARI\n",
      "\n",
      "\n",
      "Professional Summary:\n",
      "Having 2.10 years of Professional experience in SQL Server 2014/2017.\n",
      "Having experience in creating database objects such as Stored Procedures, Functions, Views,Indexes,Joins to facilitate efficient data Manipulation and Data Consistency.\n",
      "Having good experience in writing complex queries using Derived Table, Sub-Queries, Set Operators and Joins.\n",
      "Having Proficient Experience on Temporary Objects in SQL like CTE,Temporary Table, Table Variable.\n",
      " I have very good experience with SQL Profile by Debugging the Query.\n",
      "Experience in Creating and Updating Clustered and Non-Clustered Indexes to keep up the SQL Server Performance.\n",
      "\n",
      "Professional Experience:\n",
      "\n",
      "Currently working as Software Developer at Square Bridge Technologies PVT LTD, Bangalore since SEP 2018 to till date.\n",
      "Academic Profile: \n",
      " B.Tech in Electronics and communication engineering(ECE) From JNTU Hyderabad.\n",
      " Intermediate in M.P.C from  Narayana Junior College, Hyderabad\n",
      " SSC from   Secondary School Education,  Vardhana school,  Hyderabad\n",
      "Technical Skills:\n",
      "       Microsoft Technologies              :  SQL Server 2014/2012/2017.\n",
      "       Languages\t\t    \t             :  MySQL\n",
      "       Operating Systems\t   \t   :  Windows 2008 Server, Windows XP/   Windows 7.\n",
      "\n",
      "\n",
      "Projects\n",
      "\n",
      "Project#2\t: Healthcare Management\n",
      "Client\t               : Aetna\n",
      "Duration\t: Feb-2020 to Till Date\n",
      "Role\t\t: Sql Developer\n",
      "\n",
      "Description: Aetna is an American managed health care company that sells traditional and consumer directed health care  insurance plans and related services, such as medical, pharmaceutical, dental, behavioral health, long-term care, and disability plans, primarily through employer-paid (fully or partly) insurance and benefit programs, and through Medicare .\n",
      "Responsibilities:\n",
      "Developed physical data models and created DDL scripts to create database schema and database objects\n",
      "Wrote user requirement documents based on functional specification.\n",
      "Created new tables, written stored procedures, triggers for Application Developers and some user defined functions. Created SQL scripts for tuning and scheduling.\n",
      "Developed source to target specifications for Data Transformation Services.\n",
      "Developed functions, views and triggers for automation\n",
      "Extensively used Joins and sub-Queries to simplify complex queries involving multiple tables and also optimized the procedures and triggers to be used in production.\n",
      "Provided disaster recovery procedures and policies for backup and recovery of Databases.\n",
      "Performance Tuning in SQL Server using SQL Profiler and Data Loading.\n",
      "Project#1\t: Workers Compensation management:\n",
      "Client\t               : Stone wood Insurance\n",
      "Duration\t: Sep-2018 to Feb-2020\n",
      "Role\t\t: Software Developer\n",
      "\n",
      "Description: Worker’s compensation is a form of insurance providing wage replacement and medical benefits to employees injured in the course of employment in exchange for mandatory relinquishment of the employee's right to sue their employer for the tort of negligence. The trade-off between assured, limited coverage and lack of recourse outside the worker compensation system is known as \"the compensation bargain\". One of the problems that the compensation bargain solved is the problem of employers becoming insolvent as a result of high damage awards.\n",
      "\n",
      "Responsibilities:\n",
      "Involved in Design, Development and testing of the system\n",
      "Developed SQL Server Stored Procedures, Tuned SQL Queries (using Indexes and Execution Plan)\n",
      "Developed User Defined Functions and created Views\n",
      "Created Triggers to maintain the Referential Integrity.\n",
      "Reviewed existing business procedures and recommended and implemented changes.\n",
      "Responsible for setting preferences for various ad-hoc requests and distribution of tasks.\n",
      "Declaration\n",
      "\tI hereby declare that the information that is provided above is up to date and true. I would be more than happy to provide any additional information, if required.\n",
      "\n",
      "Date:\t\n",
      "Place: Hyderabad\t\t\t\t\t\t\t                  Pavana Kumari\n",
      "\n",
      "\n",
      "Processing text:\n",
      "                                    resume\n",
      "\n",
      "\n",
      "Ramalakshmi K\t\t\t\t  \n",
      " \n",
      "\n",
      "Career Objective :\n",
      "    Professional objective is to pursue a career as Software Developer in the IT Industry and a position that utilizes my education and experience in the field of Information Technology, so that I can contribute to the organization and further enhances my professional skills.\n",
      "\n",
      "Experience Summary:\n",
      "\n",
      "2.5 year of working experience in Microsoft SQLServer /Microsoft BI, AWS-Redshift.\n",
      " Motivated and result-driven BI Developer with a proven track record in Business Intelligence (BI), Data Warehouse (DWH) and Data Analytics related projects. Proven ability to identify business needs and develop valuable solutions to drive accuracy and process efficiency. \n",
      "Have exposure to work in tools such as SQL Server Management Studio, Microsoft Visual Studio, Business Intelligence Development Studio, SQL Server Profiler, SSIS.\n",
      "Wrote scripts and indexing strategy for a migration to Confidential Redshift from SQL Server and MySQL databases.\n",
      "Hands-on experience to creating a packages in SSIS and used different kind of data flow transformations, control flow tasks and maintained.\n",
      "Writing complex SQL queries, joins, importing & exporting the data from one database to another database and through files to databases.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technical Skills:\n",
      "\n",
      "Languages/Technologies - Python,SQL\n",
      "Libraries - Numpy,Pandas,Matplotlib\n",
      "RDBMS - SQL Server,Mysql,Teradata\n",
      "ETL Tool - SSIS\n",
      "Cloud Platform - AWS Redshift\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Educational Qualifications:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project Details:\n",
      " \n",
      " \n",
      "Employer : Bixware Technologies \n",
      "Project Title : ETL, Cube\n",
      "Client  : More \n",
      "Project Role : Software Developer\n",
      "Period : Jan 2019 - Till date \n",
      "\n",
      " \n",
      "Project Description : \n",
      "\n",
      "More Retail Limited is a retail store brand which was earlier known as Aditya Birla Retail Limited, when it was part of Aditya Birla Group. More Retail Limited (MRL) is the retail formley Aditya Birla Group, a $43 billion corporation. The company ventured into food and grocery retail sectors in 2007 and subsequently expanded its presence across t he country under the brand more with two formats - Supermarkets and Hypermarkets. There are currently 750 Supermarkets and 30 Hypermarkets and Brands aimed to offer a shopping experience that delivers unbeatable value and quality. More is the fourth largest supermarket & Hypermaket chain in the country after Future Group.The company head office stores and maintains all the supermarkets & Hypermarkets stores data into the largest data warehouse and then processing and  provides those data through data marts.Sales Cube is to provide a sales summary to the users efficiently. Inventory Cube is to provide a data of “Inventory on Hand “and “Low Stock” to the users through Office Data Connection (ODC).\n",
      "\n",
      "\n",
      "Role and Responsibilities :\n",
      "\n",
      " • Implementing and Managing ETL solutions and automating operational processes.\n",
      " • Was responsible for ETL and data validation using SQL Server Integration Services\n",
      " • Developing and monitoring the jobs as per daily basis.\n",
      " • Analyzing the daily reports sales data and inventory.\n",
      " • working on Databases for updation of Business required data.\n",
      " • Querying, creating stored procedures and writing T-SQL join to address various reporting operations and also random data requests.\n",
      " • Involved detailed plan describing how to develop, maintain, Deploy, replace and alter or enhance  sales and inventory cube. \n",
      " • Defined and deployed monitoring, metrics, and logging systems on AWS.\n",
      " • Designed and Developed ETL jobs to extract data and load it in data mart in Redshift.\n",
      "\n",
      "\n",
      "\n",
      "Personal Information:\n",
      "\n",
      "Father’s Name\t\t: \tK Narasimha Rao\n",
      "Date of Birth\t\t\t:\t12-May-1996\n",
      "Gender\t            \t:\tFemale\n",
      "Languages Known\t\t:\tTelugu,Hindi,English\n",
      "Permanent address               :           Tipparajuvari Street,VRC center,\n",
      "                                                            Nellore,AP.\n",
      "                                                             \n",
      "Declaration:\n",
      "\n",
      "I hereby declare that all information mentioned above are true and correct to best of my knowledge and belief.\n",
      "\n",
      "\n",
      "\n",
      "Place: Mumbai\t\t\t\t\t\t\t\n",
      "Ramalakshmi K\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Name: Ramesh\n",
      "\n",
      "Career Objective: \n",
      "                To contribute an organization that provides an opportunity to showcase my technical skills and helps me to gain knowledge in domain and technology.\n",
      "Professional Summary:\n",
      "3.5 Years of experience in system Design, Development and Support of Microsoft SQL server 2008, 8R2 and 2012.\n",
      "Extensive experience on Joins, Set Operators, Temporary Tables, Table Variables, CTE/Derived Tables, sub-Queries.\n",
      "Extensive experience on constructing Tables, Views, Indexes, Synonyms, Functions, Cursors and Stored Procedures.\n",
      "Experience on ETL (Data Extraction Transforming and Loading) in BIDS (Business intelligence development studio)/ SSDT (SQL Server Data Tools) using SSIS (SQL Server Integration Services), Bulk Insert, BCP (bulk copy program).\n",
      "Experience on Design and Development of SQL Server Integration Services (SSIS) packages and using various control flow tasks like Data Flow Task, for-each Loop Container, For Loop Container.\n",
      "Experience on different transformations like Data Conversion, Conditional Split, Merge, Merge Join, Union All, Derived Column, Multi-Cast, SCD, Fuzzy Lookup etc.\n",
      "Experience on providing Logging, Error Handling by using Event Handler, Checkpoints, and logging for SSIS Packages.\n",
      "Designed different types of Bulk Insert task, Execute SQL task, FTP task and Send mail tasks.\n",
      "Experience on Deploying the SSIS Packages\n",
      "Experience on all types of reports like Table, Matrix, Sub-Reports, Image etc.,\n",
      "Generated multiple reports using SSRS from SQL Server Database (OLTP) and included various reporting features such as Group-by, Drill-Down, Drill-Through, Cascading Reports, Parameterized Reports and Report builder.\n",
      "Experience on Created Linked Reports, cache Reports.\n",
      "Deployed and processed SSIS packages and SSRS reports weekly to update information (as per business logic) by using SQL server agent and windows scheduler.\n",
      "Knowledge on SQL profiler, performance tuning, Query tuning and new features of advanced versions in SQL server.\n",
      "Excellent Report creation skills using Microsoft Reporting Services (SSRS) 2008/2012.\n",
      "Willing to learn new things and hard working.\n",
      "Excellent communication, ability to deal with different people, interpersonal and analytical skills, and a highly motivated team player with the ability to work independently.\n",
      "\n",
      "\n",
      "Education:  Master of Computer Applications (2018)\n",
      "\n",
      "Technical Skills:\n",
      "Operating Systems\t:   Windows, Unix \n",
      "Database Tools             :  SQL server Management   Studio (SSMS)\n",
      "Languages\t\t:  SQL and T-SQL\n",
      "ETL Tools\t\t:  SQL Server Integration Services (SSIS)\n",
      "Reporting Tools           :  SQL Server Reporting Services (SSRS)\n",
      "Databases\t\t:   MS SQL Server\n",
      "\n",
      "Professional Experience:\n",
      "\n",
      "Currently working as SQL Developer for Tietoevryindia In Bangalore from Feb 2018 To Till Date\n",
      "\n",
      "\n",
      "Project Details:\n",
      "Project# 2\t\n",
      "Title                     :    T-Mobile\n",
      " Client\t                :    T-Mobile\n",
      "Duration            :    April-2020 to till date (1 year 2 months)\n",
      "Skills Used        :     SQL ,SSIS,SSRS\n",
      "Role Played\t :   SQL Server& MSBI Developer \n",
      "\n",
      "\n",
      "Abstract:\t\n",
      "\tIt is an E-commerce web application, consists of two main modules admin module and User module. Inside user module it has multiple components like cart, orders, payment etc. and in Admin module have a component like category, sub-category, products and etc.\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Excellent report creation skills using Microsoft SQL Server Reporting Services (SSRS).\n",
      "Created SQL Server Reports based on the requirements by.\n",
      "Developed reports and deployed them on server using SQL Server Reporting Services (SSRS).\n",
      "Developed Complex Stored Procedures, Views and Temporary Tables as per the requirement.\n",
      "Wrote complex SQL queries using joins, sub queries and correlated sub queries to retrieve data from different SQL Server Databases and Excel files, apply business logic, load in table and create view for end users.\n",
      "Created DDL scripts to create database schema and database objects like tables, stored procedures, views, functions, and triggers using T- SQL.\n",
      "Create the clustered/non-clustered indexes on tables; Trace out for any table required any indexes and determine the type of index on it.\n",
      "Created complex reports which involve more number of groupings and multi-value parameters\n",
      "Developed reports like Claim Statements, Fee Bills Transactions, and some end request user reports on periodic basis.\n",
      "Provided technical guidance and support to end-users by developing documentations required.\n",
      "Experience in creating complex SSIS packages using proper control and data flow elements.\n",
      "Worked extensively on SSIS Package designs for Import/Export from various Data Source Flat file, Excel to MS SQL Server and vice versa and schedule the jobs.\n",
      "\n",
      "Used various Transformations such as Slowly Changing Dimension, Multicast, Merge Join, Lookup, Fuzzy Lookup, Conditional Split, Aggregate, Derived Column, and Data Conversion Transformations.\n",
      "Generated matrix reports, drill down, drill through, sub reports, multi parameterized reports in SSRS\n",
      "Rendering the reports to PDF formats as per the requirement and printing all the reports in a batch process for Monthly Statements. Scheduling the SSIS packages and Jobs.\n",
      "\n",
      "\n",
      "\n",
      "Project #1\t\t\n",
      "\n",
      "       Title                 :   Sales Flash                               \n",
      "       Client\t    :   British Gas\n",
      "       Duration        :   May-2018 to feb-2020(1 year 10 months)\n",
      "       Skills Used    :   MS-SQL SERVER \n",
      "       Role played  :   Associate Software Engineer\n",
      "Abstract:\t\n",
      "\t\tBritish Gas is an energy and home services provider in the United Kingdom. It is the trading name of British Gas Services Limited and British Gas New Heating Limited, both subsidiaries of Centrica. Serving around 12 million homes in the UK, British Gas is the biggest UK energy supplier and is considered one of the Six which dominate the gas and electricity market in the United Kingdom\n",
      "Responsibilities:\n",
      "Determined the SQL Server Installation. Installed SQL Server Management tools using SQL Server Setup Program and Tested the Installation of SQL Server.\n",
      "Create database objects such as tables, views, stored procedures, Triggers etc.\n",
      "Implemented Triggers for checking complex business conditions, providing security for the tables.\n",
      "Created check constraints to maintain data integrity.\n",
      "Created stored procedures and functions to support efficient data storage and manipulation.\n",
      "Planned complete Back-up of Database and Restored the Database from Disaster Recovery.\n",
      "Create the clustered/non-clustered indexes on tables; Trace out for any table required any indexes and determine the type of index on it.\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\t         Current Location \t:\tHyderabad.ish.ent requirement.related sub queries to retrieve data from the database.tead of going there and fixing an appointment. In Doctor’s side they can view their appointments and prescribe medicine for their patients-Knowledge in health care system maintains patient’s prescriptions so that their medical details are always available in internet, which will be more convenient for the patients. This will be more comfortable for the patient. Patient details and prescriptions are maintained confidentially. There are four modules in E-knowledge in Health care system they are Patient module, Doctor module, Administrator module, General  user module\n",
      "\n",
      "Processing text:\n",
      "B. vinod kumar\n",
      "\n",
      "OBJECTIVE:\n",
      "Willing to work under a challenging and professional environment with exposure to new technologies as an SQL and MSBI developer in the area of SQL SERVER 2014, 2016 with Enterprise Portal and where there is a scope for Organizational growth as well as individual growth.\n",
      "Professional summary:\n",
      "Having around 2.2Years of IT Experience in Microsoft Business Intelligence (MSBI) under SQL server environment, with through knowledge of SQL server 2014,2016 databases.\n",
      "Extensive experience on Joins, Set Operators, Table Variables, Temporary Tables, CTE & Sub Queries.\n",
      "Good experience in writing Simple and sample SQL queries.\n",
      "Experience in Developing Stored Procedures and User defined functions.\n",
      "Hands on Experience Triggers , views, cursor and synonyms.\n",
      "Experience on Writing SQL using joins, sub queries.\n",
      "Good at generating multiple reports using SSRS from SQL server database and included various reporting features such as Drill-Down, Drill-Through, Cascading Reports and Sub Reports.\n",
      "Experience in importing/exporting data between different sources like Excel/Flatfile etc.\n",
      "Good experience on Backups & Restoring into different Servers.\n",
      "Hands on Exeperience on different transformations like Data conversion, Derived coloumn, Look up, Merge join, Union All, Sort, Fuzzy lookup.\n",
      "Good Experience on Ranking, Aggregate and String Functions.\n",
      "Experience on Design and development of SQL Server Integration Services(SSIS) packages and using various control flow tasks like Data floe task and Excute SQL task and containres like For Loop container and sequence container and For -each container.\n",
      "Experience on deploying the reports and creating subscriptions to send the reports on schedule basis.\n",
      "\n",
      "EDUCATIONAL BACKGROUND:\n",
      "B.Tech (computer science and engineering),JNTU,Ananthapuramu.\n",
      "\n",
      "PROFESSIONAL EXPERIENCE:\n",
      "Working in united health group as a Software Engineer, Bangalore since may-2019 to till date.\n",
      "\n",
      "\n",
      "TECHNICAL SKILLS:\n",
      "Technologies\t: Microsoft Business Intelligence Tools (MSBI)\n",
      "Languages\t: SQL, T-SQL.\n",
      "ETL Tools\t: SQL Server Integration Services.\n",
      "Reporting Tools\t: SQL Server Reporting Services\n",
      "\n",
      "PROJECT DETAILS:\n",
      "Client: Uk\n",
      "Project: National skill Development corporation\n",
      "Role: SQL Server and SSIS developer\n",
      "Envirnoment : SSIS, SSRS and MS SQL Server.\n",
      "Project 1: National Skill Development Corporation (NSDC)\n",
      "Client\t: National Skill Development Corporation (INDIA) Role\t: SQL Developer\n",
      "Environment\t: SQL Server, Nano-BI. Duration\t: May 2019 to till now.\n",
      "\n",
      "Description:\n",
      "NSDC Provides training / placements to people across the country through SIP across specific skill sets. Under NSDC there are multiple scheme types like PMKVY, Non-PMKVY and Fee-Based, Based on scheme type candidates will enroll to the batches under particular training centres. In every batch minimum 10 candidates can enroll. After enrolling candidates will go for Training then these candidates will go for assessment and Failed candidates can apply for re-assessment and the candidates who are passed will go for the certification. And the certified candidates will get placement through NSDC.\n",
      "\n",
      "ROLES AND RESPONSIBILITIES:\n",
      "By using NANO BI Analytical tool creating tables.\n",
      "Developed ETL Scripts to populate the data from different tables by using joins, CTE’s and Date functions.\n",
      "By using NANO BI Analytical tool creating tables.\n",
      "Involved in Creating analytics with measures and dimensions to populate data and created dashboard to clients by their requirement.\n",
      "Responsible for Creating and Modifying T-SQL stored procedures for validating the integrity of the data.\n",
      "Responsible for writing complex SQL Queries, Joins, Constraints, DDL, DML Date Functions to implement the business logic.\n",
      "\n",
      "Experience in creating different types of Reports according to the user request by using NANO BI Analytical tool.\n",
      "Involved in deploying and scheduling the reports using Report Emailer.\n",
      "Involved in scheduling the Stored procedures to refresh the data on every day using Workflows in NANO BI.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "B. Vinod kumar\n",
      "\n",
      "Processing text:\n",
      "Chinna Subbarayudu M\n",
      "DOB: 06th March 1994\n",
      "Nationality: Indian\n",
      "\t\n",
      "PROFILE SUMMARY:\n",
      "\n",
      "Having around 5.1 years of IT experience in developing and Implementation of ERP technology by using Workday HCM and ETL (informatica) technologies.\n",
      "3.6 years of experience as Workday Integration Consultant and involved in a maintenance and implementation.\n",
      "Experience in all phases in Workday like requirements gathering, Analysis, Design, Development and Testing.\n",
      "Hands on experience in inbound/ outbound integrations using core connector, Workday studio, managing business processes, working with EIB, report writer.\n",
      "Developed and maintained custom-report types (Advanced, Matrix, Composite) using report writer tool.\n",
      "Involved in transformation of XML into XSLT for presenting data for different web Services.\n",
      "Building Workday Integration (EIB), calculated fields, Custom Reports and Writing XSLT transformation code.\n",
      "Developed testing strategies and validation scenarios along with project Scope and Requirement documents\n",
      "Prioritizing, reproducing and verifying bug fixes in different Workday integrations.\n",
      "Having knowledge in XML, WD-SOAP Web Service, and WD- REST Web Service and experienced in using tools such as Soap, XML Exchanger\n",
      "Involved in writing transformation code for converting XML into XSLT\n",
      "for different web services.\n",
      "Performed validation testing and end to end testing and also involved in integration testing\n",
      "Having good experiences in testing, we perform UAT and end to end validation testing\n",
      "Knowledge in Software Development Life Cycle process (Analysis, Design, Development, Testing) for Implementation and Support in different application domain.\n",
      "Experience of working in Production support model.\n",
      "Excellent client interaction skills and proven experience in working independently as well as in a team.\n",
      "\n",
      "TECHNICAL SKILLS:\n",
      "\n",
      "\n",
      "Education Details:\n",
      "Bsc(Computers) from Yogi Vemana University,Kadapa.\n",
      "Work Experience:\n",
      "Working as a Workday Technical Consultant for Progile Infotech pvt ltd  from June - 2016 to till date.        \n",
      "Projects under taken:\n",
      "\n",
      "\n",
      "Client: South West Airlines                                                                                   June2019- Present\n",
      "Role: Workday Technical  Consultant\n",
      "\n",
      "Responsibilities:\n",
      "Integrations in Workday using different tools like CCW, EIB, DT, Custom Report and Workday Studio, Responsible for developing Integrations and testing them.\n",
      "Responsible for supporting the new change requests and enhancements in the project\n",
      "Created calculated fields and Worked on Simple and Advanced Reports.\n",
      "Worked on Integration Systems (EIBs, Core Connectors).\n",
      "Day to day support of Workday Integrations, Security, and Reporting issues.\n",
      "Had knowledge on hire, terminate, data changes etc. of employees\n",
      "Expertise in developing Payroll interfaces using PICOF, PECI with the help of Workday Studio and Document Transformation to meet client’s complex payroll requirements.\n",
      "Design of web services to send/receive data between Workday and Third party system.\n",
      "Developed analytics dashboards utilizing multiple data sources to provide actionable reporting and embedded analytics.\n",
      "Experienced in analyzing and preparing Project Deliverables such as Technical Design Document (TDD) and Functional Design Document (FDD).\n",
      "Created test scripts and coordinated the testing effort with all the stakeholders for System and UAT. \n",
      "\n",
      "\n",
      "Client:  Arbella Insurance Group\t\t\t\t                                Dec2017– May2019\n",
      "Role:  Workday Integration Consultant\n",
      "\n",
      "Responsibilities:\n",
      "Analyzed client’s HCM/Payroll business needs through client working sessions and supported development of new business processes and a future state design.\n",
      "Worked as an Integration Developer for Analysis, design, development, testing and implementation of Workday HCM solutions for Global Implementation in GE. \n",
      "Performance Tuning in Population (2 lakh employees) and Complexity Perspective.\n",
      "Created Multiple CCW Integrations for Demographical data with DT, EIBs with reports\n",
      "Supported on both Inbound and Outbound Studio Integrations, Created security groups, users and configured required security policies in Domain and BP level..\n",
      "Utilize in-depth knowledge of functional and Technical experience in Workday and other leading-edge products and technology in conjunction with industry and business skills to deliver solutions to customer.\n",
      "Built Integrations in Workday using different tools like CCW, EIB, and Reports. Identifying Testing strategy getting sign-off on all project deliverables.\n",
      "Collaborate with the ST (System Testing) and UAT (User Acceptance Testing) teams to test the integration builds. Fix issues encountered in ST and UAT phase.\n",
      "Developed Several Complex Integrations using Workday Studio and EIB.\n",
      "Day to day support of Workday HCM, Security, Payroll, Benefits, Compensation and Reporting issues\n",
      "Involved in the design phase and prototyping for further discussions with the client.\n",
      "Created and used calculated fields in reporting, business processes, integrations and other areas within Workday.\n",
      "\n",
      "Client:  News Technologies  \t\t\t          \t\t\t     June 2016 –Nov 2017\n",
      "Role:  Peoplesoft Consultant          \n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Involved in design and customization of tables and panels and adding new option using People Tools.\n",
      "Responsible for Test Plan, Defect Report Status, and Knowledge Transfer Documents.\n",
      "Uploading the test scripts from MS Excel to Test Director.\n",
      "Developed and executed the SQL queries to fetch the data from PeopleSoft HRMS (Oracle).\n",
      "The fetched data has to be analyzed against the bridge database and it should be reported if there is any deviation.\n",
      "Integrated third party hiring application with PeopleSoft System using Component Interface program and loaded data into PS tables.\n",
      "Unit tested the developed application and created test scripts and test cases for the Unit Testing and System Testing\n",
      "Declaration:\n",
      "                  I hereby declare that the information provided above is true to the best of my knowledge.\n",
      "\n",
      "\n",
      "Date : \t\t\t\t\t\t\t\t\tName: M Chinna Subbarayudus\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\t\n",
      "\n",
      "\n",
      "Name         : Gopi Krishna Reddy\n",
      "\t\t                       \n",
      "\n",
      "PROFESSIONAL SUMMERY:\n",
      "Working as a Workday Consultant with 3+ years as Workday Consultant and good experience on Report Writing, Integration of HCM. \n",
      "\n",
      "Knowledge of the software development life cycle from design through scoping, requirements gathering, analysis, development, testing, user acceptance, deployment, maintenance/support and change management. \n",
      "Good working knowledge on Inbound and Outbound EIB Integration concepts and created various EIB Integrations.\n",
      "Building Core Connector integrations for extracting worker, position, status, leave and absence delta changes.\n",
      "Designed and built all types of integrations using Document Transformation, EIB, PICOF, Cloud Connectors and Custom Report Writer. \n",
      "Having  good knowledge on Workday Studio \n",
      "Experience with XML, XPATH and XSLT and Expert in designing/development of Interfaces with legacy and third party systems. \n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenant to Sandbox and Production using Object Transporter.\n",
      "Experienced in developing Custom Reports, Advanced Reports using Report Writer.\n",
      "Strong experience using technologies involving Workday applications, reporting and analytics. \n",
      "Good experience on create Report Groups and Workbooks to create Excel worksheet groups and create Dashboards.\n",
      "Strong Knowledge on working with CR-Change Requests as per business requirement and Building and moving changes to production.\n",
      "Worked closely with Business and Development Teams for Designed and Documented Enhancements as well as conducted Production Support Troubleshooting around Integrations for Global Workday HCM System.\n",
      "Excellent Interpersonal, Presentation and Communication Skills with the ability to work in a team and a Stand-alone Environment. \n",
      "EDUCATIONAL DETAILS:\n",
      "\n",
      "Completed Bachelor of Degree from JNTU - K University in 2014.\n",
      "\n",
      "TECHNICAL SKILLS:           \n",
      "\n",
      "\n",
      "PROJECT DETAILS:           \n",
      "Company: Tyson Foods, Bangalore                 (May 2018 to Present)\n",
      "Project: Workday Support and Enhancement\t\t\t\t\t\t\t\n",
      "Role: Workday Technical Consultant\n",
      "\n",
      "Responsibilities:\n",
      "Involved in Workday HCM for various HR modules such as Benefits, Compensation, Time Tracking and Absence Management.\n",
      "Worked on Calculated Fields to create Report level and Global level.\n",
      "Monitor daily Schedulers and Report Errors as needed.\n",
      "Design and Build Integrations and worked closely with testing and production teams to solve issues with integrations.\n",
      "Created Custom Reports like Simple, Advanced Reports as per the client requirements and shared with the security groups.\n",
      "Created Reports against the Worker business object and worked on Headcount, Turnover and Compensation Reports.\n",
      "Good experience with Core Connector Worker to work on Employee Demographics and build Benefit Integrations and Account Provisioning Integrations.\n",
      "Created Inbound/Outbound integrations using Workday Studio, Core/Cloud Connectors, EIB’s and Document Transformation Process.\n",
      "Involved in Unit Test on Integrations, UAT support and end user training.\n",
      "Design, build or maintain integrations of all types: Reports, EIB, Core Connectors, Payroll Connectors or Studio.\n",
      "Write / Modify Technical Design/ Specifications as needed\n",
      "Participate in Integration Testing and Peer Testing.\n",
      "Work independently or with minimal supervision with various Stakeholders including the Functional Consultants.\n",
      "Monitor and update ticketing tool on daily basis. Manage work activities and ticket volumes to meet required SLA’s and service delivery measures.\n",
      "Developed Core Connector and Document Transformation integrations to get changes file of CSV format from XML Output.\n",
      "\n",
      "\n",
      "Used sequence generators, generating templates and validating inbound integration system results.\n",
      "Day to day support for Workday HCM, Integrations and Reporting issues.\n",
      "\n",
      "Technical Environment: Workday 30/31/32, Workday Studio, Workday EIB, Workday BIRT, Core Concepts, Document Transformation, Calculated Fields, Oxygen Editor, Workday Report Writer, XML, XSLT.\n",
      "\n",
      "\n",
      "PERSONAL INFORMATION\n",
      "\n",
      "Full Name\t\t\t: \tGopi Krishna Reddy \n",
      "Gender\t\t\t               : \tMale \n",
      "D.O.B\t\t  \t               : \t19-04-1993 \n",
      "Marital Status\t                             : \tMarried\t \n",
      "Nationality\t\t\t: \tIndian \n",
      "Languages Known\t\t: \t English, Telugu and Kannada.\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Environment:PeopleSoft HCM 9.1, People Tools 8.51, Oracle 11iloyee Self Service applicationspplying business expertise and best business practices.ration with PeopleSoftterface Builder (EIB).ed of 364,445 employees worldwide and, as of September 2018, was the sixth-largest company in the world by revenue. As of 2017, Toyota is the world's second-largest automotive manufacturer. Toyota was the world's first automobile manufacturer to produce more than 10 million vehicles per year which it has done since 2012, when it also reported the production of its 200-millionth vehicle. As of July 2014, Toyota was the largest listed company in Japan by revenue.\n",
      "\n",
      "Processing text:\n",
      "                 N T U A),Nandyala.ineering From AVR&SVR College of Engineering&Techologypplication Designer, people code, Application Engine. 2016 to September 2017ing governance model. requirements and regular maintenance (some routine data entry).nt Interface, File Layout.\n",
      "\n",
      "Processing text:\n",
      "Operations - \u000b",
      "  1. Joining formalities.\u000b",
      "  2. Handling Employee Database (Both in Soft Form and Files Management)\u000b",
      "  3. Leaves and Attendance Management\u000b",
      "  4. Confirmations, Performance Appraisals, Performance Management\u000b",
      "  5. Exit-Interviews\u000b",
      "\u000b",
      "\u000b",
      "Employee Relations - \u000b",
      "  1. Handling all the queries of the employees. Be it related to Salary, Leaves, Attendance, and Transfer etc.\u000b",
      "  2. They are also expected to explain the various policies, strategies and benefits to employees.\u000b",
      "  3. They are expected to stop all type of rumours and misleading communications.\u000b",
      "  4. They should motivate the employees on day-to-day basis.\n",
      "\n",
      "Processing text:\n",
      "                                      \n",
      "                                                   G Himaja\n",
      "                                                                                                            \n",
      "\n",
      "\n",
      "Career Objective\n",
      "\n",
      "To work towards achieving the greater success in my career through hard work, consistency and the ability to work with others to achieve organizational goals, aims and objectives.   \n",
      "    \n",
      "Professional Summary\n",
      "\n",
      "Having around 3 Years of IT ERP experience which include 2+ years as workday Integration Consultant and Remaining as HR.\n",
      "\n",
      "Good Involvement in Workday Projects full life cycle, Development / deployment, upgrades, Integrations etc.\n",
      "\n",
      "Good knowledge in the Functional Workday includes HCM, Compensation, Payroll interface, Business Process configurations, etc.\n",
      "\n",
      "Extensively worked on calculated fields used in developing various custom reports.\n",
      "\n",
      "Strong Knowledge on Involved in CR-Change Request as for business requirement and Building and moving changes to production.\n",
      "\n",
      "Good Exposure in Integrations- Inbound and Outbound, Payroll interface implementations.\n",
      "\n",
      "Good Experience in Workday Integration Tools - Connectors, PICOF/PECI, RAAS, EIB, API, Reporting, Document Transformation, STUDIO, XSLT, HTML, Data Load etc., and Third party Integrations for client for various vendors like ADP etc.\n",
      "\n",
      "Worked on Functional Data Inbound data loads via EIB for (Applicant, Dependent, Compensation Data Loads).\n",
      "\n",
      "Good Experience in Outbound integrations using EIB and Document Transformation for sending Demographic data to end vendors.\n",
      "\n",
      "Experience on getting requirement from the client and sharing the work across team.\n",
      "\n",
      "Good Experience in BIRT to generate Bonus Letters using workday Studio. \n",
      "\n",
      "Good Experience in Report designing using workday Studio. \n",
      "\n",
      "Strong Knowledge on Deploy reports in multiple environments (Dev-QA-Prod) Using solution.\n",
      "\n",
      "Proven communication and interpersonal skills.\n",
      "\n",
      "\n",
      "\n",
      "Technical- Skills:\n",
      "\n",
      "\n",
      "Experience Summary:\n",
      "\n",
      "Worked as Software Engineer in Thermo Fisher Scientific from June 2018 – Till date.\n",
      "Education:\n",
      "Completed Degree (BSc. computer science) from S V University, Tirupathi-2018.\n",
      "Project:\n",
      "        Project\t          :     Support &Implementation of workday HCM\n",
      "       Client                 :     Thermo fisher scientific\n",
      "       Role\t          :    Workday Integration Consultant\n",
      "Roles & Responsibilities\n",
      "\n",
      "Understanding the Business Requirements by studying the Functional Documents.\n",
      "Creation of Advanced Custom reports for End user for reporting on Demographic Information.. \n",
      "Hands-on experience in creating the calculated fields using different functions for complete logics. \n",
      "Created EIB Inbound Integrations for loading the employees personal Information like, Emergency contacts, Compensation, One time payments, Bank account information, cost center information.\n",
      "Created EIB outbound Integrations, written XSLT code and sending data from workday to downstream systems.\n",
      "Modified the XSLT code as per CR-request and adding the new XSLT code for Different info types.\n",
      "Created the new outbound integrations to sending the Payroll Information from workday to ADP payroll system.\n",
      "Created Workday Studio inbound studio programs to load compensation information from ADP to workday.\n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenant to Sandbox and Production using Object Transporter\n",
      "\n",
      "Supporting the Different teams in UAT phase as well as with test factory teams during integration testing phase.\n",
      "Involved in calls with client and update the work status as well as clarifications if any.\n",
      "\n",
      "\n",
      "Project    \n",
      "      Client                 :     Thermo fisher scientific\n",
      "       Role\t          :    HR-Executive\n",
      "Roles & Responsibilities\n",
      "\n",
      "• Handling end to end recruitment activities.\n",
      "•   Uploading the profiles on internal recruitment portal to check the duplicity of the profiles.\n",
      "•   Track of all the open requirements.\n",
      "•   Discussion with business about the job requirements/plan of hire.\n",
      "•   Decision on mode and channel of hire based on the requirements.\n",
      "•   Sourcing the profiles through social network, employee references, references from the   \n",
      "  Candidates, Vendors, etc \n",
      "•   Sourcing the profiles through vendors for contract hiring requirements.\n",
      "•   Initial screening and shortlist the profiles for the interview process.\n",
      "•   Interview schedule for the shortlisted candidates.\n",
      "•   Arrangement of logistics for the interviews.\n",
      "•   Arrangement of panels for the Non-technical and managerial interviews.\n",
      "•   Interview coordination.\n",
      "•   Discussion with project team/business unit about the requirements and initiate sourcing as \n",
      "  per the requirement.\n",
      "•   Preparing the report and submitted to Business.\n",
      "\n",
      "Personal Information\n",
      "\n",
      "\n",
      "Declaration:      \n",
      "                   \n",
      "I hereby declare that the information furnished above is true to the best of my Knowledge. \n",
      "                                                                          \n",
      "                                                                                                                                      Yours Faithfully\n",
      "                                                                                                                       G Himaja                                                                                                                                 \n",
      "\n",
      "Processing text:\n",
      "Monitoring and tuning performance.e's health and taking preventive or corrective action as required.York City and head quartered in Boston. As of 2018, the company operates through the following segments: aviation, healthcare, power, renewable energy, digital industry, additive manufacturing and venture capital and finance. Installing Oracle software.ssful product development, launch, tech transfer and reliable global supply.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "JYOTI VERMA\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "3 years of Experience in Workday as Functional HCM Consultant.\n",
      "Good exposure in working on business improvements and process activities.\n",
      "Exceptional ability in understanding the business needs and improving the process.\n",
      "Excellent communication skills and proven experience in working independently as well as in a team.\n",
      "Involved in preparing business requirement documents and analysis of client functional requirements.\n",
      "Extensive knowledge on Complete Tenant configurations – (Supervisory Organizations, Roles, Business Processes)\n",
      "Experience in performing HCM tasks like defining Job Profiles, position creations, employee hiring, transfers, promotions, demotions and terminations etc., as part of Workday Testing requirements.\n",
      "Configuration of Supervisory Organizations, Business Process.\n",
      "Experience working on Workday HCM Global roll out and Support projects\n",
      "Proficient in analyzing and translating business requirements to technical requirements and architectures.\n",
      "Day to day support of Workday HCM, reporting issues and implementing enhancements when needed.\n",
      "Created Custom Reports and scheduled reports as requested by end-users.\n",
      "Exposure on modifying/troubleshooting/enhancing existing custom reports using Calculated Fields.\n",
      "Created and used calculated fields in reporting, business processes, and integrations within Workday.\n",
      "Understanding and careful analysis of the Internal HR team requirements.\n",
      "Exposure on object management skills in Workday like configuring Supervisory/Matrix Organizations (Divide organizations, Inactivate Organizations, create subordinates).\n",
      "Experience in creating Job Profiles, Job Families and Job Family Groups, also worked with the creation and maintenance of position and job staffing models.\n",
      "Experience in maintenance and creation of Workday Supervisory Organizations, Locations, Positions, Cost centers, Cost Center hierarchies\n",
      "Excellent interpersonal skills with a strong desire to achieve specified goals.\n",
      "Knowledge on Compensation (salary plans based on different grades, grade profiles and allowances).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Currently working as a Workday HCM Functional Consultant in Icroz Solutions Pvt Ltd, Hyderabad from September 2018 to till date.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project-1\t:\tSupport of Workday HCM\n",
      "Client\t:\tElectronic Arts\n",
      "Role\t:\tWorkday Consultant Duration\t:\tSept 2018 to Till Date\n",
      "\n",
      "\n",
      "Worked extensively on creating calculated fields and setting up validation rules to  accomplish the Client needs for BP Setup and Reporting needs.\n",
      "Involved in setting up Eligibility Criteria, Workflows and Security Groups to support Business Processes for Core HR.\n",
      "Exposure in developing Standard, Advanced, custom reports  and  thorough understanding  of Workday data sources and business objects.\n",
      "Day to day support of Workday HCM\n",
      "Created Supervisory Organizations, Cost Centers, Cost Center Hierarchies, and location hierarchies and modification of Workday Business Processes and definitions.\n",
      "Creating and maintaining Workday Custom reports like Simple, Advance Reports.\n",
      "Creating supervisory Organizations, creating sub ordinates, assign superior, Move workers, Creating Locations\n",
      "Knowledge on Workday Standard Reports and Custom Reports.\n",
      "Knowledge on Calculated Fields, System wide and Report Specific Fields.\n",
      "Knowledge on Staffing Models, Job profiles, Positions.\n",
      "Knowledge on security policies and security groups\n",
      "Knowledge on EIB integrations\n",
      "\n",
      "\n",
      " Declaration:\t\n",
      "\n",
      "I hereby declare that the information furnished above is true to the best of my Knowledge.\n",
      "\n",
      "     Yours faithfully\n",
      "JYOTI VERMA\n",
      "\n",
      "Processing text:\n",
      "Date:                                                                                                                       Name: Madeeswar A in Informatica Designer.nd UAT. Navy, Intermix, Hill City, and Athleta. Gap Inc. is the largest specialty retailer in the United States.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "Mooraboyina Guravaiah\n",
      "Workday Integration Specialist\t\t\t\t                            \n",
      "\t\n",
      "CARRIER OBJECTIVE: \n",
      "My intention at this step would be to learn new things related to my profession. As it is a    technical field, one has to be updated because the technology changes often. It is my         responsibility to learn and adopt the new technology. It would be profitable for me as well as for my company\n",
      "\n",
      "PROFESSIONAL SUMMARY\n",
      "\n",
      "Having 5+ years of experience in the field of IT, in which 3+ years of experience in providing Workday Technical Development in Workday Support and Enhancement Project.  \n",
      "\n",
      "Technically proficient in customizations, enhancements and Reports using various tools like Report writer, EIB, Core Connector and Studio.\n",
      "\n",
      "Good working knowledge on Inbound and Outbound EIB integration concepts and created various EIB integrations.\n",
      "\n",
      "Building Core Connector integrations for extracting worker, position, status, leave and absence delta changes.\n",
      "\n",
      "Designed and built all types of integrations using Document Transformation, EIB, PICOF, Cloud Connectors and Custom Report Writer. \n",
      "\n",
      "Experience with XML, XPATH and XSLT, and Expert in designing/development of Interfaces with legacy and third party systems. \n",
      "\n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenet to Sandbox and Production using Object Transporter.\n",
      "\n",
      "Experienced in developing Custom Reports, Advanced Reports using Report writer\n",
      "\n",
      "Strong experience using technologies involving Workday applications, reporting and analytics. \n",
      "\n",
      "Good experience on create Report Groups and Workbooks to create Excel worksheet groups. And creating Dashboards.\n",
      "\n",
      "Strong Knowledge on working with CR-Change Requests as per business requirement and Building and moving changes to production.\n",
      "\n",
      "Worked closely with business and development teams, designed and documented \n",
      "enhancements as well as conducted production support troubleshooting around integrations for Global Workday HCM system.\n",
      "\n",
      "Excellent interpersonal, presentation and communication skills with the ability to work in a team and a stand-alone environment. \n",
      "\n",
      "EDUCATION QUALIFICATION\n",
      "\n",
      "Completed B.Sc (Bachelor of Science) from Nagarjuna University - 2013 \n",
      "\n",
      "TECHNICAL SKILLS:   \n",
      "\n",
      "Technical Expertise\t              :  \tXML, XSLT, EIB, Core Connectors, \n",
      "Functional Expertise\t               :  \tCore HCM\n",
      "Reporting Tools\t\t:  \tReport Writer, Crystal Reports11, XMLP\n",
      "Technical Skills\t\t:  \tEIB, Core Connector, DT and Studio\n",
      "\n",
      "Work Experience \n",
      "\n",
      "Currently Working as Workday Consultant in Jade Global, Pune from May’2016 to Till Date \n",
      "Project Details \n",
      "\n",
      "Jade Global, PUNE     ( Apr’2018 to Till Date)\n",
      "Project:                Workday Support and Enhancement \n",
      "Designation:\t Workday Consultant \n",
      "RESPONSIBILITIES\n",
      "\n",
      "Involved in Workday HCM for various HR modules such as Benefits, Compensation, Time tracking and Absence Management.\n",
      "\n",
      "Working on Calculated Fields to create Report level and Global calculated Fields.\n",
      "\n",
      "Monitor daily schedulers and report errors as needed.\n",
      "\n",
      "Design and build integrations and worked closely with testing and production teams to solve issue with integrations.\n",
      "\n",
      "Created Custom reports like Simple, Advanced Reports as per the client requirements and shared with the security groups.\n",
      "\n",
      "Worked on Calculated Fields to create Report level and Global cal Fields.\n",
      "\n",
      "Good experience with Core Connector worker to work on employee demographics and build Benefit integrations and Account provisioning integrations.\n",
      "\n",
      "Created complex Inbound/Outbound integrations using workday studio, core/cloud connectors, using EIB’s, document transformation process.\n",
      "\n",
      "Involved in unit test on Integrations, UAT support and end user training.\n",
      "\n",
      "Design, build or maintain integrations of all types: reports, EIB, Core Connectors, payroll connectors, or Studio.\n",
      "\n",
      "Write / modify Technical Design/ Specifications as needed\n",
      "\n",
      "Participate in integration testing and peer testing.\n",
      "\n",
      "Work independently or with minimal supervision with various stakeholders including the functional consultants.\n",
      "\n",
      "Monitor and update ticketing tool on daily basis. Manage work activities and ticket volumes to meet required SLA’s and service delivery measures.\n",
      "\n",
      "Developed Core connector and Document Transformation integrations to get changes file of CSV format from XML Output.\n",
      "\n",
      "Used sequence generators, generating templates and validating inbound integration system results.\n",
      "\n",
      "Day to day support for Workday HCM, Integrations and Reporting issues.\n",
      "\n",
      "TECHNICAL ENVIRONMENT: Workday 30/31/32/33/34, Workday studio, workday EIB, Workday BIRT, Core concepts, Document transformation, Calculated fields, Oxygen Editor, Workday report writer, XML, XSLT.\n",
      "\n",
      "\n",
      "2.  Jade Global, Pune    (May’16 to Mar’2018)\n",
      "     Project                  :      PeopleSoft Support and Enhancement \n",
      "     Designation         :\tConsultant\n",
      "\n",
      "Have Customized and developed Application engines for loading bulk data from external systems.\n",
      "\n",
      "Track and resolve user support issues with current system Maintain good working relationships with project team members, internal customers (e.g. AP,PO,BI and GL), and external service vendors\n",
      "\n",
      "Have designed technical documents and have worked towards development of interfaces and conversions based on design documents.\n",
      "\n",
      "Modified, designed, configured and built fields, records, sub records, setting up keys to records, assign table edits like prompt table.\n",
      "\n",
      "Involved in online changes to the delivered pages, components, menus and translate values.\n",
      "\n",
      "Have Customized and developed Application engines for loading bulk data from external systems.\n",
      "\n",
      "Developed and modified People Code to implement specific business rules and validations to enable the System to perform the business process.\n",
      "\n",
      "Used File Layout Definition to get data from the legacy system to PeopleSoft tables.\n",
      "\n",
      "Managed and monitored process scheduler for any issues while scheduled interfaces/processes ran and resolved the issues\n",
      "\n",
      "Developed/Modified various PS queries in order to help the client day-to-day activity.\n",
      "\n",
      "Involved in creating PS Query’s and sending it through email to different country FSCM heads.\n",
      "\n",
      "Worked on the reporting tools like PS Query, XML Publisher\n",
      "\n",
      "Have worked on File Layout, Application Engine, Component Interface, File layout, Excel to CI, XML Report\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PERSANAL DETAILS:\n",
      "\n",
      "\tFather’s Name\t         : Danaiah M\n",
      "\tDate of Birth\t         : 15-02-1992\n",
      "                     Gender                                 : Male\n",
      "                     Nationality                          : Indian \n",
      "                       Marital Status                   : Married\n",
      "\n",
      "\n",
      "Declaration:  \n",
      "      I here by declare that all the information furnished is true to by best of my knowledge.\n",
      "\n",
      "Place :\n",
      "Date  :                                                       \n",
      "                       \t\t\t\t\t\t\t\t\t         (Guravaiah M)\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Have worked on File Layout, Application Engine, Component Interface, File layout, Excel to CI, XML Reportved the issues the business process..g. Hire, Absence and performance), and external service vendorse Interface Builder (EIB).\n",
      "\n",
      "Processing text:\n",
      "VENKATA SAIKRISHNA\n",
      " Workday Consultant\n",
      "\n",
      "\n",
      "PROFSSIONAL SUMMARY:\n",
      "\t\n",
      "Over all 3 years of IT experience as a Workday Consultant.\n",
      "Integral in maintenance and creation of Workday Supervisory Organizations, Business Process, Locations, Positions, Company, Cost centers, and Hierarchies.\n",
      "Experience in understanding the Client Business Requirements, Organizational Hierarchy Setup, Configurable Security Setup and Tenant Setup.\n",
      "Worked with different Staffing Models, defining Hire restrictions to Job Management, Position Management.\n",
      "Hands on experience with Compensation Module like creating Compensation Grades, Compensation Eligibility Rules, Allowance Plans, Salary Plans, Hourly Plans.\n",
      "Experience in creating Job Profiles, Job Families, and Job Family Group.\n",
      "Experience with Workday security groups like Role based security, User based Security, Intersection, and Job based Security.\n",
      "Experience with creating Staffing models for Supervisory Orgs, Reorganizations and business process framework, Organization Types, Organization Hierarchies.\n",
      "Strong Experience with Workday Report Writer - Custom Reporting (Calculated Fields, Advanced, Standard Reports).\n",
      "Hands on experience in inbound/ outbound integrations using EIB and core connectors.\n",
      "Troubleshooted day to day issues arising in Workday, reporting issues to identify and fix root causes.\n",
      "\n",
      "TECHNICAL SKILLS:\n",
      "\n",
      "\n",
      "PROFESSIONAL EXPERIENCE:\n",
      "\n",
      "Working as Workday Consultant in Value Momentum, from Aug-2018 to Till Date.\n",
      "Role: Workday Consultant\n",
      "Responsibilities:\n",
      "Created Supervisory Organizations, Cost Centers, Cost Centre Hierarchies, and location hierarchies’ maintenance, Staffing Models, Job details Positions and Job Requisitions.\n",
      "Setup end to end recruiting process for clients from creating business processes like job application, Offer, Hire, and Onboarding, setup external career site, questionnaires, offer letters and review documents. \n",
      "Staffing Movements, An employee changes in position, inbound process and outbound process.\n",
      "Termination Process, initiate termination process, review termination process, to do tasks\n",
      "Worked on the creation of benefit plans, job profiles, and job families.\n",
      "Configured Workday compensation packages including salary, bonus, allowance, commission, and compensation eligibility rules based on management levels, job profile, and job family.\n",
      "Managed job description and workflow of employee data for compensation module including job families, pay ranges and supervisor setup.\n",
      "Setup Merit plans including merit and bonus plan processing and created the business process for bonus plan, merit plan, salary plan and hourly plan.\n",
      "Worked on several calculated fields like look up related value, Evaluate Expression, True or false conditions, Arithmetic Calculation, formatting date fields etc... \n",
      "Performed arithmetic calculation in Matrix report for counting, averaging, summing, ranging between maximum and minimum. \n",
      "Worked with Simple and Advanced Reports, defining columns, business objects, fields.\n",
      "Setup security groups, domain security policies and business process security policies.\n",
      "Worked with Business Process and configurations various business process on Compensation, Talent Management, Recruiting, Benefits. \n",
      "Configuration of Workday’s business process framework configured conditional rules to guide workflow or validate data as required to accommodate desired outcomes.\n",
      "Developing the integrations using tool Enterprise Interface Builder (EIB), Core connector\n",
      "Designed and built both inbound and outbound EIB in various segments of Workday system.\n",
      "Environment: EIB, Web services, Workday Report Writing, custom Reports, calculated fields, compensation, MS PowerPoint, MS Excel, Windows.\n",
      "\n",
      "\n",
      "\n",
      "EDUCATION:\n",
      "MBA in HR and Marketing from KL University in 2018.\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "DECLARATION:\n",
      "\n",
      "I do here by declare that all particulars mentioned above are true to the best of my knowledge.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hyderabad\t\t\t\t\t\t\t\t\t                     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Best Regards, Swetha. all the details and particulars furnished above are true to the best of my knowledge.rsity.ion security group. reporting, work assignments.acks. It provides hardware, software, and services to investigate cybersecurity attacks, protect against malicious software, and analyze IT security risks.\n",
      "\n",
      "Processing text:\n",
      "Rahul  (Techno Functional Consultant)  \n",
      "Professional Summary\t\n",
      "Having Around 5+ years of experience in ERP Experience including 3 years in workday HCM and Expertise in Workday HCM , Benefits, Leave of Absence, Integration , Reporting , workday studio .\n",
      "Core Qualifications & Skills\t\n",
      "Involved in Full life cycle Workday implementation experience from requirement gathering to post deployment product support for HCM modules as well as various integrations in workday.\n",
      "Hands on configuring the Various Core HCM, Benefits ,Recruiting, Payroll ,Talent Modules .\n",
      "Expertise in Report writer, EIB, PICOF, DT, Workday Studio, CCW,CCB,BIRT, Calc Fields. \n",
      "Expertise in Payroll integrations from workday to ADP , PS, by using PICOF and PECI .\n",
      "Developed and maintained custom-report types (Advanced, Matrix) using report writer tool.\n",
      "Hands on experience in creating BIRT layouts using Report Designer, for Using Report Designer.\n",
      "Involved in transformation of XML into XSLT for presenting data for different web Services.\n",
      "Expertise In Workday Security, leave absence, recruiting and Configuring the Befit 401 Plan etc.\n",
      "Good Knowledge  Creating leave families , Leave types , and absence condition rules in Module.\n",
      "Experience in inbound/outbound integration using EIB, CCW/CCB, Report Writing, creating Workday Cal fields, Custom report, (Matrix, Composite, trending, Advanced) BIRT tool .\n",
      "Configured the custom Dashboard and Created Reports and added to the various dash boards.\n",
      "Configured BP for leave of absence , Recuring , core HCM, written condition rules for steps etc.\n",
      "Expertise in building EIBs (Enterprise Interface Builder) integration within WD for sending Data\n",
      "Prioritizing, reproducing, and verifying bug fixes in different Workday integrations, reports BP’s.\n",
      "Ability to work creatively , analytically in a problem-solving workday Production environment,\n",
      "Interaction with all work streams including functional, conversion and project management.\n",
      "Expertise in developing Payroll interfaces using PICOF/ PECI with the help of Workday Studio and Document Transformation to  meet client’s complex payroll requirements using DT, Studio.\n",
      "Experience in understanding and gathering the business requirements, translating Functional\n",
      "specifications and develop code along with detailed design, Performed UTP test cases in wd.\n",
      "Excellent client interaction skills and experience in working independently as well as in a team.\n",
      "Developed Several Complex Integrations using Workday Studio and EIB CCW, PICOF, DT.\n",
      "Have good knowledge ETV/XTT functions in Document transformation for validating the data.\n",
      "Having knowledge in XML, WD-SOAP Web Service, and WD- REST Web Service and\n",
      "Experienced in  using such as Soap UI , Postman , XML Exchanger tools for testing API call .\n",
      "Experience on getting requirement from the client and handing sharing the work across team.\n",
      "Hands on experience in creating New security groups,  or updating security groups with various domains , security polices, activating security policies and identifying the security Objects .\n",
      "Professional \n",
      "Working As software Engineer in  Infosys  From Jun 2016 – Till date.\n",
      "\n",
      "\n",
      "Technical- Skills.\n",
      "\n",
      "\n",
      "Education Details:\n",
      "Completed B-Tech from JNTU Anantapur 2016  with 70 %.\n",
      "Project Profile:-\n",
      "Project-2\t   :   Implementation & Support  workday HCM\n",
      "Client\t                 :  CDK Global .\n",
      "Role\t\t   :  Workday Techno Functional Consultant.\n",
      "\n",
      "Description: CDK Global is the largest global provider of integrated information technology and digital marketing solutions to automotive dealerships and manufacturers in more than 100 countries worldwide for the world’s biggest car brands Although we operate on a global scale we are small by comparison and that is a good thing It means that we are still a business where every person matters and where anyone can make an impact on our growth and success We have opportunities in a wide range of business areas so wherever in the world you join us you will get the support training and tools you need to make significant\n",
      "\n",
      "Role and Responsibilities:\n",
      "Understanding the Business Requirements by studying the Functional Documents.\n",
      "Modified the XSLT code as per CR-request and adding the new XSLT for Different info types. \n",
      "Create the new WD studio programs to sending AI-Statement to worker documents using BIRT.\n",
      "Creating the custom reports as per the client requirement and preparing the UTP documents.\n",
      "Created Workday Studio programs to load compensation data from ADP to workday.\n",
      "Created EIB Inbound Integrations for loading the employees personal Information like, Emergency contacts, , One-time payments, Bank account information, cost center information.\n",
      "Created EIB Integrations, written XSLT code and sending data from WD to downstream systems.\n",
      "Hands-on experience in creating the calculated fields using different functions complete logics. \n",
      "Supporting the Different teams in UAT phase as with test factory teams during integration testing.\n",
      "Involved in calls with client and update the work status as well as clarifications if any.\n",
      "Handled Workday Service Upgrade Testing (WD29, WD30) for all the existing integrations\n",
      "Responsible for supporting the new change requests and enhancements in the project.\n",
      "Created calculated fields and worked on simple and advanced, matrix , Trending  reports.\n",
      "Worked on integrations systems (EIB’s, Core Connectors, PICOF.DT, Workday Studio).\n",
      "Day to day support of workday integrations, security, Business Process, and reporting issues.\n",
      "Coordinated with Onshore on requirements gathering, implementation, testing and enhancement of Integration, reports , business Process, EIB,BIRT and  workday studio integrations .\n",
      "Configured various business processes and created notifications to integrations, Reports etc.\n",
      "Design of web services to send/receive between Workday and Third-party system using API call .\n",
      "Developed analytics dashboards , data sources to provide actionable reporting  analytics.\n",
      "Deployed workday objects using Solutions from implementation to UAT, production tenants by following the change management process, solving the migration issues by using OX.\n",
      "Configured Leave family, leave type, Absence rules for countries as per business requirements\n",
      "Involved in Workday version upgrade testing and Scheduling and Monitoring Integrations.\n",
      "Expertise in developing Payroll interfaces using PICOF, PECI with the help of Workday Studio and DT to meet client’s complex payroll requirements sending to Diff payroll Vendors.\n",
      "Experienced in analyzing and preparing Project Deliverables Technical Design Document (TDD).\n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenet to Sandbox and Production using Object Transporter. \n",
      "Created the new outbound integrations to sending the time off corrections Information from workday to ADP payroll system.\n",
      "Project-2\t   :   Implementation & Support  workday HCM\n",
      "Client\t                 :  CDK Global .\n",
      "Role\t\t   :  Workday  PS  Consultant.\n",
      "\n",
      "Description: CDK Global is the largest global provider of integrated information technology and digital marketing solutions to automotive dealerships and manufacturers in more than 100 countries worldwide for the world’s biggest car brands Although we operate on a global scale we are small by comparison and that is a good thing It means that we are still a business where every person matters and where anyone can make an impact on our growth and success We have opportunities in a wide range of business areas so wherever in the world you join us you will get the support training and tools you need to make significant\n",
      "\n",
      "      Role and Responsibilities:\n",
      "Responsible for various customizations of fields, records, pages, components and menus as per the client requirements by using Application Designer\n",
      "Customized JOB DATA component to accommodate few more fields which are using as inputs for other systems and worked on APP engine, SQER, PS query, component Interface .\n",
      "Created CI with AE to import the JOB Requisitions data into PeopleSoft system from file and performed some validations before inserting to PS system.\n",
      "Was involved in functionality of sending Emails notifications through users with help of Send Mail Function.\n",
      "Used Process Scheduler to run scheduled process at a specific time and/or run recursively at a specific interval and used process Monitor to view status of the process.\n",
      "Creating new application engine program for sending employees data to third party system.\n",
      "Generating the Relocation Letters As per HR request and sending to the Daily Process Report to the client.\n",
      "Developed People Code to implement specific business rules and validations to enable the system to perform the business process.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Ramesh A\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "(Workday HCM Consultant)\n",
      "\n",
      "\n",
      "PROFESSIONAL SUMMARY:\n",
      "An ERP Consultant with overall 5+ years of professional IT experience with 3+ years of extensive Workday experience.\n",
      "Exceptional experience in Workday’s Core HR, Staffing and Compensation Functional areas.\n",
      "Hands on experience in Configuring Organizations, Business process and creation of Custom Reports.\n",
      "Experienced on Compensation elements configurations and updates.\n",
      "Involved in requirements analysis, integrations, testing and system documentation support.\n",
      "Creation of various calculated fields to use in custom reports.\n",
      "Configuring EIB Inbound and Load data into workday with webservices.\n",
      "Creation of various custom reports as per the requirements.\n",
      "Working on various enhancements related to EIB Integrations, Custom Reports and Configuration changes.\n",
      "Experience with creating Staffing models for Supervisory Orgs, Reorganizations and business process framework, Organization Types, Organization Hierarchies.\n",
      "Good experienced in developing technical solutions for the Workday platform using EIB and Web Services.\n",
      "Workday training includes Fundamentals, Simple Inbound Integrations, Business Processes, Calculated Fields, Report Writer, and Security Fundamentals.\n",
      "Experience in writing SQL queries and have exposure to different databases, includes SQL Server.\n",
      "Possess Good communication skills, keen to adapt to new technologies and effective Team Player. \n",
      "\n",
      "TECHNICAL SKILLS:\n",
      "\n",
      "\n",
      "EDUCATION:\n",
      "Bachelor of Technology: Mechanical Engineering from Jawaharlal Nehru Technological University – Kakinada.\n",
      "PROFESSIONAL EXPERIENCE:\n",
      "Tata Consultancy Services  \t\t\t \n",
      "Project: Support/Enhancement of Workday HCM\t                               \t\t\t      (May’ 19 – Till date) \n",
      "AIMS Community College, USA\n",
      "Workday HCM Functional Consultant\n",
      "\n",
      "Roles and Responsibilities:\n",
      "Responsible to work on workday application incidents raised by business end users.\n",
      "Troubleshoot the issue to find the root cause of the incident and provide them a solution.\n",
      "Written custom validations on business process object as per business requirement.\n",
      "Modified Business process as add/remove steps from the existing configurations.\n",
      "Changed the security groups on business process security policy functional areas.\n",
      "Modified step condition rules for existing business processes.\n",
      "Developed custom Integrations to update Compensation Eligibility rules, Grade and Grade profiles.\n",
      "Developed Inbound integrations to load job profile and matrix organization per business requirement.\n",
      "Clarify the end user queries and guide new users about workday system functionality.\n",
      "Communicate end users for better understand of the case and update the status of incident.\n",
      "Responsible to Loaded new set of setup data through EIB.\n",
      "Create and modify condition rules as per new business policy changes.\n",
      "Configured new work schedules as requested by the business operations user.\n",
      "\n",
      "\n",
      "Project: Support of Workday HCM                       \t\t\t\t\t(Nov’17 – May’ 19)\n",
      "Safeway, Phoenix, AZ       \t\t\t\t\t\t\n",
      "Workday Reports Developer.\n",
      "\n",
      "Roles and Responsibilities:\n",
      "Worked on Reports to create custom reports using Workday Report Writer to meet the business needs of HR application report consumer groups. \n",
      "Generate different kinds of reports - Simple, Advanced and Matrix reports to meet client requirements within the workday tenant. \n",
      "Create calculated fields for Custom Reports to ensure required report delivery. \n",
      "Developed advanced custom reports, composite reports and matrix reports in Workday and test developed reports.\n",
      "Designedand built both inbound and outbound EIB integrations in various segments of Workday system.\n",
      "Created Organizations (Locations, Supervisory Orgs, Business Units, Cost Centers, Custom orgs, Organization Hierarchy (Location Hierarchy).\n",
      "Create reports by using appropriate data source and business objects to deliver output for end users.\n",
      "Created report on Employee Convert to Contract to full time Employee List.\n",
      "Created report on Contingent workers, converting the contingent workers into employees.\n",
      "Extensively worked on Workday application in creating reports, calculated fields, basic integrations using EIB, data conversion and Migrations.\n",
      "Developed custom reports for the hcm modules like Core HR.\n",
      "Used Report Writer to create new Custom reports with appropriate Data Sources, Objects and Fields\n",
      "Supported Customer resources in development and troubleshooting of reports and integrations.\n",
      "\n",
      "\n",
      "Project: Support of PeopleSoft HCM\t\t\t\t\t\t\t(April’16 – Oct’17)\n",
      "Amdocs\n",
      "PeopleSoft Developer\n",
      "\n",
      "Responsibilities:\n",
      "Analyzed the requirement documents to understand the customer business requirement.\n",
      "Customized system applications and designed many applications as scratch.\n",
      "Work with incident request raised at user end.\n",
      "Interact with onsite team to know status of project on daily basis.\n",
      "Responsible to work on support issues.\n",
      "Consulting with the Solution Architect on business prospective implementation workflow.\n",
      "Collaborating with overseas team-mates on daily/weekly discussions.\n",
      "Analyzing the issues and providing resolutions reported by users\n",
      "Working on Incidents, Service Request and EWO’s (Enhancement Work Orders).\n",
      "Developed custom advanced custom reports, calculated fields, complex xslt logic \n",
      "Coordinate with other team members for defect deliveries and production support activities.\n",
      "Conduct knowledge sharing sessions to newly joined team members.\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Client Management, Partnering with Managers and Business unit heads to determine staffing needs, provide recruiting expertise, design hiring and sourcing strategies, help build a strong talent force.atisfaction levels.Changes, Location Changes, Pay rule/Function/Business Unit Changes.nologies with key HR processes. Responsible for delivering day-to-day HR systems service delivery activities in support of policies and  practices,  this  role  will  primarily  focus  on  supporting  the  management  of  our  external, contingent workforce within the Workday HR system.\n",
      "\n",
      "Processing text:\n",
      "Bachelors in Electronics & Communication Engineering from JNTU-Kakinada, India in 2017. Document transformation, Calculated fields, Workday report writer, XML, XSLT.con.ound/Outbound, Sup Orgs, Business Objects.e great commitment to implement client’s Workday Strategy.\n",
      "\n",
      "Processing text:\n",
      "Seeking suitable positions in Workday HCM  as Techno functional consultant with a reputed organization that would help me utilize my skills and grow as an individual to deliver more for the organization’s growth.                                                                                  \t\t\t                     \n",
      "PROFESSIONAL EXPERIENCE – 4 + years (Serving  Notice).\n",
      "HIGHLIGHTS\n",
      "Workday Integration, Studio, Core HCM, Recruiting, Benefits, Leave of absence. \n",
      "Trainings on Core Financials Integration, Workday Studio.\n",
      "Strong in EIB Inbound & Outbound, Reports, Calculated Fields, Custom Objects, Business Process, Dashboards, CCW/PICOF, Calc Fields, BIRT,\n",
      "Worked on Implementations and Configuration, security, Business Process.\n",
      "Achievements:\n",
      "Successfully completed 2 major Project’s implementations.\n",
      "KT to the new hires, Provide training Internally  .\n",
      "TECHNICAL SKILLS:\n",
      "\n",
      "Workday HCM, Core HCM, Recruiting , LMS , Report Writer, EIB, Calc Fields, Payment Connectors, Workday Studio, Business process, Security, DT. Benefits , Talent etc.\n",
      "Core Connectors, PICOF, Document Transformation, BIRT.\n",
      "People code, App engine, CI.XML, XSLT. \n",
      "Work Experience :\n",
      "\n",
      "Working As a Workday consultant  at  Wipro technologies from  2018 to till .\n",
      "Worked as Software engineer in Infosys  from  2017 AUG  to JULY  2018.\n",
      "\n",
      "Having 4+ years of experience in ERP Experience and including 3 years in workday HCM, completed Workday Integration and Support to the previous project.\n",
      "Excellent functional skills HCM  modules like Core HCM, Leave of Absence, Recruiting, setup etc.\n",
      "Expertise in Configuring business Process for various business process adding steps condition rules.\n",
      "Involved in the project Implementation, Testing, Managing Business, Troubleshooting the issues during the implementation and post implementation support and involved end to end Implementation .\n",
      "Configured various business process related to Leave of Absence ,Condition rule , business process. \n",
      "Good Knowledge ion Creating leave families , Leave types , and absence condition rules in absence.\n",
      "Hands on experience in inbound/ outbound integrations using connectors, Workday studio, BIRT tools.\n",
      "Developed and maintained custom-report types  like advanced, matrix, Composite using report writer. \n",
      "Expertise in Payroll integrations from WD to ADP , PS, NGA  by using PICOF and PECI connectors.\n",
      "Participate in all activities of Workday Project while working with customers during alignment sessions, discovery meetings, touchpoint meetings, customer configuration, testing production support.\n",
      "Familiar with Ticketing tools like Service now and Salesforce, HPLM  for the incidents and CR’s.\n",
      "Expertise in building EIBs (Enterprise Interface Builder) for integration within WD for sending Data.\n",
      "Good knowledge on ETV/XTT functions in DT while sending data from WD to payroll.\n",
      "Hands on experience in Workday security, Functional area, Security polices, Domains Etc.\n",
      "Expertise In workday Leave of absence, recruiting modules and Configuring the Befit 401 Plan etc.\n",
      "Configured business process for leave of absence , Recuring , core HCM, condition rules for steps  etc.\n",
      "Created complex integration using studio for data syncope integration from WD to Different system.  \n",
      "Experience in inbound/outbound integration using EIB, Core Connector, Report Writing, creating Workday Calculated fields, Custom report, (Matrix, Composite Advanced) and BIRT tool .\n",
      "Monitor Workday community portal to find new enhancements that are delivered during new upgrade and implement required enhancements for our business requirement, identifying the updated changes \n",
      "Excellent analytical, problem solving, communication and interpersonal skills with ability to interact with individuals at all levels.  Consistently meets goals, objectives, and target dates.\n",
      "Involved in Workday update testing for all integrations , Supporting to HRIT team based on request.\n",
      "Motivated team player willing to accept exciting challenges with sound of the IT industry.\n",
      "Involved in transformation of XML into XSLT for presenting data for different web Services.\n",
      "Hands on experience in creating New security groups,  or updating security groups with various domains security polices, activating security policies ,identifying the security for business obj\n",
      "Having knowledge in XML, WD-SOAP Web Service, and WD- REST Web Services.\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Created various EIB outbound integrations for sending employees data from WD to external GDW  .\n",
      "Worked on development to add additional functionalities to the existing different PICOF Integrations either in the Workday Studio code level or Configuration level.\n",
      "Developed various Custom Reports for compensation, transfer, etc.\n",
      "Created New matrix Report and sharing to HRIS team and creating ISU and ISSG for reports.\n",
      "Coordinate with users in UAT phase while testing Change request .\n",
      "Developed the studio integration for merging the multiple reports for STI and LTI Amount using workday studio.\n",
      "Created the PICOF Outbound integration to generate the multiple files like Hire, termination, OTP, Allowance details to third party Payroll system.\n",
      "As per SFDC cases, provided the “Start proxy access “to the KL HRSS team to perform transactions. \n",
      "Worked on  migration of data from Sandbox to Production.\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Create various reports as per business (Advanced, Matrix, Composite, Trending, Dash Boards , BIRT).\n",
      " Prepare business requirement specification document and technical documents\n",
      "Responsible for creating custom reports Advance, Matrix, Search, trending and box reports\n",
      "Involved in building EIB outbound integrations for recruitment, core HCM, compensation modules.\n",
      "Worked on building CCW/PECI integrations for extracting the delta changes from workday To ADP.\n",
      "Having good experience in building Studio inbound and outbound integrations.\n",
      "Utilized DT for converting the CCW, PICOF output XML files into text files\n",
      "Having good knowledge on Functional concepts like Business processes , condition rules , To do steps.\n",
      "Hands-on experience In Migrating the XSLT Code, Reports from  Sandbox and Production \n",
      "Involved in configuring security, roles and access restrictions at domain level and BP level.\n",
      "Provide Day to day support of Workday Integrations, and Reporting issues.\n",
      "\n",
      "English, Hindi & Telugu. \n",
      "                                              \t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "Processing text:\n",
      "\n",
      "WORKDAY | HCM | FCM\n",
      "Name \t\t: Kumar S.S\n",
      "Role \t\t: Workday Consultant \n",
      "\n",
      "Professional Summary:\n",
      "\n",
      "Having 6+ years of experience in Workday as a Workday Consultant, and involved in Workday HCM|FCM,  security ,support and enhancement Projects.\n",
      "\n",
      "Having good understand of various Functional areas in HCM as well as Workday Financial.\n",
      "\n",
      "HCM – Core HCM, Absence, Time Tracking, Recruiting, and Benefits.\n",
      "\n",
      "FCM – Procure to Pay, Payables, Business Assets , Expense, Billing and  Revenue. \n",
      "\n",
      "Technically proficient in customizations, enhancements using various tools like Report writer, Calculated Fields, EIB, Core Connector, DT and Workday Studio. \n",
      "\n",
      "Have good experience in various core connector templates like Core Connector worker, PICOFF and PECI.\n",
      "\n",
      "Good Working knowledge workday studio components like workday-In, workday-out Rest, Workday-out Soap, A-sync mediation, Splitter, aggregator, MVEL, Store, CSV-to-XML in Workday Studio.\n",
      "\n",
      "Good Working knowledge in technologies XML, XSLT, SOAP, Web services.\n",
      "\n",
      "Have working experience on PECI (payroll interface effective changes ) and creating custom objects.\n",
      "\n",
      "Have worked on, business process configurations and security areas based on business requirement.\n",
      "\n",
      "Expertise in Report analyst with using Advanced, Matrix and Composite reports. \n",
      "\n",
      "Have worked with incident and change requests for BAU.\n",
      "\n",
      "Worked on creating Complex Calculated Fields using Single Instance, lookup related Value, Lookup As of date fields in Custom reports in Workday HCM. \n",
      "\n",
      "Worked on EIB Inbound to load the data from file to workday system using Web services for cost center, OTP, transfer, Change Emergency contact information etc.\n",
      "\n",
      "Work experience in configuring Business Processes, Security configurations and Developing Reports.\n",
      "\n",
      "Working experience on creating custom object and custom fields As per requirement. \n",
      "\n",
      "Good working experience on security configurations and creating ISU and creating security groups.\n",
      "\n",
      "Good knowledge in migrating reports from lower tenant to sandbox and production using object transporter.\n",
      "Good problem solving and communication skills.\n",
      "\n",
      "Experience Summary:\n",
      "\n",
      "Currently working as workday consultant in ITC InfoTech, Bengaluru from  Oct’2017 to Till date.\n",
      "Worked as senior software engineer in Wipro from July 2014 to Sep 2017.\n",
      "Technical Skills:\n",
      "    \n",
      "\n",
      "\n",
      "Project Summary:\n",
      "\n",
      "Major Projects executed:\n",
      "Project 3# : \n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "Roles and Responsibilities: \n",
      "\n",
      "Created new integration to pull the new hires information using Core Connector Worker and Document Transformation, which uses connector integrations XML Output as its data source input.\n",
      "\n",
      "Created EIB inbound integration for loading data. \n",
      "\n",
      "Creating core connectors integration using  PECI ( payroll effective change interface) template.\n",
      "\n",
      "Developed simple and secure integrations using Workday Enterprise Interface Builder (EIB).\n",
      "\n",
      "Creating custom objects and custom fields and calculated fields as per requirements. \n",
      "\n",
      "Inbound/Outbound Integration Creation using Workday EIB, Core Connectors.\n",
      "\n",
      "Developed the custom reports for sending the Job Anniversary alerts to the Workers managers for initiation the OTP Plan.\n",
      "\n",
      "Developed various Custom Reports such as Lookup and Audit Reports using Calculated Fields.\n",
      "\n",
      "Creating security groups and adding permissions in domain security policies.\n",
      "\n",
      "Involved in creating the inbound integration using Workday studio and Workday out SOAP, router component to load the Compensation data into workday system.\n",
      "\n",
      "Involved in Loading the data for Emergency contacts, cost center, one time payments, bank account details data through enterprise interface builder(EIB) using web services like add updated org, onetime payments etc.\n",
      "\t\t\n",
      "Modified the XSLT code as per CR-request and adding the new XSLT code for Different info types.\n",
      "\n",
      "Hands on experience in using ETV and XTT functions in Document transformation.\n",
      "\n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenet to Sandbox and Production using Object Transporter.\n",
      "\n",
      "Understanding the Business Requirements by studying the Functional Documents.\n",
      "PROJECT  2#\n",
      "\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Created various EIB outbound integrations for sending customer contract data from workday system to all sales mangers email group.\n",
      "\n",
      "Involved in creating the inbound integration using workday studio and workday out soap, router component to load the currency rates into workday system.\n",
      "\n",
      "Worked on worktag configurations and arrange a posting rule set based on worktag functionality.\n",
      "\n",
      "Have worked custom validations in maintain custom validations based on business requirement. \n",
      "\n",
      "Developed the new custom reports for capturing all business process and transactions based on the client requirement and creating the calculated field for transfer, promotion etc.\n",
      "\n",
      "Developed the new custom reports for Supplier and Customer Aging reports and Trail balance and Cash basis reports based on spend and revenue categories.\n",
      "\n",
      "Scheduling the custom reports on daily, weekly, monthly basis based on client requirement.\n",
      "\n",
      "Understanding the requirements from the client and developing new integrations. Experienced to work with Workday Report Writer and creating custom integrations with third party applications using Enterprise Interface Builder (EIB).\n",
      "\n",
      "Track and resolve user support issues with current system Maintain good working relationships with project team members, internal customers (e.g. BI, AR and AP, PO), and external service vendors.\n",
      "\n",
      "Involved in Finance Audit phase and provide access and created audit report based on business need.\n",
      "\n",
      "Have tested for AP and PO modules for newly created Company.\n",
      "\n",
      " Used sequence generators, generating templates and validating inbound integration system results.\n",
      "\n",
      "Created and used calculated fields in reporting, business processes, integrations and other areas within Workday.\n",
      "\n",
      "Involved in Setup security  and  Workday Business process Configuration.\n",
      "\n",
      "\n",
      "PROJECT  1#\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Worked on Application Engine, File Layout, Component Interface and Integration Broker.\n",
      "Designed technical documents and have worked towards development of interfaces and conversions based on design documents.\n",
      "Modified, designed, configured and built fields, records, sub records, setting up keys to records, assign table edits like prompt table.\n",
      "Involved in online changes to the delivered pages, components, menus and translate values.\n",
      "Have Customized and developed Application engines for loading bulk data from external systems.\n",
      "Developed and modified People Code to implement specific business rules and validations to enable the System to perform the business process.\n",
      "Used File Layout Definition to get data from the legacy system to PeopleSoft tables.\n",
      "Managed and monitored process scheduler for any issues while scheduled interfaces/processes ran and resolved the issues.\n",
      "Developed/Modified various PS queries in order to help the client day-to-day activity.\n",
      "Involved in creating PS Query’s and sending it through email to different country FSCM heads.\n",
      "Worked on the reporting tools like PS Query, XML Publisher.\n",
      "Have worked on File Layout, Application Engine, Component Interface, File layout, Excel to CI, XML Report.\n",
      "\n",
      "Educational Summary:\n",
      "\n",
      "M.Tech in computer science and Engineering (C.S.E) from Bharath  University, Chennai in 2009.\n",
      "B.Tech (PE) from Nagarjuna University, Guntur in 2006.\n",
      "\n",
      "Processing text:\n",
      "\u0007lso having experience in Support activities like fixing the errors, scheduling.t.ls ls \"integrated logistics solutions\" across the Asia Pacific region. The division offers a range of transport, warehousing and value-added services. The division operates a fleet of air, sea, rail and road vehicles and vessels. The fleet has more than 19,000 vehicles including courier trucks, prime movers, b-doubles, and trailers; and 13,000 units of containers, ships, vessels and aeroplanes operating across the Asia Pacific region. In Singapore specifically, TGL was reported in 2011 as owning small cargo ships, which ferry container trucks to and from nearby ports in neighbouring Malaysia and Indonesia and a fleet of trucks consisting of about 70 Hino, Fuso and UD prime movers that have roughly seven single trailers for each mover. In Vietnam TGL has over 300 trucks.\n",
      "\n",
      "Processing text:\n",
      "                                                                          \n",
      "Vinay kumar .v\n",
      "Workday Functional Consultant\n",
      "\n",
      "EXPERTISE SUMMARY\t\n",
      "Having 4.2 years of Total Experience in as a Workday  Functional Consultant.\n",
      "Knowledge on the functional modules of Workday (Core HCM, Supervisory Organization, Delegation, Cost Center, Locations and Knowledge on Security).\n",
      "Experience in implementing Workday Functional and Integrations for various modules including HCM Core, Compensation, Time Tracking and Absence Management, Payroll, Benefits and Performance Management.\n",
      "Having good knowledge on Security Groups: Role Based, User Based & Job Based.\n",
      "Experienced in Report Writing, Custom Reports (Simple, Advanced, Matrix and Composite), Calculated Fields, Integrations, EIB, Connectors, XML, XSLT, Workday web services, Organization Structure & Custom Objects. \n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenant to Sandbox and Production using Object Transporter.  \n",
      "Excellent object management skills in Workday like configuring Supervisory Organizations, Matrix Organizations, Compensation (salary based on different grades, allowances), Performance Management, Time Management, Business Process (Hiring and Termination).\n",
      "Strong team player with excellent interpersonal, communication and leadership skills and ready to take an independent challenge and has the ability to work in a team.\n",
      "TECHNICAL SKILLS\n",
      "Workday Skills                   : Reports, Studio, Workday Business Processes, Security, Staffing, Report\n",
      "Writer,          ……………………….Calculated Fields, EIB, Core Connector, Web Services, etc.\n",
      "Languages / Tools             : XML, XSLT & Studio.\n",
      "Document Processing     : Microsoft Excel, Microsoft Word, Microsoft PowerPoint.\n",
      "\n",
      "EDUCATION SUMMARY\t\n",
      "Master of business administration from Narayana engineering College in 2017 with  80%\n",
      "\n",
      "WORK EXPERIENCE\t\n",
      "Working as a Workday Consultant in Tech Mahindra from Sep 2017 to Till Date.\n",
      "\n",
      "PROFESSIONAL SUMMARY\t:\n",
      "\n",
      "Project #1:\n",
      "Company        : Tech Mahindra\n",
      "Project Type  : Workday Support and Enhancements\n",
      "Designation   : Workday Consultant\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Develop new Integrations ( EIB, Core connector) and Custom Reports based on business requirements.\n",
      "Modifications and implementing multiple enhancements to existing, Custom Reports, Calculated field and XSLT.\n",
      "Hands-on experience In Migrating the Reports from Lower tenet to Sandbox and Production using Object Transporter.\n",
      "Worked on Core connector for Template Location, worker, and Document Transformation.\n",
      "Worked on Integration system User for transfer the ownership of reports, schedule and Integration.\n",
      "Worked on Inbound and Outbound EIB Integration concepts and created the various EIB integrations.\n",
      "Configure workday configurable security as per client’s business requirements.\n",
      "Created EIB Inbound Integrations for loading the employees personal Information like Emergency contacts, Compensation, One-time payments, Bank account, cost center information.\n",
      "Monitor daily schedulers and report errors as needed.\n",
      "Developed Core Connector and Document Transformation integrations to get changes file of CSV format from XML Output.\n",
      "Strong Knowledge on working with CR-Change Requests as per business requirement and building and moving changes to production.\n",
      "Involved in performing Mass Loading of data using EIBs.\n",
      "Involved in calls with client and update the work status as well as clarifications if any. \n",
      "Day to day support for Workday HCM, Integrations and Reporting issues.\n",
      "\n",
      "Project #2:\n",
      "Company        : Tech Mahindra\n",
      "Project Type  : PeopleSoft Support and Enhancements\n",
      "Designation   : Analyst\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Have Customized and developed Application engines for loading bulk data from external systems.\n",
      "Track and resolve user support issues with current system Maintain good working relationships with project team members, internal customers, and external service vendors\n",
      "Have designed technical documents and have worked towards development of interfaces and conversions based on design documents.\n",
      "Modified, designed, configured and built fields, records, sub records, setting up keys to records, assign table edits like prompt table.\n",
      "Involved in online changes to the delivered pages, components, menus and translate values.\n",
      "Have Customized and developed Application engines for loading bulk data from external systems.\n",
      "Developed and modified People Code to implement specific business rules and validations to enable the System to perform the business process.\n",
      "Used File Layout Definition to get data from the legacy system to PeopleSoft tables.\n",
      "Managed and monitored process scheduler for any issues while scheduled interfaces/processes ran and resolved the issues\n",
      "Developed/Modified various PS queries in order to help the client day-to-day activity.\n",
      "Worked on the reporting tools like PS Query, XML Publisher\n",
      "Have worked on File Layout, Application Engine, Component Interface, File layout, Excel to CI, XML Report\n",
      "\n",
      "\n",
      "\n",
      "DECLARATION:\n",
      "           I hereby declare that all the information furnished is true to by best of my knowledge.\n",
      "\n",
      "Extraction complete. Data saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import win32com.client  # For .doc files on Windows\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the path to your resumes folder\n",
    "folder_path = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume'\n",
    "\n",
    "# List to store extracted information\n",
    "resume_data = []\n",
    "\n",
    "# Function to extract text from .docx files\n",
    "def extract_text_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "# Function to extract text from .doc files\n",
    "def extract_text_doc(file_path):\n",
    "    word = win32com.client.Dispatch(\"Word.Application\")\n",
    "    doc = word.Documents.Open(file_path)\n",
    "    text = doc.Content.Text\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    return text\n",
    "\n",
    "# Function to extract details using regex or keyword matching\n",
    "def extract_details(text):\n",
    "    # Initialize empty details\n",
    "    details = {\n",
    "        'Skills': 'N/A',\n",
    "        'Experience Level': 'N/A',\n",
    "        'Education Level': 'N/A',\n",
    "        'University': 'N/A',\n",
    "        'Year of Passing': 'N/A',\n",
    "        'Percentage': 'N/A'\n",
    "    }\n",
    "\n",
    "    # Print the text for debugging\n",
    "    print(f\"Processing text:\\n{text}\\n\")\n",
    "\n",
    "    # Updated regex to find specific details\n",
    "    skills_match = re.search(r\"(Skills|Skills:|Skills -|Skills are)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    experience_match = re.search(r\"(Experience Level|Experience|Experience:|Exp)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    education_match = re.search(r\"(Education Level|Education|Education:)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    university_match = re.search(r\"(University|University:|College)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    year_match = re.search(r\"(Year of Passing|Year)[\\s:]*([0-9]{4})\", text)\n",
    "    percentage_match = re.search(r\"(Percentage|Marks)[\\s:]*([0-9]+\\.?[0-9]*)%\", text)\n",
    "\n",
    "    # If matches are found, store the extracted data\n",
    "    if skills_match:\n",
    "        details['Skills'] = skills_match.group(2).strip()\n",
    "        text = text.replace(skills_match.group(0), '')  # Remove this part from remaining text\n",
    "    if experience_match:\n",
    "        details['Experience Level'] = experience_match.group(2).strip()\n",
    "        text = text.replace(experience_match.group(0), '')\n",
    "    if education_match:\n",
    "        details['Education Level'] = education_match.group(2).strip()\n",
    "        text = text.replace(education_match.group(0), '')\n",
    "    if university_match:\n",
    "        details['University'] = university_match.group(2).strip()\n",
    "        text = text.replace(university_match.group(0), '')\n",
    "    if year_match:\n",
    "        details['Year of Passing'] = year_match.group(2).strip()\n",
    "        text = text.replace(year_match.group(0), '')\n",
    "    if percentage_match:\n",
    "        details['Percentage'] = percentage_match.group(2).strip() + '%'\n",
    "        text = text.replace(percentage_match.group(0), '')\n",
    "\n",
    "    return details, text  # Return both extracted details and remaining text\n",
    "\n",
    "# Traverse through the folder and subfolders\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        text = \"\"\n",
    "\n",
    "        # Check the file type and extract text accordingly\n",
    "        if file.endswith('.docx'):\n",
    "            try:\n",
    "                text = extract_text_docx(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "        elif file.endswith('.doc'):\n",
    "            try:\n",
    "                text = extract_text_doc(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Extract details from the text\n",
    "        details, remaining_text = extract_details(text)\n",
    "\n",
    "        # Append folder name, file name, extracted details, and remaining resume text\n",
    "        resume_data.append({\n",
    "            'Folder Name': os.path.basename(root),\n",
    "            'File Name': file,\n",
    "            'Skills': details['Skills'],\n",
    "            'Experience Level': details['Experience Level'],\n",
    "            'Education Level': details['Education Level'],\n",
    "            'University': details['University'],\n",
    "            'Year of Passing': details['Year of Passing'],\n",
    "            'Percentage': details['Percentage'],\n",
    "            'Resume Text': remaining_text.strip()  # The remaining text after extracting key details\n",
    "        })\n",
    "\n",
    "# Convert extracted data to a pandas DataFrame\n",
    "df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Save the extracted data to a CSV file\n",
    "output_file = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Extraction complete. Data saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6be4e17-954d-4336-a7aa-2263114fd1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text:\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "Processing text:\n",
      "  Anubhav Kumar Singh\t\t\n",
      "\n",
      "  To work in a globally competitive environment on \n",
      "  challenging assignments that shall yield the \n",
      "  twin benefits of the job satisfaction and a steady-paced \n",
      "  professional growth.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " Professional Experience\n",
      "\n",
      " 06/2019 - Current\tHCL\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\tCurrent Role: System Admin Offshore\n",
      "\t\t\tSkills : Shell Scripting, Linux , PeopleSoft Administration , Github\n",
      "\n",
      "Managing PeopleSoft HCM and PeopleSoft FSCM production environments along with support environments installed on Linux and Windows OS.\n",
      "Involved in Day to Day activities such as Project Migration, Database Refresh, System admin changes, Tax updates etc.\n",
      "Troubleshooting of various servers like application servers, Web Servers, Process Scheduler Servers.\n",
      "Applying Tuxedo and WebLogic Middleware CPU patches for various applications.\n",
      "Working on shell scripting used as integration method for exchange of files to external systems\n",
      "Installation and troubleshooting of 2-tier setup as per requirement.\n",
      "Reviewing Vulnerabilities reported by Security Teams.\n",
      "Renewal of SSL in Weblogic.\n",
      "Vulnerability remediation whenever a vulnerability is report by RMIS team.\n",
      "Worked on PUM (PeopleSoft Update Manager) and installation through DPK.\n",
      "Working Knowledge of Ansible and Docker.\n",
      "Developing new Shell scripts and troubleshooting Shell Script failures.\n",
      "\n",
      "\n",
      " 07/2017- 06/2019\tTechMahindra\t\t\t\t\t\t\t\t\t\n",
      "\t\t\tRole/Project: Application Support through Automation/Devops Tools and PeopleSoft Admin\n",
      "\t\t\tSkills : Shell Scripting, Linux , PeopleSoft Administration, Jenkins, Ansible\n",
      "\t\t\t\n",
      "\t\t\tProject 1: People Tools 8.55 Upgrade & HCM 9.2 Application Upgrade\n",
      "\t\t\tProject 2: Migration of Applications from NTT Cloud and On-premises to AWS Cloud\n",
      "\n",
      "Worked on shell scripting for various application requirement.\n",
      "Working on Ansible and Jenkins to automated start/stop and various activities of application.\n",
      "Basic knowledge of Docker.\n",
      "Applying SSL certificates on new released applications.\n",
      "Worked on Elastic Search Configuration in PeopleSoft.\n",
      "Gained knowledge in AWS Resources..\n",
      "Strong understanding of Unix architecture/Command and trouble shooting in Unix/Linux platform.\n",
      "Efficient in using Configuration Management & Deployment Tool like Ansible.\n",
      "Good experience in job scheduling via crontab and IBM Tivoli Workload Scheduler (TWS).\n",
      "Having good knowledge in automation using shell scripting \n",
      "Continuous integration management using Jenkins, installing and configuring Jenkins.\n",
      "Responsible for writing Ansible playbook to perform various task\n",
      "Managed administration tasks installation, configuration, applications, troubleshooting, and performance related issue.\n",
      "Applying Tuxedo and WebLogic CPU patches for various applications.\n",
      "Working on Vulnerabilities reported by Security Teams.\n",
      "Reviewing the platform certification information of products, platforms, database servers, web and application servers, browsers, and other products for PeopleTools 8.55.\n",
      "Server Migration to AWS (Amazon Web Service).\n",
      "Installation of PeopleSoft server components Application Servers, Process Scheduler Servers, Tuxedo, Web logic Servers for New release PeopleTools on Unix/Linux Servers.\n",
      "Applying latest patch to PeopleTools.\n",
      "Installing and configuring Change assistant for various upgrade passes.\n",
      "Creating and running PeopleTools Upgrade Job for PeopleTools 8.55 Upgrade.\n",
      "Setting up Performance monitor.\n",
      "Creating new app, web and process scheduler domains post upgrade on new Linux severs.\n",
      "Troubleshooting common Domain boot problems.\n",
      "Identifying and configuring source and target databases in CA for HCM 9.2 application upgrade.\n",
      "Working with HCM PUM Images.\n",
      "Creating Change packages using PUM and applying to Source/Target databases as per requirement.\n",
      "Creating application upgrade job using change assistant.\n",
      "\n",
      "\n",
      " 09/2015 - 07/2017\tSRDT Pvt Ltd. (SRM GROUP)\n",
      "\t\t\tRole/Project: PeopleSoft application and Database Admin\n",
      "\t\t\tSkills : PeopleSoft Administration, Weblogic, Tuxedo, App designer, PUM, PeopleTools \t\t\t\t\tUpgrade, PeopleSoft Campus Application Upgrade.\t\t\t\n",
      "\n",
      "Maintaining 7 Production Environments with 21 supporting environments installed on Windows server 2008 R2 and Oracle 11g.\n",
      "Possess through knowledge and experience in PeopleSoft architecture, administering PeopleSoft server components Application Servers, Process Scheduler Servers, Tuxedo, Web logic Servers, PIA (PeopleSoft Internet Architecture), Integration Broker, Report Nodes, application issues and technical issues.\n",
      "PeopleSoft Skills with experience in Migrations & Production support of PS Applications\n",
      "Exposure in applying PeopleSoft Bundle Updates through Change Assistant.\n",
      "Exposure in working on both Windows & UNIX/Linux Environments with Oracle database.\n",
      "Working knowledge of integration broker.\n",
      "Refreshed Testing, DEV and Pre-PROD from PROD environments.\n",
      "Experience in Troubleshooting of various servers like application servers, Web Servers, Process Scheduler Servers.\n",
      "Experienced in providing 24/7 support on production and development environments.\n",
      "Installation of Database Servers, Web servers and Application Server and PeopleSoft Application (HRMS 9.2,FSCM9.2, CS9.0, CS 9.2,HRMS 9.2) and People Tool (8.53,8.54, 8.55)\n",
      "Installed and Configured SES (Secure Enterprise Search) for HRMS Instance.\n",
      "Experience in Installing Oracle Policy Automation, Oracle Policy Modelling and creating OPA Database in existing database (Oracle)\n",
      "Implemented Single Sign On between PeopleSoft Applications.\n",
      "Implemented PeopleSoft Interaction Hub to integrate external content and information with PeopleSoft applications.\n",
      "Upgraded People Tool 8.53 to 8.54 for Campus 9.0Production Environment.\n",
      "Upgraded People Tool 8.53 to 8.55 for Finance 9.2 Testing Environment.\n",
      "Upgraded application CS 9.0 to 9.2.\n",
      "Configured PUM (PeopleSoft Update Manager) for every new Image.\n",
      "Applying Tax Updates, BUGS and Tailored Change Packages through PUM.\n",
      "Upgraded Oracle Database 11.2.0.1 to 11.2.0.4 using DBUA. \n",
      "Created Instances on People Tools 8.55 to provide Testing environments.\n",
      "Prepared Upgrade Status reports and sheets.\n",
      "Co-ordinated and provided support for offshore projects.\n",
      "Imported Self Signed Certificate into WebLogic to provide secure port access of Instances.\n",
      "Set up of Terminal Server to provide a Central access of People Tools for Technical/Developers.\n",
      "Created tickets to development team and followed up with them to get the resolution for any error occurred. \n",
      "\n",
      "\n",
      "\t\t\tProjects:\n",
      "\n",
      "\t\tClient: DRDO\n",
      "\t\tProject: Single Sign On\n",
      "\t\tRole: PeopleSoft Admin\n",
      "\t\tEnvironment: People Tool 8.50, HRMS 9.1, FSCM 9.1\n",
      "\n",
      "\t\tDescription:\n",
      "\t\tSingle sign-on (SSO) is a property of access control of multiple related, but independent software \t\t\tsystems. With this property a user logs in with a single ID and password to gain access to a \t\t\tconnected system or systems without using different usernames or passwords.\n",
      "\n",
      "\n",
      "\t\tClient: NetApp\n",
      "\t\tProject: Support and Maintenance\n",
      "\t\tRole: PeopleSoft Admin/L2 Support\n",
      "\t\tEnvironment: PeopleTool 8.49, HRMS 8.9\n",
      "\n",
      "\t\tDescription:\n",
      "\t\tHandled IB related issue.\n",
      "\t\tClear process scheduler cache as per weekly maintenance process.\n",
      "\t\tHandled PSADMIN related activities.\n",
      "\n",
      "\n",
      " 11/2013 - 05/2015\tACS                                                                                                                           \n",
      "\n",
      " Personal Details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "PLACE:\t\t\t\t\t\t\t\t\tG. Ananda Rayudu-mentioned information is true to the best of my knowledge.University.. the customization for the PeopleSoft. Demo, Development, Support, Test, and Production instances.\n",
      "\n",
      "Error processing file C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc: Word.Application.Quit\n",
      "Processing text:\n",
      "Murali\n",
      "\n",
      "Experience Summary \n",
      "\n",
      "I have 6 years of experience working in PeopleSoft Administration and performing various infrastructure related activities in PeopleSoft environments. \n",
      "\n",
      "Installed and configured PeopleSoft 9.0,9.1,9.2 Web server, Application server, Database server and Process scheduler \n",
      "server on Windows, UNIX and Linux platforms.\n",
      "Creating Domains for Web server, Application server and Process scheduler server.\n",
      "Applied Patches Manually and applied Maintenance Packs through Change Assistant tool.\n",
      "Experience in DPKs installations.\n",
      "Applying TAX UPDATES and fixes using PUM\n",
      "Migrating projects from one environment to another environment using Application Designer and also through CAPI, STAT tools.\n",
      "Performed Single sign on (SSO)Implementation.\n",
      "Experience in running Compare Reports between pre and Post Migrations.\n",
      "Experience in setting up Client Workstation for Developers and Testers.\n",
      "Involved in Configuration of Integration Broker setting up Between the Modules for sending the Messages.\n",
      "Involved 24/7 production Support to Client.\n",
      "Involved in Running Audit Reports (DDDAUDIT AND SYSAUDIT) for Integrity Checks.\n",
      "Experience in Configuration and Setup the REN server.\n",
      "Configured and Maintained Report Nodes settings.\n",
      "Checked and Clear Cache for the servers.\n",
      "Involved in Troubleshooting of the servers like Application server, web server and Process scheduler server. \n",
      "Worked on Peopletools Upgrade PT8.52 to PT8.55 and 8.55 to 8.57.\n",
      "Installing and configuring Elastic Search 6.1.2\n",
      "\n",
      "Career Profile:\n",
      "\n",
      "Client :Sembcorp , Brazil\n",
      "\n",
      "Description:\n",
      "This project involved active production support in the fields of HRMS 9.2. Additionally also involved in maintenance and enhancement of the system.\n",
      "\n",
      "Responsibility:\n",
      "\n",
      "\n",
      " Installation and setup of People Soft HCM & ELM 9.2 on Oracle.\n",
      " Creating database user, assigning roles & privileges to the users.\n",
      " Maintaining various People Soft instances.\n",
      " Debugging and resolving issues related to application server\\web server\\process    scheduler.\n",
      " Weekly\\monthly database maintains.\n",
      "Performed People tools upgrade from 8.55.14 to 8.57.05.\n",
      "Performing Post refresh Activities.\n",
      "\n",
      "\n",
      "\n",
      "Client :Wipro, IND\n",
      "Platforms : People Tools 8.56, People Soft HCM 9.2.\n",
      "\n",
      "Description:\n",
      "This project involved active production support in the fields of HRMS 9.2. Additionally also involved in maintenance and enhancement of the system.\n",
      "\n",
      "Responsibility:\n",
      " Installation and setup of People Soft HCM 9.2 on Oracle.\n",
      " Creating database user, assigning roles & privileges to the users.\n",
      " Maintaining various People Soft instances.\n",
      " Debugging and resolving issues related to application server\\web server\\process    scheduler.\n",
      " Weekly\\monthly database maintains.\n",
      " Creating and modifying data mover scripts.\n",
      " Migrating projects using CAPI.\n",
      " Applying Patches.\n",
      " Setting up a PeopleSoft Reporting environment for reporting.\n",
      " Interacting with the client for various Production related issues.\n",
      "Applying TAX UPDATES using PUM.\n",
      "Performing Post refresh Activities.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Project Title :People Soft HCM Production Support and Enhancement\n",
      "Client : ASG, USA\n",
      "Platforms : People Tools 8.52,8.54 People Soft HCM 9.0,9.2 DB2\n",
      "AIX 5.1.\n",
      "\n",
      "Description:\n",
      "This project involved active production support in the fields of HRMS 9.0. Additionally also involved in maintenance and enhancement of the system.\n",
      "\n",
      "Responsibility:\n",
      "\n",
      " Installation and setup of People Soft HCM 9.0,9.1 on DB2.\n",
      " Creating database user, assigning roles & privileges to the users.\n",
      " Maintaining various People Soft instances.\n",
      " Debugging and resolving issues related to application server\\web server\\process    scheduler.\n",
      " Weekly\\monthly database maintains.\n",
      " Creating and modifying data mover scripts.\n",
      "Migrating projects using STAT,CAPI.\n",
      " Applying Patches.\n",
      " Setting up a PeopleSoft Reporting environment for reporting.\n",
      " Interacting with the client for various Production related issues.\n",
      "Applying TAX UPDATES using PUM.\n",
      "Performing Post refresh Activities.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technology\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal Details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date:\n",
      "\n",
      "Place:  Hyderabad\n",
      "\n",
      "Processing text:\n",
      "\u0007   bies books, Yoga, Gardening, Surfing.Higher Secondary School,financial application. and financial services company providing services in investment banking, provate banking and asset management and sahred services.ion I work for.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROFILE SUMMARY\n",
      "\n",
      "I have overall 6.8 years’ experience as PeopleSoft Administrator. Installed PeopleTools 8.55 from the scratch including its products. \n",
      "Experience in Peopletools 8.51, 8.54.08, 8.55.07&Application 9.0 and 9.2 (HRMS/FSCM). Deterministic approach towards problem solving & troubleshooting.\n",
      "Proficient in Integration Broker.\n",
      "Upgraded FSCM and HCM applications to PeopleTools 8.55.07 from PeopleTools 8.54.08.\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Graduated B-Tech in Electronics and Communication Engg. from M.V.G.R College of Engineering, Vizianagaram(JNTUK) with an aggregate of 68.93%.\n",
      "Achieved 90% marks in 12th standard. Scored 86% in 10th standard.\n",
      "\n",
      "ACHIEVEMENTS\n",
      "Awarded Bravo in 2015 Q3, 2016 Q1 and Pat on Back in Q2, 2016, Q1, 2017 in Techahindra.\n",
      "Awarded Associate of the month award and Innovator of the month (1 time). Awarded spot and pat on back in Capgemini\n",
      "\n",
      "WORK EXPERIENCE\n",
      "CAPGEMINI (MAY’19 – TILL NOW)\n",
      "Production support for 5 finance environment and their respective non production environments.\n",
      "\n",
      "Project Experience:\n",
      "Project Name \t\t\t\t: AXA\n",
      "Role\t\t\t\t\t: Consultant\n",
      "Environment\t\t\t\t: Windows Server 2012 R2\n",
      "\n",
      "COGNIZANT TECHNOL OGY SOL UT IONS (AUGUS T ' 1 8 – APRIL’19)\n",
      "Voya Financial Insurance US client project which deals with support and managing Finance applications.\n",
      "\n",
      "Project Experience:\n",
      "Project Name \t\t\t\t: Voya Financials\n",
      "Role\t\t\t\t\t: Associate\n",
      "Environment\t\t\t\t: Windows Server 2012 R2\n",
      "\n",
      " TECH MAHINDRA LIMIT ED (JULY ' 1 4 - AUGUS T ' 18)\n",
      "\n",
      "PeopleSoft 9.2 Implemented for HR and FIN application. PeopleSoft 9.2 Implementation project includes 10 PeopleSoft applications, interfaces with third-party applications and interfaces with live production PeopleSoft 9.2 environment in SDLC.\n",
      "\n",
      "Project Experience: Project Name \n",
      "Role Environment\n",
      "\n",
      ": CIO COMMON\n",
      ": Software Engineer\n",
      ": SOLARIS, Windows Server 2008R2\n",
      "\n",
      "\n",
      "RESPONSIBILITIES:\n",
      "Provided administrative supports for PEOPLESOFT tools version 8.51, 8.54, 8.55.25, 8.56.10 and application HRMS 9.0, 9.2 & Financials/SCM 9.0, 9.2 modules on Windows and UNIX OS\n",
      "Creation of indexes for tables from application designer.\n",
      "PeopleSoft Database Setup, troubleshooting issues and other daily PeopleSoft admin activities\n",
      "Configured PeopleSoft application server, process scheduler & web server domains, setup Master Scheduler.\n",
      "Installing Oracle Tuxedo, Weblogic, Java, Application Disk (FSCM and HCM) and Oracle database on UNIX and Windows servers from scratch\n",
      "Installed PeopleTools 8.55 for HCM and FSCM with a demo database. Upgraded FSCM application to Peopletools 8.55 from PeopleTools 8.54.08. Applied patch 8.55.07 in FSCM\n",
      "Configured Report Nodes. Bouncing of App, Web and Process schedulers and clearing cache\n",
      "Performed pre-refresh and post refresh activity during Database cloning activity.\n",
      "Recompilation of COBOL source codes\n",
      "Worked on project migrations using Application Designer and Change Assistant.\n",
      "Applied image 15, 16, 25 and 37 on FSCM 9.2 using PUM and change assistant. Good hands-on experience in application designer, data mover, and change assistant. Well aware of PIA (PeopleSoft Internet Architecture).\n",
      "\n",
      "Configuring Integration broker and report nodes\n",
      "Creating UDM file transfer Interfaces and monitoring them\n",
      "Deploying gnupg keys and certificates in servers.\n",
      "Installed and configured Elastic search. \n",
      "TOOLS USED:\n",
      "PeopleTools 8.54.08, 8.56.10, 8.55.25, Application Designer, Data Mover\n",
      "Toad, Sqldeveloper, Microsoft SQL Management Studio 2014 \n",
      "Oracle 11g, Oracle 12c, Microsoft SQL server 2014\n",
      "Filezilla, Winscp, PCOMM, TWS, Service now, Silva\n",
      "\n",
      "TRAINING & CERTIFICATIONS\n",
      "Oracle Cloud Infrastructure Architect Associate\n",
      "Oracle Cloud Infrastructure Architect Professional\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Prepared copy of production database, tasks involved were to run audit reports DDDAUDIT and SYSAUDIT ler Server.es and Applied related Database patches and Application Patches.O to manage database transactions, and Jolt, TUXEDO's counterpart, to facilitate transaction requests issued from the Internet. Both TUXEDO and Jolt are products of BEA Systems\n",
      "\n",
      "Processing text:\n",
      " PeopleSoft Admin\n",
      "VARKALA VIKAS\n",
      "\n",
      "Career Objective:\n",
      "\n",
      "I have total 4.2 Years’ Experience in PeopleSoft Admin and PeopleSoft DBA. I hope to enhance my skill set while adding value to the business, to enable implementation of solutions, which aid the company’s objectives, understanding and anticipating the needs, interests and motivations of the clients and to deliver on time, budget and to quality, delivering value through improving agility, quality and reliability\n",
      "\n",
      "Professional Summary:\n",
      "\n",
      "Having 4.2 years of experience in PeopleSoft implementation, Support, People Tools Upgrades, configuration, migrations, maintenance and administration of Application Server Domains, Process Scheduler Servers, Web Server Domains, PUM and Elastic search.\n",
      "Involved in various Tools and Application Upgrades.\n",
      "Experience in driving Infrastructure Hardware Upgrades, Disaster Recovery Activities.\n",
      "Configured https and secure web server (SSL) administration.\n",
      "Monitor system by developing and maintaining monitoring Shell scripts\n",
      "Experience in Oracle Database Administration for 11gR2, 12cR1 and 12cR2\n",
      "Experience in Health Check for all the PeopleSoft Environments\n",
      "Experience in PeopleSoft Database Refreshes from Production to Development and Testing Environments\n",
      "Experience in Performance and Tuning of Application Servers, Web Servers\n",
      "Experience in Windows Administration\n",
      "Implemented PeopleSoft Internet Architecture (PIA) on Demo, Test, Development and Production instances.\n",
      "Extensively involved in resolving Performance issues.\n",
      "Experience in PeopleSoft Installations of PeopleTools 8.56,8.57 HCM 9.2, WebLogic 12cr2 Tuxedo 12cR2 and People Books 8.56,8.57 Windows 2012R2\n",
      "In depth experience on PeopleSoft Update Manager (PUM) for applying PeopleTools patches, Application Bundles on PeopleTools and HRMS 9.2 and FSCM 9.2 Applications\n",
      "In Depth Experience in Integration Broker setup.\n",
      "Experience in Secure Socket Layer (SSL) implementation on PeopleSoft.\n",
      "Proficiency in creation and configuration and administration of Application Server Domains, Process scheduler Domains, Web Server Domains\n",
      "Experience in Reconfiguration of Application Server Domains, Process Scheduler Server Domains and Web Server domains.\n",
      "Experience in Project Migrations using Application Designer and Data Migrations using Data Mover\n",
      "Experience in generating Pre-compare reports and Post Compare Reports between various environments.\n",
      "\n",
      "Experience in setting up client Work Station for developers and testers.\n",
      "Experience in resolving developer issues like resetting passwords, locking and unlocking user accounts.\n",
      "Maintain the workflow of PeopleSoft users.\n",
      "Worked on applying Patches, Bundles and Tax Updates using Change Assistant and\n",
      "PeopleSoft Update Manager (PUM)\n",
      "Installing and Configuring Change Assistant to apply bundles and tax-updates.\n",
      "Involved in setup configuration of Integration Broker in Financials and HCM Applications.\n",
      "Maintaining integrity and internal consistency of the database using DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Experience on clearing the cache of all servers such as Application Server Domains, Web Server Domains and Process Scheduler servers on a regular basis.\n",
      "Monitor the log files to find out bottleneck of the status of servers\n",
      "Maintaining and troubleshooting various servers like Application Server domains, Process Scheduler Domains and Web Server Domains\n",
      "Regularly involved in doing Database Cloning and Refreshing on PeopleSoft Instances.\n",
      "Experience in Installing COBOL Software and compilation.\n",
      "Experience in Tuning of Application Server Domains, Process Scheduler Domains and Web Server Domains.\n",
      "In Depth Experience in PeopleSoft Database Performance and Tuning\n",
      "Experience in Data Guard (DR) support\n",
      "Experience in Database patching.\n",
      "Experience in PeopleSoft Database Refreshes using RMAN.\n",
      "Good team player and a proven individual contributor\n",
      "\n",
      "\n",
      "Area of Technical Skills:\n",
      "\n",
      "Educational Qualification:\n",
      "B.SC from Osmania university in 2017.\n",
      "\n",
      "Professional experience:\n",
      "Worked as PeopleSoft Administrator/ PeopleSoft DBA with Progile infotech Pvt LTD from July 2017 to till date.\n",
      "Project Experience and Achievement’s:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Client\t:\tHartford Insurance Group, Hartford, CT.\n",
      "Project\t:\tInstall, Configure and Production Support of PeopleSoft Applications and Databases.\n",
      "Environment\t:\tPeople Tools 8.57,8.56,8.55 HRMS9.2, FSCM9.2, Oracle 12c,\n",
      "Tuxedo 12cR2, Oracle WebLogic 12cR2, Windows Server 2012 R2, Oracle Enterprise Linux 5,6.\n",
      "Role\t:\tPeopleSoft Admin/PeopleSoft DBA\n",
      "Duration\t:\tJuly 2017 to till date\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Monitoring the day-to-day working of the system.\n",
      "Build Verification Test – To check proper installation and running of all PeopleSoft components, processes and reports.\n",
      "Object Migration between different instances involving compare reports, building objects etc.\n",
      "Involved in Implementation of PeopleSoft Internet Architecture (PIA) including Application Servers, Web Servers and Batch Servers.\n",
      "Handled Security Management tasks like creating new user profiles, roles, permission lists and granting privileges.\n",
      "Handled Application Management tasks like Applying Patches & Fixes.\n",
      "Configured workstation for PeopleSoft developers on their VM's for accessing PeopleTools like Application designer, Data Mover, Administrating Application Server and Process Scheduler Server using PSAdmin utility\n",
      "\n",
      "Migration of all PeopleSoft projects to DEV, TEST and PROD instances.\n",
      "Analysis of production issues raised by clients and providing solutions.\n",
      "Report Node configurations.\n",
      "Worked on Project Migrations and Data Migrations.\n",
      "Generating Compare Reports.\n",
      "Downloading Patches, Tax updates & applied to the environments and maintains the customizations for the PeopleSoft.\n",
      "Experience in applying Patches, Bundles and Tax Updates using Change Assistant and\n",
      "PeopleSoft Update Manager (PUM)\n",
      "Installing and Configuring Change Assistant to apply Change packages and tax-updates.\n",
      "Appling Patches for Demo, Dev, Test and Production Environments.\n",
      "Configuring and monitoring Process Scheduler and troubleshooting various issues related.\n",
      "\n",
      "Involved in the Performance of the databases and application by creating multiple domains across the instances\n",
      "Troubleshooting  of  Application  Server  Domains,  Process Scheduler Domains\tand\tWeb Server Domains\n",
      "Configure Https and secure web server (SSL) administration\n",
      "Setup load Balancer configuration and application server clustering setups / Master Process scheduler set up for high availability systems\n",
      "Performed data migration using data pump and data mover utilities\n",
      "Load balancing of Application server & Web server.\n",
      "Setup Application Security using User Profiles, Roles and Permission lists.\n",
      "Refreshing PeopleSoft test environment for synchronisation to production.\n",
      "Maintaining   integrity   and   internal   consistency   of   the   database\tusing DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Involved in 24/7 Production Support to clients.\n",
      "Checked and cleared the application server cache on a regular basis as a maintenance process.\n",
      "Installed People Books and configured the Web Server to access People Books.\n",
      "Configured and maintained Report Nodes and Settings.\n",
      "Generating compare reports between various environments.\n",
      "Documenting all support issues with their resolutions and feedback.\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "Processing text:\n",
      "Involved in Logical Backups using Data Pump Technology.ups.nd HRMS9.2 using PeopleSoft PUM.ains. the instances.ons and profiles to users. file systems, application servers, web servers and batch servers.d batch servers.\n",
      "\n",
      "Processing text:\n",
      ".   menting all support issues with their resolutions and feedback.le Books.ntenance process. AUDIT reports periodically.ilability systemsn Server Domains, Process Scheduler Servers, Web Server Domains., Process Scheduler Servers, Web Server Domains, PUM  and SES.rstanding and anticipating the needs, interests and motivations of the clients and to deliver on time, budget and to quality, Delivering value through improving agility, quality and reliability\n",
      "\n",
      "Processing text:\n",
      "PeopleSoft Administration\n",
      " \n",
      "Vivekanand Sayana                                                                                                                                                                                                           \t\n",
      "\n",
      "Career Objective: \n",
      "\n",
      "With my valid expertise of 7.5 years in PeopleSoft, I hope to enhance my skill set while adding value to the business, to enable implementation of solutions, which aid the company’s objectives, understanding and anticipating the needs, interests and motivations of the clients and to deliver on time, budget and to quality, delivering value through improving agility, quality and reliability\n",
      "\n",
      "Professional Summary:\n",
      "\n",
      "Over 7.5 years of experience in PeopleSoft implementation, Support, configuration, migrations, maintenance and administration of Application Server Domains, Process Scheduler Servers, Web Server Domains, PeopleTools Upgrades, Application Updates, PUM, SES and Elastic Search. \n",
      "Experience in integration activities between various PeopleSoft Financials, HRMS, EPM and FSCM environments. \n",
      "Extensively involved in resolving Performance issues.\n",
      "Experience in driving Infrastructure Hardware Upgrades, Disaster Recovery Activities. \n",
      "Experience in Health Check for all the PeopleSoft Environments\n",
      "Experience in PeopleSoft Database Refreshes from Production to Development and Testing Environments\n",
      "Experience in Performance and Tuning of Application Servers, Web Servers\n",
      "Performed 3 full life cycle implementations in PeopleSoft.\n",
      "Implemented PeopleSoft Internet Architecture (PIA) on Demo, Test, Development and Production instances.\n",
      "Experience in PeopleSoft Implementation on PeopleTools 8.56, FSCM 9.2, Web Logic 12.2.1, Tuxedo 12.2.2 and Oracle 12c R2 on Oracle Enterprise Linux 7 and Windows 2012 R2.\n",
      "Experience in PeopleSoft Installations of PeopleTools 8.55, HCM 9.2, WebLogic 12.1.3,\n",
      "Tuxedo 12.1.3 and People Books 8.55 on Oracle Enterprise Linux 6 and Windows 2012R2\n",
      "Experience in PeopleSoft Installations of PeopleTools 8.54, HCM 9.2, Weblogic 12.1.2, Tuxedo 12.1.0 and People books 8.54 on windows 2012 R2 and Oracle Enterprise Linux 6.\n",
      "Experience in PeopleSoft Installations of PeopleTools 8.53, FSCM 9.2, Weblogic 10.3.6, Tuxedo 10.3 and People Books 8.53 on windows 2008 R2 and Oracle Enterprise Linux 5.4\n",
      "Experience in PeopleSoft Installations of PeopleTools 8.50, HCM 9.1,Weblogic 10.3, Tuxedo 10.3, Oracle 10g R2 and People Books 8.50 on Windows Server 2003 and Oracle Enterprise Linux 5.\n",
      "In depth experience on PeopleSoft Update Manager (PUM) for applying PeopleTools patches, Application Bundles on PeopleTools 8.53, 8.54 and HRMS 9.2 and FSCM 9.2 Applications, Using DPK’s to deploy PUM latest Images and DPK’s to Install, Middle tier, App Tier and PeopleTools.\n",
      "In Depth Experience in Integration Broker Troubleshooting.\n",
      "Proficiency in creation and configuration and administration of Application Server Domains, Process scheduler Domains, Web Server Domains \n",
      "Experience in Reconfiguration of Application Server Domains, Process Scheduler Server Domains and Web Server domains.\n",
      "Experience in Project Migrations using Application Designer and Data Migrations using Data Mover\n",
      "Experience in generating Pre-compare reports and Post Compare Reports between various environments.\n",
      "Experience in setting up client Work Station for developers and testers.\n",
      "Experience in resolving developer issues like resetting passwords, locking and unlocking user accounts.\n",
      "Maintain the workflow of PeopleSoft users.\n",
      "Worked on applying Patches, Bundles and Tax Updates using Change Assistant and PeopleSoft Update Manager (PUM)\n",
      "Installing and Configuring Change Assistant to apply bundles and tax-updates.\n",
      "Involved in setup configuration of Integration Broker in Financials and HCM Applications.\n",
      "Maintaining integrity and internal consistency of the database using DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Experience in load balancing of Application server domains and Process Scheduler Servers.\n",
      "Experience on clearing the cache of all servers such as Application Server Domains, Web Server Domains and Process Scheduler servers on a regular basis.\n",
      "Monitor the log files to find out bottleneck of the status of servers\n",
      "Experience in Troubleshooting of Data mover while installing PeopleSoft.\n",
      "Maintaining and troubleshooting various servers like Application Server domains, Process Scheduler Domains and Web Server Domains\n",
      "Experience in Tuning of Application Server Domains, Process Scheduler Domains and Web Server Domains.\n",
      "Strong communication, collaboration, team building and inter-personal skills\n",
      "Good team player and a proven Individual contributor\n",
      "\n",
      "Area of Technical Skills:\n",
      "\n",
      "Educational Qualification:\n",
      "\n",
      "MBA (HR & Marketing) from KBN College, Nagarjuna University, Vijayawada in 2011.\n",
      "\n",
      "B.Sc (Bachelor of Science) from SRR & CVR College, Nagarjuna University, Vijayawada in 2009.\n",
      "Professional experience:\n",
      "\n",
      "Worked as PeopleSoft Systems Administrator in Capgemini Technology Services India Limited from Feb 2020 to Sept 2020.\n",
      "Worked as PeopleSoft Systems Administrator in Cognizant Technology Solutions India Pvt Ltd from Oct 2017 to Sept 2019.\n",
      "Worked as Associate - PeopleSoft Administrator with A&A Innovative Solutions Pvt. Ltd from Jan 2013 to Oct 2017.\n",
      "\n",
      "Project Experience and Achievement’s\n",
      "\n",
      "Client\t\t\t: \tDisney (Fox Entertainment) & Allegis \n",
      "\n",
      "Environment \t\t:\tHCM, FSCM & ELM 9.2, People Tools 8.56, Oracle 12c, \n",
      "                                                WebLogic 12.2.1, Tuxedo 12.2.2, Red Hat Enterprise Linux 6.      \n",
      "\n",
      "Role\t\t\t:           Sr. PeopleSoft Admin/PeopleSoft DBA \n",
      "                                                \n",
      "Duration                     :           Feb 2020  to Sept 2020\n",
      "\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Involved in PeopleTools upgrade from PeopleTools 8.55 to 8.57\n",
      "Involved in Application update from FSCM 9.2.017 to FSCM 9.2.032\n",
      "Strong experience on PeopleSoft PUM server installation and troubleshooting.\n",
      "Applying fixes, patches and bundles for PeopleSoft FSCM92 and HRMS92 using PeopleSoft PUM. \n",
      "Worked intensively on performance tuning of PIA architecture based on load testing and up scaling architecture to support the expected load\n",
      "Created a dedicated Integration Broker gateway as message volume was high and for easy maintenance. \n",
      "Redesigned and Configured High availability and load balancing for existing PeopleSoft \n",
      "Internet Architecture. \n",
      "Responsible for the daily maintenance and troubleshooting of complex hosted solutions\n",
      "Monitoring the day-to-day working of the system.\n",
      "Handled Application Management tasks like Applying Patches & Fixes.\n",
      "Load balancing of Application server & Web server, Performed Database Refreshes, Imports, Exports and Backups.\n",
      "Object Migration between different instances involving compare reports, building objects etc. \n",
      "Monitoring Application servers, web servers and process scheduler errors\n",
      "Check the reports for status Blocked, queued, processing, no success etc. Error Log Attached, Check the Reports Ran to Success\n",
      "Perform Remote call test\n",
      "Check the integration broker\n",
      "Check the Server Disk space, Load level, PeopleSoft ping under acceptable level\n",
      "Status of Housekeeping activities (Checking and Cleaning up the logs)\n",
      "Daily perform Project Migrations and Data Migrations.\n",
      "Generate Compare Reports between various environments.\n",
      "Checked and cleared cache on all servers such as Application Servers, Web Servers, and Process Scheduler Servers on a regular basis as a maintenance process.\n",
      "Maintain the workflow of PeopleSoft users.\n",
      "Download Updates and Fixes and apply to the environments and maintain the customizations for the PeopleSoft.\n",
      "Download PeopleSoft Update Image and Apply to the Applications.\n",
      "Applied Patches and Tax Updates.\n",
      "Installed and Configured Change Assistant to apply PUM image. \n",
      "Maintaining integrity and internal consistency of the database using DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Performed Jolt failover and load balancing of Application Server Domains and Process Scheduler Servers Domains.\n",
      "Involved in the Performance of the databases and application by creating multiple domains across the instances.\n",
      "Monitor the log files to find out bottleneck of the status of servers\n",
      "Troubleshoot of Data mover while installing PeopleSoft.\n",
      "Troubleshooting of Process Scheduler servers if the jobs are stacked on a Queue.\n",
      "Maintain and troubleshoot various servers like Application Servers, Process Scheduler Servers and Web Servers.\n",
      " Involved in doing Refreshing on PeopleSoft instances weekly twice or thrice.\n",
      "Documenting all support issues with their resolutions and feedback.\n",
      "\n",
      "\n",
      "Client\t\t\t: \tInter-Continental Hotels Group\n",
      "\n",
      "Environment \t:\tFSCM 9.2, People Tools 8.56, Oracle 12c, \n",
      "                                                WebLogic 12.2.1, Tuxedo 12.2.2, Red Hat Enterprise Linux 6.      \n",
      "\n",
      "Role\t:           Sr. PeopleSoft Admin/PeopleSoft DBA \n",
      "                                                \n",
      "Duration                     :           Oct 2017 to Sept 2019\n",
      "\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Involved in PeopleTools upgrade from PeopleTools 8.54 to 8.55\n",
      "Involved in Application update from FSCM 9.2.006 to FSCM 9.2.016\n",
      "Strong experience on PeopleSoft PUM server installation and troubleshooting.\n",
      "Applying fixes, patches and bundles for PeopleSoft FSCM92 and HRMS92 using PeopleSoft PUM. \n",
      "Perform Remote call test\n",
      "Check the integration broker\n",
      "Check the Server Disk space, Load level, PeopleSoft ping under acceptable level\n",
      "Status of Housekeeping activities (Checking and Cleaning up the logs)\n",
      "Daily perform Project Migrations and Data Migrations.\n",
      "Generate Compare Reports between various environments.\n",
      "Checked and cleared cache on all servers such as Application Servers, Web Servers, and Process Scheduler Servers on a regular basis as a maintenance process.\n",
      "Maintain the workflow of PeopleSoft users.\n",
      "Download Updates and Fixes and apply to the environments and maintain the customizations for the PeopleSoft.\n",
      "Download PeopleSoft Update Image and Apply to the Applications.\n",
      "Applied Patches and Tax Updates.\n",
      "Installed and Configured Change Assistant to apply PUM image. \n",
      "Maintaining integrity and internal consistency of the database using DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Performed Jolt failover and load balancing of Application Server Domains and Process Scheduler Servers Domains.\n",
      "Involved in the Performance of the databases and application by creating multiple domains across the instances\n",
      "Monitor the log files to find out bottleneck of the status of servers\n",
      "Setup Master/Slave load balance for pub/sub services\n",
      "Worked intensively on performance tuning of PIA architecture based on load testing and up scaling architecture to support the expected load\n",
      "Created a dedicated Integration Broker gateway as message volume was high and for easy maintenance. \n",
      "Redesigned and Configured High availability and load balancing for existing PeopleSoft \n",
      "Internet Architecture. \n",
      "Responsible for the daily maintenance and troubleshooting of complex hosted solutions\n",
      "Monitoring the day-to-day working of the system.\n",
      "Handled Application Management tasks like Applying Patches & Fixes.\n",
      "Load balancing of Application server & Web server, Performed Database Refreshes, Imports, Exports and Backups.\n",
      "Object Migration between different instances involving compare reports, building objects etc. \n",
      "Monitoring Application servers, web servers and process scheduler errors\n",
      "Check the reports for status Blocked, queued, processing, no success etc. Error Log Attached, Check the Reports Ran to Success\n",
      "Troubleshoot of Data mover while installing PeopleSoft.\n",
      "Troubleshooting of Process Scheduler servers if the jobs are stacked on a Queue.\n",
      "Maintain and troubleshoot various servers like Application Servers, Process Scheduler Servers and Web Servers.\n",
      " Involved in doing Refreshing on PeopleSoft instances weekly twice or thrice.\n",
      "Generating weekly status reports on all support issues to delivery manager\n",
      "Documenting all support issues with their resolutions and feedback.\n",
      "\n",
      "\n",
      "Client\t\t\t: \tBaylor Scott and White\n",
      "\n",
      "Environment\t:           HRMS 9.2, People Tools 8.55, Oracle 12c, \n",
      "                                                WebLogic 12.1.2, Tuxedo 12.1.1, Red Hat Enterprise Linux 6.      \n",
      "                       \n",
      "Role\t:           Sr. PeopleSoft Admin/PeopleSoft DBA \n",
      "                                                \n",
      "Duration                     :           Jun 2013 to Oct 2017\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Strong experience on PeopleSoft PUM server installation and troubleshooting.\n",
      "Applying fixes and patches bundles for PeopleSoft FSCM92 and HRMS92 using PeopleSoft PUM. \n",
      "Setup Master/Slave load balance for pub/sub services\n",
      "Worked intensively on performance tuning of PIA architecture based on load testing and up scaling architecture to support the expected load\n",
      "Created a dedicated Integration Broker gateway as message volume was high and for easy maintenance. \n",
      "Redesigned and Configured High availability and load balancing for existing PeopleSoft \n",
      "Internet Architecture. \n",
      "Responsible for the daily maintenance and troubleshooting of complex hosted solutions\n",
      "Monitoring the day-to-day working of the system.\n",
      "Handled Application Management tasks like Applying Patches & Fixes.\n",
      "Load balancing of Application server & Web server, Performed Database Refreshes, Imports, Exports and Backups.\n",
      "Object Migration between different instances involving compare reports, building objects etc. \n",
      "Monitoring Application servers, web servers and process scheduler errors\n",
      "Check the reports for status Blocked, queued, processing, no success etc. Error Log Attached, Check the Reports Ran to Success\n",
      "Perform Remote call test\n",
      "Check the integration broker\n",
      "Check the Server Disk space, Load level, PeopleSoft ping under acceptable level\n",
      "Status of Housekeeping activities (Checking and Cleaning up the logs)\n",
      "Daily perform Project Migrations and Data Migrations.\n",
      "Generate Compare Reports between various environments.\n",
      "Checked and cleared cache on all servers such as Application Servers, Web Servers, and Process Scheduler Servers on a regular basis as a maintenance process.\n",
      "Maintain the workflow of PeopleSoft users.\n",
      "Download Updates and Fixes and apply to the environments and maintain the customizations for the PeopleSoft.\n",
      "Download PeopleSoft Update Image and Apply to the Applications.\n",
      "Applied Patches and Tax Updates.\n",
      "Installed and Configured Change Assistant to apply PUM image.\n",
      "Perform setup of Integration Broker between various environments for HRMS and FSCM. \n",
      "Maintaining integrity and internal consistency of the database using DDDAUDIT, SYSAUDIT, ALTERAUDIT reports periodically.\n",
      "Performed Jolt failover and load balancing of Application Server Domains and Process Scheduler Servers Domains.\n",
      "Involved in the Performance of the databases and application by creating multiple domains across the instances\n",
      "Monitor the log files  to find out bottleneck of the status of servers\n",
      "Troubleshoot of Data mover while installing PeopleSoft.\n",
      "Troubleshooting of Process Scheduler servers if the jobs are stacked on a Queue.\n",
      "Maintain and troubleshoot various servers like Application Servers, Process Scheduler Servers and Web Servers.\n",
      " Involved in doing Refreshing on PeopleSoft instances weekly twice or thrice.\n",
      "Generating weekly status reports on all support issues to delivery manager\n",
      "Documenting all support issues with their resolutions and feedback.\n",
      "\n",
      "Processing text:\n",
      "\u0007PeopleSoft HCM 8.80, People Tools 8.48.er user requirement.animalsetailer in the United States, with corporate offices in San Diego and San Antonio. Petco sells 9.2, PeopleTools to 8.56.16 and Oracle 12c DB.\n",
      "\n",
      "Processing text:\n",
      "=========================================================================================== 2014 .ths. be resolved within stipulated timeline.isher Report, Form etc.\n",
      "\n",
      "Processing text:\n",
      "Team lead activities like resource planning and management, quarterly appraisal discussion, estimations and reporting etc.as per the requirements.l as Hierarchy roll-ups for specific trees. It has a workflow mechanism that automatically routes the request through various approval channels based on pre-defined rules. The system holds mappings between Book data in GBM and more than 50 transaction systems that are connected with GBM. The primary use of GBM is to serve as a Golden Source of information for all books and related attributes which originates from GBM defined across all applications globally.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Having 4.6 years of experience in PeopleSoft application enhancement, implementation, Data conversion, Support and Upgrade projects. Well experienced on People tools and having Functional knowledge HCM and FSCM Applications.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Bachelor of Technology (B-Tech) from JNTU-K\n",
      "   Currently Working as a People Soft Consultant in Randstad, Hyderabad\n",
      "\n",
      "\n",
      "PeopleSoft Consultant – Randstad, Hyderabad, Andhra Pradesh, India (June 2020 to till date)\n",
      "Project:  Randstad (Enhancements)\n",
      "Client:    Randstad Staffing \n",
      "Responsibilities:\n",
      "Analyze the requirement documents to understand the customer business requirement.\n",
      "Provide the technical approach for each FDD assign me.\n",
      "Customize the system applications and designed many objects from scratch.\n",
      "Write people code to implement the business logic.\n",
      "Design custom Application engine programs to process the data.\n",
      "Design Application engine programs to send notifications.\n",
      "Responsible to prepare unit test cases and technical design documents.\n",
      "Responsible to support SIT and UAT.\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code, Component Interface, Application Packages), PeopleSoft HCM, Oracle, Windows.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technical Associate – Verizon, Hyderabad, Andhra Pradesh, India (Dec 2018 to May-2020)\n",
      "Project:  Verizon Wireless (Development)\n",
      "Client:    Verizon\n",
      "Responsibilities:\n",
      "Analyze the requirement documents to understand the customer business requirement.\n",
      "Provide the technical approach for each FDD assign me.\n",
      "Customize the system applications and designed many objects from scratch.\n",
      "Write people code to implement the business logic.\n",
      "Design custom Application engine programs to process the data.\n",
      "Design Application engine programs to send notifications.\n",
      "Implemented component interface program to load data into people soft.\n",
      "Used file layout in inbound programs.\n",
      "Responsible to prepare unit test cases and technical design documents.\n",
      "Responsible to support SIT and UAT.\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code, Component Interface, Application Packages), PeopleSoft FSCM 9.1, Oracle, Windows.\n",
      "\n",
      "\n",
      "Software Engineer – HSBC, Hyderabad, India (Aug 2016 to Nov 2018)\n",
      "Project:  HSBC (Upgrade Project)\n",
      "Client:    HSBC Bank\n",
      "Responsibilities:\n",
      "Analysis and Understand the Source and Target system business process.\n",
      "Compare the objects between source and targets and identify the changes.\n",
      "Retrofit all the objects based on compare reports.  \n",
      "Unit testing and prepare unit Test cases on each retrofit.\n",
      "Design and Development new modifications required by customer.\n",
      "Prepared Technical design documents on each retrofit and enhancement.\n",
      "Add new text catalogues for various languages.\n",
      "Responsible for overseeing the Quality procedures related to the project. \n",
      "Responsible for move objects from Development to SIT Environment\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code), PeopleSoft HCM 9.1, DB2, Windows, UNIX.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Having 4.6 years of experience in PeopleSoft application enhancement, Support and Upgrade projects. Well experienced on People tools and having Functional knowledge HCM and FSCM Applications.\n",
      "\n",
      "\n",
      "\n",
      "Master of computer applications, Vinayaka Missions University, Chennai, Tamilnadu, India (3year program- 2010).\n",
      "\n",
      "Senior Consultant – Randstad, Hyderabad, Andhra Pradesh, India (June 2020 to till date)\n",
      "\n",
      "Project:  Randstad (Enhancements)\n",
      "Client:    Randstad Staffing \n",
      "Responsibilities:\n",
      "Analyze the requirement documents to understand the customer business requirement.\n",
      "Provide the technical approach for each FDD assign me.\n",
      "Customize the system applications and designed many objects from scratch.\n",
      "Write people code to implement the business logic.\n",
      "Design custom Application engine programs to process the data.\n",
      "Design Application engine programs to send notifications.\n",
      "Responsible to prepare unit test cases and technical design documents.\n",
      "Responsible to support SIT and UAT.\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code, Component Interface, Application Packages), PeopleSoft HCM, Oracle, Windows.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sr. Technical Associate – Verizon, Hyderabad, Andhra Pradesh, India (Dec 2018 to May-2020)\n",
      "\n",
      "Project:  Verizon Wireless (Development)\n",
      "Client:    Verizon\n",
      "Responsibilities:\n",
      "Analyze the requirement documents to understand the customer business requirement.\n",
      "Provide the technical approach for each FDD assign me.\n",
      "Customize the system applications and designed many objects from scratch.\n",
      "Write people code to implement the business logic.\n",
      "Design custom Application engine programs to process the data.\n",
      "Design Application engine programs to send notifications.\n",
      "Implemented component interface program to load data into people soft.\n",
      "Used file layout in inbound programs.\n",
      "Responsible to prepare unit test cases and technical design documents.\n",
      "Responsible to support SIT and UAT.\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code, Component Interface, Application Packages), PeopleSoft FSCM 9.1, Oracle, Windows.\n",
      "\n",
      "Senior Software Engineer – HSBC, Hyderabad, India (Aug 2016 to Nov 2018)\n",
      "\n",
      "Project:  HSBC (Upgrade Project)\n",
      "Client:    HSBC Bank\n",
      "Responsibilities:\n",
      "Analysis and Understand the Source and Target system business process.\n",
      "Compare the objects between source and targets and identify the changes.\n",
      "Retrofit all the objects based on compare reports.  \n",
      "Unit testing and prepare unit Test cases on each retrofit.\n",
      "Design and Development new modifications required by customer.\n",
      "Prepared Technical design documents on each retrofit and enhancement.\n",
      "Add new text catalogues for various languages.\n",
      "Responsible for overseeing the Quality procedures related to the project. \n",
      "Responsible for move objects from Development to SIT Environment\n",
      "\n",
      "Environment: People Tools (Application Designer, Application Engine, People Code), PeopleSoft HCM 9.1, DB2, Windows, UNIX.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      " \n",
      "\n",
      "CAREER OBJECTIVE\t\t\n",
      "\n",
      "Pursuing Peoplesoft Executive role, having an overall experience of 3.6 Years in Financial Supply Chain Management and processes include Modification, Testing, and Supporting in PeopleSoft FSCM modules.\n",
      "\n",
      " PROFESSIONAL SKILL\t\t\n",
      "\n",
      "Functional: Purchasing, Inventory, Billing, Sound knowledge Account Payable, Sound knowledge in Peoplesoft Security\n",
      "Technical: PS Query, Basic knowledge in Peoplesoft Security, Application Designer, Peoplecode, SQL\n",
      "TOOLS: People Tools, ORACLE SQL Developer\n",
      "Database: ORACLE\n",
      "\n",
      "PROFESSIONAL SUMMARY\n",
      "Project # 1\n",
      "Module:   Accounts Payables \n",
      "Client\t: Accounts Team Aptara \n",
      "\n",
      "Role\t: Developer\n",
      "Technologies Used\t: Crystal Reports, People Tools, Application Designer, Reporting Tools\n",
      "\n",
      "\n",
      "Application Designer: By using this tool we have created page which contains run control record and that page add in the component and register the component so that its reflected in the PIA(pure internet architecture)\n",
      "People Tools:          we have created a permission list by the help of people Tools and that permission                list to a separate role so that selected user can access the page.\n",
      " we have also created a process to run the crystal through this tools so that the output will visible through process monitor.\n",
      "Reporting Tools:      we have created PS queries by the help of Reporting Tools for main report and for sub report in the crystal report.\n",
      "Crystal Reports:      by this tool we can used the PS queries, formula fields, running Total fields to get the required output\n",
      "\n",
      "Project # 2\n",
      "Module:   Purchasing\n",
      "Client\t: Admin Team\n",
      "\n",
      "Role\t: Developer\n",
      "Technologies Used\t: People Tools\n",
      "\n",
      "As for the client requirement for requisition purpose we have to create a new origin for admin so that any requisition raise through that origin it’s only for Admin purpose.\n",
      "to get the requisition approval flow for admin we have created the origin for admin and add that origin in the route control profile by the help of People Tools. And that route control profile\n",
      "added in the approver user ids to get the work done.\n",
      "\n",
      "\n",
      ".\n",
      "• Tracking the Defects to Closure and Defects Verification.\n",
      "• Status meetings with Client.\n",
      "• Creating Peoplesoft User id as per the User requirement\n",
      "• creating Origin, route control profile, Roles for requisition.\n",
      "• Handling Requisition, Purchase Order, Receipt and Inventory related issue.\n",
      "• creating Billing specialist etc. as per the requirement from the user, also resolve the bug (e.g. if invoice not get printed etc.).\n",
      "• Handling journal error issues (e.g. its might be combo error, amount difference, open period error or zero line error)\n",
      "\n",
      "​FUNCTIONAL SUMMARY\n",
      "\n",
      "Oracle PeopleSoft Application (Finance) 8.9\n",
      "Modules Handled: Resource Management of FSCM\n",
      "Purchasing\n",
      "Inventory\n",
      "Billing\n",
      "Sound knowledge in Account Payable\n",
      "Sound knowledge of PeopleSoft security\n",
      "\n",
      "TECHNICAL SUMMARY\n",
      "\n",
      "Primary Skills: PS Query, Application Designer (Field, Record, Page, Component, Menu), SQL\n",
      "Secondary Skills: Peoplecode\n",
      "TOOLS: People Tools, ORACLE SQL Developer\n",
      "Database: ORACLE\n",
      "\n",
      "EDUCATION\t\t\t\t\t\n",
      "B.Tech in Electrical and Electronics Engineering, Indus college of engineering, Biju Patnaik University of Technology, Orissa from0\n",
      "\n",
      "PERSONAL VITAE\n",
      "\n",
      "Date of Birth\t: 10th Jan 1991\n",
      "Languages \t: English, Hindi, Odia\n",
      "Nationality\t: Indian\n",
      "Gender\t\t: Male\n",
      ".\n",
      "\n",
      "DECLARATION\n",
      "\n",
      "I do hereby declare that the information given above is true and correct to my knowledge and belief.\n",
      "\t\t\t\t\t\t\n",
      "Date:                                         \t\t\t\t\t\t    \t    Priyabrata Hota.\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Done few customizations to delivered App Engine process AP-APY2015, which can be used for Create Payments for Vouchers.uirements.teract with On-site team to clarify requirements.\n",
      "\n",
      "Processing text:\n",
      "Tanna Sujatha \n",
      "\n",
      "\n",
      "\n",
      "OBJECTIVE\n",
      "Seeking a challenging role in the area of IT to work in an organization where I can utilize my functional knowledge to provide the best solutions to the business.\n",
      "\n",
      "PROFESSIONAL SUMMARY:\n",
      "\n",
      "Functional Expertise in the below PeopleSoft Finance modules\n",
      "Purchase\n",
      "Account Payables\n",
      "Experienced in working with Reporting tools like PS-query.\n",
      "End-End functional knowledge of AP & PO modules and handled various change requests from the user.\n",
      "\n",
      "SYNOPSIS\n",
      "Energetic and result oriented professional with 3.6 years of experience in IT. Extended expertise in PeopleSoft Financials 9.2 in the area of design, maintenance and production support. Deep understanding of technology with focus on delivering business solutions. Presently working as Sr. System Engineer\n",
      "Excellent decision-making skills with a positive approach.\n",
      "Dedicated and highly ambitious to achieve personal goals as well as the organizational goals.\n",
      "Ability to build new territories and expand opportunities towards the achievement of stated targets.\n",
      "\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "BTECH from KAUSHIK COLLEGE OF ENGINEERING, Visakhapatnam in 2015 with an academic percentage of 63%.\n",
      "\n",
      "PUC from NARAYANA junior college Visakhapatnam in 2011 with an academic percentage of 74.2%.\n",
      "\n",
      "S.S.C from ZP High School, BURJA in 2009 with an academic percentage of 71.1%.\n",
      "\n",
      "SOFTWARE PROFICIENCY\n",
      "\n",
      "PeopleSoft Functional:\tPurchase, Account Payables, Vendor Management\n",
      "Databases:\tOracle SQL Developer.\n",
      "Reporting Tools:\tPS Query \n",
      "\n",
      "WORK HISTORY\n",
      "Company: Datum Technologies                                                   (Mar’17-Present) \n",
      "Designation: Sr. System Engineer\n",
      "\n",
      "PROJECTS HANDLED\n",
      "\n",
      "Project- #1:\n",
      "(Jul’17 –Present)\n",
      "Project Name: Datum (PeopleSoft FSCM Maintenance and Support)\n",
      "Client:\tDATUM\n",
      "Role:\tSr. System Engineer\n",
      "Duration:\tJul’17– Present\n",
      "Team Size:\t6members\n",
      "\n",
      "Description:\n",
      "This is a maintenance and Production Batch Support project. Maintenance involves working on the tickets which needs customization, Setup and enhancements for creating or modifying the PeopleSoft objects. Production support involves monitoring the batch jobs scheduled.\n",
      "Roles and Responsibilities:\n",
      "Monitoring of Batch jobs and resolving the job failures on time.\n",
      "Unit testing and documentation as per organizational requirement.\n",
      "Documentation of process flow as per the business requirement.\n",
      "Involved in interactions with users for requirement/change gathering, UATs etc. Handling various requests from the user.\n",
      "\n",
      "\n",
      "PERSONAL DETAILS\n",
      "Date of Birth:\t1st July, 1994\n",
      "Languages:\tEnglish, Telugu\n",
      "Gender:\tFemale\n",
      "Marital Status:\tMarried\n",
      "Nationality\tIndian\n",
      "Present Address:\tPocharam, Hyderabad, Telangana, India.\n",
      "\n",
      "I hereby declare that the information furnished above is true to the best of my knowledge.\n",
      "\n",
      "Sujatha Tanna\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "C O N T A C T :\n",
      "\n",
      "Address: Manyata Tech Park,\n",
      "Nagavara, Bangalore 560045\n",
      "\n",
      "LinIn: subha-santosh-b16698139\n",
      "\n",
      "S K I L L S :\n",
      "\n",
      "PeopleSoft Finance FSCM ARIBA\n",
      "JAVA Full Stack Development SQL\n",
      "Power BI\n",
      "\n",
      "I N T E R E S T S :\n",
      "\n",
      "Learning new Technologies. Planting Hybrid Species.\n",
      "Cooking. Travelling Singing.\n",
      "\n",
      "S T R E N G T H S :\n",
      "\n",
      "Time Management. Responsible for my deliverables.\n",
      "Leadership qualities.\n",
      "\n",
      "L A N G U A G E S :\n",
      "\n",
      "Japanese.\n",
      "French (Started Learning).\n",
      "SRI SUBHA SANTOSH KUMAR JOSYULA\n",
      "A S S O C I A T E C O N S U L T A N T\n",
      "P R O F E S S I O N A L S U M M A R Y :\n",
      "\n",
      "I am having more than 3.2 years of experience in assistance and development for projects like ARIBA and PEOPLESOFT FINANCE . I have successfully completed TOOLS PATCH and TOOLS UPGRADE PROJECT with 0% refuse validations. I am the main Point of contact in Non Regression Testing and User Acceptance Testing. I am responsible to find solutions which makes customer satisfaction.\n",
      "\n",
      "W O R K E X P E R I E N C E :\n",
      "\n",
      "ASSOCIATE CONSULTANT\n",
      "CapGemini - AXA | June 2018 - Till Date\n",
      "Working on modules like Accounts Payable. Accounts Receivable and General Ledger, Expenses, User Profile Self Service (USS), Security along with Application Designer and SQL server .\n",
      "Organised customer information and account data for business planning and customer service purposes.\n",
      "Received 97% positive customer survey results. Worked on People Code and Packaging activities.\n",
      "Successfully monitored the Process Monitoring for failed jobs.. Collectively worked with the team to maintain 100% SLA. Developed and implemented many JAVA scripts to make the changes as per client's requirement.\n",
      "\n",
      "\n",
      "E D U C A T I O N :\n",
      "\n",
      "BACHELOR OF TECHNOLOGY, ELECTRONICS AND COMMUNICATION\n",
      "Vishnu Institute of Technology - JNTUK | 2014 - 2018 Average : 75%\n",
      "\n",
      "\n",
      "A W A R D S A N D\n",
      "C E R T I F I C A T I O N S :\n",
      "\n",
      "Basic Certified Power BI Desktop Manager - Coursera 2021 Agile Software Development - 2021\n",
      "Rising Star Award -CapGemini - Q4-2020\n",
      "BEST TEAM AWARD | PeopleSoft Finance Team  | 2019 and 2020\n",
      "OCA-8 JAVA DEVELOPER\n",
      "Microsoft Office Specialist.\n",
      "Japanese Language Basic Certification.\n",
      "\n",
      "Processing text:\n",
      "Name: Ravali P \n",
      "\n",
      "                                                                             Curriculum Vitae \n",
      "                                          Specialization: BE (computer science and Engg)   \n",
      "\n",
      " \n",
      "To utilize my technical skills for achieving the target and developing the best performance in organization. \n",
      " \n",
      " \n",
      "\n",
      " \n",
      " \t \n",
      " \n",
      "MANUAL TESTING SKILLS \n",
      " \n",
      "   Strong knowledge in SDLC concepts. \n",
      "   Extensive knowledge in White Box Testing. \n",
      "   Good knowledge in Functional testing, Integration testing, \n",
      "   Extreme Knowledge on System Testing \n",
      "   Good knowledge in Adhoc Testing, Reliability testing.    Good Knowledge on Exploratory Testing    Good knowledge in STLC concepts. \n",
      "   Good knowledge in Test cases and Test scenarios. \n",
      "   Good knowledge in globalization testing, compatibility testing.    Through Knowledge on Regression Testing    Good  knowledge in Test plan.\n",
      " \n",
      "   \n",
      "     AGILE METHDOLOGY \n",
      " \n",
      "   Good knowledge on Scrum Methodology.    Expertise in Sprint Planning Meeting. \n",
      "   Good knowledge on Scrum Meeting \n",
      "   Extreme knowledge on Sprint Retrospective Meeting \n",
      "   Good knowledge on Product Backlog Meeting and Bug Triage Meeting. \n",
      "   Extreme Knowledge on Normalization \n",
      " \n",
      " \n",
      " \n",
      "JAVA SKILLS \n",
      " \n",
      "   Good knowledge on Method Overloading and Method Overriding. \n",
      "   Good understanding on Static and NonStatic. \n",
      "   Good understanding on Variables. \n",
      "   Good knowledge on Constructor. \n",
      "   Good knowledge in Abstraction. \n",
      "   Good knowledge in Encapsulation. \n",
      "   Good knowledge in Inheritance. \n",
      "   Good knowledge in Collections. \n",
      " \n",
      " \n",
      " \n",
      " \t \n",
      " \n",
      " \n",
      "TRAINING OR COURSES:- \t \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      "     \n",
      "  INDUSTRIAL EXPOSURE:- \t \n",
      " \n",
      " ACHIEVEMENTS:- \t \n",
      "     \t  I’m certified in ‘Cyber Security’ Training at SJBIT in Bengaluru \n",
      "     \t  I’m certified in Volleyball Olympics in Distict level  \n",
      "      ASSIGNEMENTS \n",
      " \n",
      "   I have identified 100 Functional Test cases on Flipkart.com \n",
      "   I have identified 200 Integration Test cases on WhatsApp \n",
      "   I have identified 200 Integration Test cases on  Amazon.com \n",
      "   I have found 100 defects while doing FT, Usability, Camaptibility, Globalization Testing \n",
      " \n",
      " STRENGTHS \n",
      " \n",
      "\n",
      " \n",
      "DATE OF BIRTH:                                     04/11/1995 \n",
      " \n",
      "GENDER:                                                     Female              \n",
      "FATHER NAME:                                     Fasala Reddy N \n",
      "LANGUAGES KNOWN:                         English, Telugu,Kannada,Hindi \n",
      " \n",
      " \n",
      "NATIONALITY:                                        Indian. \n",
      " \n",
      "ADDRESS:                                                 Thirumaladevarahalli(v),Parthihalli(p)                                                                Kodigenahalli(H),Madhugiri(T),Tumkur(D)                                                           state: Karnataka \n",
      " \n",
      "\n",
      " \n",
      "I hereby declare that all the above-mentioned information is true to the best of my knowledge. \n",
      "                                                                                                                                              \n",
      "                                                                                                                                             Your’Sincerely \n",
      "                                                                                                                                                    Ravali P                                               \n",
      "Place: Bangalore                                                                                          \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \t \n",
      "\n",
      "Processing text:\n",
      "  \n",
      "SUSOVAN  BAG   \n",
      "Seeking  a  challenging  position  in  the  field  of  science  and  technology  to  utilize  my  skills  for  organization  and  individual  growth  and  to  enhance  my  knowledge  from  my  academic  learning  to  give  my  best  to  the  organization.   \n",
      "  \n",
      "SKILLS  \n",
      "CCNA -   Routing  &  Switching  subnetting  \n",
      "Programming:  C,   C++,Java,  HTML,CSS,  SQL   \n",
      "  \n",
      "OOPS,  Algorithms,  Data  Structures,DBMS,  Networking  \n",
      "\tOS  (Linux): Linux \t  System  Administration  with  Troubleshooting  \n",
      "  \n",
      "SOFT  SKILLS  \n",
      "\t Leadership, \t  Collaboration,  Good  communication  and  customer  Handling  skills.  \n",
      "   \n",
      "LANGUAGES  \n",
      "\t  English(Fluent), \t  Hindi(Fluent),  Bengali(Native),  Telugu  \n",
      "  \n",
      "  \n",
      "PROJECTS   \n",
      "  \n",
      "SMART  AGRICULTURE   \n",
      "Built  a  product  for  farmers  using  IoT  as  a  solution     \n",
      "AUTOMATIC  WATER  MOTOR  CONTROLLER  (2019 -   2020)    \n",
      "IoT,  android  and  API  technologies  combined  to  automate  work  of  water  motor  controllers  using  sensors.   \n",
      "  \n",
      "BOOKSTORE  MANAGEMENT  INTERFACE: C PP  (2018  -  2019)    \n",
      "Manage  the  purchase  and  return  of  books  in  a  books  store.    \n",
      "HOTEL  MANAGEMENT  SYSTEM(DEC - 2018)  \n",
      "Designed  a  front  end  module  for  the  hotel  management  system  website  using  HTML,CSS  .  \n",
      "  \n",
      "ONLINE  MOVIE  TICKET  BOOKING    \n",
      "Designed  a  fully  functioning  website  using  HTML,CSS,Javascript.`  \n",
      "  \n",
      "EDUCATION  BACKGROUND   \n",
      "\tLovely  Professional  University \t Punjab, \t  India.  \n",
      "B-Tech  in  computer  science  and   Engineering                                                                        7.22  gpa,  2020.    \n",
      "\t   HOBBIES :Web  Surfing,  Cricket,Carrom,Chess .  \t  \n",
      " \t  \t  \n",
      "/\n",
      "/\n",
      "\n",
      "Processing text:\n",
      "Kanumuru Deepak Reddy\n",
      "\n",
      "\n",
      "\n",
      "CAREER OBJECTIVE:\n",
      "\n",
      "To secure a position in a reputed organization where I can efficiently contribute my knowledge and skills to the growth of the organization and build my professional career.\n",
      "\n",
      "ACADEMIC QUALIFICATIONS:\n",
      "\n",
      "\n",
      "\n",
      "PROJECT:\n",
      "\n",
      "Title\t:Density based Traffic Control System USING ARDUINO.\n",
      "\n",
      "Duration:4 months.\n",
      "\n",
      "Description: Traffic congestion is a severe problem in most of the cities across the world and it has become a nightmare for the citizens. It is caused by delay in signal, inappropriate timing of traffic signalling etc. The delay of traffic light is hard coded and it does not depend on traffic. Therefore, for optimising traffic control, there is an increasing demand in systematic quick automatic system. This project is designed to develop a density based dynamic traffic signal control. The signal timing changes automatically on sensing the traffic density at the junction. The microcontroller used in this project is ARDUINO. The system contains IR sensors & ultrasonic sensors (transmitter and receiver) which will be mounted on the either side of the road on poles. It gets activated and receives the signal as the vehicles passes close by it.\n",
      "\n",
      "EXPERIENCE:                                        \n",
      "  \n",
      "I am carrying an experience of  2 years  from MetroLabs Services Pvt Ltd.\n",
      "\n",
      "   ROLES AND RESPONSIBILITIES :\n",
      "\n",
      "Over 2 years of extensive experience as a Front End Developer with solid understanding of website and application designing, development of different modules using ReactJS.\n",
      "Professional understanding of Software development life cycle (SDLC) as well as various phases such as Analysis Design, Development and Testing.  \n",
      "\n",
      "\n",
      "Experienced in developing User Interface using HTML5, CSS3, Bootstrap, JavaScript,  DOM, ReactJS.\n",
      "\n",
      "\n",
      "Experience in DOM as I used it in interacting with objects in HTML documents.  \n",
      "\n",
      "Experience in working with Express creating Restful API, URL routing, creating and handling HTTP CRUD \n",
      "\n",
      "Good experience in using React JS components, Forms, Events, Keys, Router, Redux Store, action creator and reducer etc.\n",
      "\n",
      "Good experience in developing draggable grid layout using react-grid-layout package.\n",
      "\n",
      "Good knowledge on building tables/grid using react-table and ag-grid library and office-fabric-ui.  \n",
      "\n",
      "Experience in maintaining APIs and existing applications.\n",
      "\n",
      "Write code that is cross-platform and cross-device compatible.\n",
      "\n",
      "Converted PSD files into pure hand-written HTML and CSS pages \n",
      "Effectively represent the voice of the user to influence and improve design decisions\n",
      "Consult with the cross-functional team throughout development, testing, and rollout to ensure designs are understood, implemented, and communicated appropriately\n",
      "Website hosting is one of the major role in my working period and according with client modifications, deletions etc.\n",
      "\n",
      "Good communication skills, both verbal and written.\n",
      "\n",
      "TECHNICAL EXPERTISE:\n",
      "\n",
      "Web Technologies   \t:  Html5, Css3, JavaScript, Responsive Designs,\n",
      "  Bootstrap, ReactJS, JSON\n",
      "  \n",
      "Development Tools \t:   Visual Studio Code\n",
      "Operating Systems   \t:  Windows 10\n",
      "\n",
      "PERSONAL DETAILS:\n",
      "\n",
      "Date of Birth\t:\t15, August,1997.\n",
      "Father’s Name\t:\tMr. K.Sudhakar Reddy,\n",
      "Permanent Address\t:\tH.no:5-8-171/3, Bmr Nagar, Naidupet.\n",
      "Languages known\t:\tTelugu, Hindi & English.\n",
      "Hobbies\t:\tPlaying cricket, Watching news.\n",
      "\n",
      "STRENGTHS:\n",
      "\n",
      "Punctuality\n",
      "Positive attitude\n",
      "Leadership\n",
      "Teamwork\n",
      "\n",
      "LANGUAGES KNOWN:\n",
      "\n",
      "Telugu\n",
      "Hindi\n",
      "English\n",
      "\n",
      "\n",
      "\n",
      "DECLARATION:\n",
      "\n",
      "I hereby declare that all the above mention details are true to best my knowledge.\n",
      "\n",
      "\n",
      "\n",
      "Place:\n",
      "Date:\t\t\t\t\t\t\t\t\t\tK.Deepak Reddy\n",
      "\n",
      "Processing text:\n",
      "HARIPRIYA BATTINA \n",
      "Experience as UI Developer in Reactjs, JavaScript. \n",
      "Phone: +91 9908576950 \n",
      "Gmail: haripriyabattini@gmai.com \n",
      "Location: Visakhapatnam \n",
      "JOB OBJECTIVE ● Looking for a challenging role to put my experience in various aspects of technology with an objective to be a leading source of information and guidance concerning th\n",
      "technological requirements. \n",
      "● Want to be a part of a reputed organization that allows me to effectively use my \n",
      "technical skills in the real world for overall growth of organization and my \n",
      "professional career. \n",
      "WORK EXPERIENCE EDUCATION \n",
      "1. Associate UI Developr \n",
      "Company: Blue Yonder, Hyderabad. \n",
      "● Work Done On “COPERNICUS” Project. \n",
      "● The Main Moto of this project is, it is GTM (Go To Market) Portal which is specially designed for demo teams to shower case Blue Yonder Products and Features for Customers and Partners \n",
      "● Technologies: HTML, CSS, React JS. \n",
      "● IDE: VS Code. \n",
      "● Methodologies: Agile. \n",
      "JOB RESPONSIBILITIES: \n",
      "● Involved Designing in Web Pages using HTML, CSS, JavaScript, React JS. ● Actively Handling the user stories raised through JIRA Tool. \n",
      "● Analyzing the stories by going through the application, Identifying the solution and also providing the functionalities. \n",
      "● Used JIRA as the bug tracking system to track and maintain the history of bugs on an everyday basis. \n",
      "● B.Tech in Information technology from Anil Neerukonda Institute of Technology and Sciences (Affiliated to Andhra University), Visakhapatnam, in the year 2018 with 6.7 CGPA. \n",
      "● Intermediate in MPC from NRI junior college, Visakhapatnam, in 2014 with a percentage of 72.2%. \n",
      "● SSC from A.P.S.W.R school Pedapadu, Srikakulam in 2012 with CGPA 7.8.\n",
      "ACADEMIC PROJECT \n",
      "TECHNICAL SKILLS STRENGTHS \n",
      "ACHIEVEMENTS DECLARATION \n",
      "Project name : ONLINE RESTAURANT RESERVATION SYSTEM \n",
      "Project Duration : 3 months. \n",
      "Description : \"Online Restaurant Reservation System\" is a web application. This system is developed to automate day to day activities of restaurants. It is a kind of business that serves the people all over the world with ready food. \n",
      "Technology used : java, HTML, MYSQL \n",
      "● Programming Languages : C, Reactjs, JavaScript, SQL Server. \n",
      "● Software Packages : MS Office. \n",
      "● Web Technologies : HTML, CSS. \n",
      "● Operating System : Windows, Ubuntu. \n",
      "● Positive attitude. \n",
      "● Believe in punctuality \n",
      "● Teamwork \n",
      "● Responsible towards work \n",
      "● Extended my services as poster Coordinator in the RADIAN 2k18 event. ● Extended my services in coordinator in farewell day 2018 \n",
      "Isolely declare that the above-mentioned facts are true to the best of my knowledge. Date: ……………………… \n",
      "Place: Hyderabad. (Hari priya B)\n",
      "\n",
      "Processing text:\n",
      "KAMALAKAR REDDY. A \n",
      "Linked In: https://www.linkedin.com/in/kamalakar-reddy-777682196/ \n",
      "PROFESSIONAL SUMMARY \n",
      "● 3 years of experience in UI Development of Enterprise Applications, Web Applicationsrelated technologies. \n",
      "● Experience in Development, Coding, Maintenance,Design, Implementation of Web applications using HTML5, CSS3, JavaScript, j Query, React JS, Redux. \n",
      "● Well versed in designing websites, Web Applications. \n",
      "● Well versed in different Project Management Tools e.g. JIRA, GIT, Bit bucket. ● Tested cross browser design issues and fixed major layout bugs for supported browsers. ● Self-motivated with good communication and interpersonalskills. \n",
      "● Ability to work independently and multitasking without negative impact to timelines orquality. \n",
      "WORK EXPERIENCE \n",
      "MARCH 2021 – TILL DATE \n",
      "ROLE : : UI DEVELOPER \n",
      "ENLUME TECHNOLOGIES, HYDERABAD. \n",
      "AUGUST 2018 – MARCH 2021 \n",
      "ROLE : SOFTWARE ENGINEER \n",
      "FORTUNAPIX PRIVATE LIMITD, HYDERABAD. \n",
      "PROJECTS \n",
      "TITLE : Monarch Tractor \n",
      "DESCRIPTION: Monarch Tractor impacts the environment exactly as intended, without side effects. This Application helpful for farmers to get tractor alerts, updates on weather conditions, Analysis, Data collection. MT platform acts as a full data collection and analysis suit. TECHNOLOGIES: HTML, Css3, Bootstrap, React Js, JavaScript. \n",
      "TITLE : lernbook \n",
      "DESCRIPTION: Fortunapix works for Digitalization of schools by providing modern digital education system in Govt. schools of Antigua and Barbuda, and Caribbean islands. This project digitalize and animates the education content for different grades in a school. \n",
      "TECHNOLOGIES: Html, Css3, React Js, Bootstrap, Jqery. \n",
      "url: http://demo.fortunapix.com/kkel/\n",
      "EDUCATION \n",
      "2017 - 2018 \n",
      "WEB DESIGNING & DEVELOPMENT COURSE \n",
      "AT ARENA ANIMATION DILSUKNAGAR, HYDERABAD. \n",
      "2010 - 2013 \n",
      "BACHELOR OF COMPUTERS \n",
      "AT G.PULLAREDDY DEGREE & PG COLLEGE, HYDERABAD. \n",
      "TECHNICAL SKILLS \n",
      "JAVASCRIPT LIBRARYS : ReactJs, Redux. \n",
      "CSS FRAMEWORK : Bootstrap. \n",
      "ENVIRONMENT : Photoshop, Visual Studio. \n",
      "WEBTECHNOLOGIES : HTML 4, CSS3, Sass. \n",
      "OPERATINGSYSTEMS : Windows, Mac, Ubuntu. \n",
      "SCRIPTINGLANGUAGES : JavaScript, jQuery. \n",
      "METHODOLOGIES : Agile. \n",
      "ACTIVITIES & INTERESTS \n",
      "∙ Cooking \n",
      "∙ Playing Cricket \n",
      "∙ Listening Music \n",
      "∙ Other Social Activities \n",
      "PERSONAL PROFILE \n",
      "FATHER’SNAME : MURAHARI REDDY. A \n",
      "GENDER : Male \n",
      "MARITALSTATUS : Single \n",
      "NATIONALITY : Indian \n",
      "KNOWN LANGUAGES : Telugu, English, and Hindi. \n",
      "LOCATION : Madhapur, Hyderabad \n",
      "DECLARATION \n",
      "I do hereby declare that all the above information furnished by me are true and correct to the best of my knowledge. \n",
      "Place : Hyderabad (KAMALAKAR REDDY .A) Date :\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Naveen Sadhu\n",
      "\n",
      "\n",
      "Title: software developer\t\t\t\t                  \n",
      "Location: Hyderabad, India\t\t\t                                \n",
      "\n",
      "Professional Summary\n",
      "1 year of overall IT experience in Html, Sql, Reactjs and Nodejs.\n",
      "Experience in working with Application development and testing tool\n",
      "Hard working and enthusiastic.\n",
      "Excellent communication, interpersonal, analytical skills, and strong ability to perform as part of team.\n",
      "Exceptional ability to learn new concepts.\n",
      "\n",
      "Education\n",
      "Bachelor of Technology in Computer Science and Engineering from Marri Laxman Reddy Institute of Technology and Management (Affiliated to JNTUH).\n",
      "Skills\n",
      "\n",
      "Professional Experience\n",
      "Current Project \n",
      "Client\t\t  : Inline4, USA\n",
      "\n",
      "Organization     : Edvenswa tech Pvt. Ltd\n",
      "\n",
      "Technology\t  : MERN stack, HTML,CSS,BOOTSTRAP\n",
      "\n",
      "Description\n",
      "\n",
      "The project goal is to provide whenever the user wants to do servicing for his bike he can go directly to this application and he can book slot for his bike servicing. Why because whenever the customer is in problem he can directly book the service so that the service provider will take the bike for servicing..\n",
      "\n",
      "\n",
      "Contribution\n",
      "Understand and implement the features \n",
      "Negotiate scope and resolving conflicting priorities.\n",
      "Translate requirements into meaningful stories that the team can deliver against.\n",
      "Application deployment.\n",
      "Developed the optimized code as per the requirement.\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal Details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Yours sincerely  \n",
      "            (Naveen Sadhu)\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "PC buildingg Sci-Fi movies \u0001   Gamingearn. \u0001   Leadership qualities and team spirit.ibre optics.wireless LAN and broadcasting. Using MATLAB, simulation of wireless channel modelling, MIMO channel modelling, MIMO channel capacity, PAPR reduction techniques are presented.ons to their client. a spring boot based on the REST-API endpoint. The React.js application consumes it with the help of AG Grid shown using beautiful UI.\n",
      "\n",
      "Processing text:\n",
      " \n",
      "PRAGNYA PATTNAIK\n",
      " \n",
      " \n",
      " \n",
      " Expertise: \n",
      " \n",
      "Having around 2 years of experience in UI development using Html5, CSS3, JavaScript, Bootstrap, React JS. \n",
      "Good knowledge in Java Script, JQuery, Ajax, React JS, TypeScript, Angular 10. \n",
      "Working on AGILE METHODOLGY\n",
      "Flexible to every Environment, Honest and believe in Hard work. \n",
      "Good Communications and Analytical skills. \n",
      "Maintain focus on high quality deliverables while working under pressure in Production environment. \n",
      "Management of the ticketing system on the production environment and resolution of the tickets with different priorities with appropriate solutions. \n",
      "Excellent interpersonal communicator and focused on building strong client/customer relationships. \n",
      "Proven ability to work efficiently in both Independent and team work environments. \n",
      "Ability to work optimally under scheduled deadlines and deliver high quality output. \n",
      " \n",
      "Technical Skills: \n",
      " \n",
      " \n",
      " \n",
      " Educational Profile: \n",
      " \n",
      "MCA from IGNOU (Indira Gandhi National Open University) 2018, Odisha. \n",
      " \n",
      "   Working Profile: \n",
      " \n",
      "Working as a Web Developer for Smart Edge India Pvt Ltd, (November 2019 to till date). \n",
      "\n",
      " \n",
      " Professional Experiences: \n",
      "\n",
      "Project 1: \n",
      " \n",
      "Project Description:- \n",
      "Golden amoon is a resort and hotel. They provides services for hotel booking, spa, conventional centre and conference hall booking system. Customers can check the availability for all services through web as well as in mobile. They can give their payment through online payment by internet banking, Debit card or in Credit Card. We developed both web and android based application which can help customers to get the services features easily and make client also for doing profitable business. \n",
      "Responsibilities: \n",
      "Understanding requirements. \n",
      "Working on UI implementation for the customers. \n",
      "Customizing React JS .\n",
      "Developed the front-end web page by using HTML5, CSS3, Bootstrap and  JQuery. \n",
      "Created CSS Websites Compatible of Google Chrome. \n",
      " \n",
      " Project 2: \n",
      "\n",
      "Project Description:- \n",
      "G2evolution is a service based company. They provide services for School Management, Ecommerce, Business Consulting, Mobile App Development, Search Engine Optimization (SEO). \n",
      "Responsibilities: \n",
      "Conversion of PSD designs into HTML5 (Responsive layouts). \n",
      "Involved in fixing the issues. \n",
      "Designing Attractive Layout. \n",
      "\n",
      "PERSIONAL DETAILS:\n",
      "\n",
      "             Name\t\t           :        PRAGNYA  PATTNAIK\n",
      "\tGender\t\t           :        Female\n",
      "\tNationality\t           :        Indian\t\n",
      "\tLanguages known       :         English & Hindi & ODIYA\n",
      "\t\n",
      "(I hereby declare that the above written particulars are true to the best of my knowledge and belief)\n",
      "\n",
      " \n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      " 204,Sri geethika prestige,road number 10,bandari layout,nizampet,Hyderabad,500090.\n",
      "\n",
      "Having 3 years of experience in developing UI-Applications. ◉ Proﬁcient and excellent hands on experience with JavaScript,HTML5,CSS3,Boostarp,React Js. ◉ Good knowledge in designing web pages using CSS3 and Bootstrap. ◉ Strong knowledge in using Object Oriented Programming concepts in JavaScript. ◉ Working knowledge of DOM models and Strong skills of usability and accessibility with HTML,CSS. ◉ Providing support to the UI Design team,form an UI architecture/frame works perspective. ◉ Experience in Boostarp (responsive web design),and React Js frameworks.. ◉ Experience in the Healthcare domain.Involved in all phases of the software development life cycle such as developing,integrating,Implementing and Debugging of web based. ◉ Excellent interpersonal abilities,communication skills,time management and team skills with an intention to work hard to meet project deadlines under stressful environment.\n",
      "\n",
      "Apr 2017 - Feb 2019\n",
      "Software Engineer\n",
      "Individual contributor responsible for designing front end applications using web technologies like HTML5,CSS3 and JavaScript.\n",
      "Responsible for creating Modules using react is,converting HTML into components.\n",
      "Responsible for creating responsive web pages using Bootstrap.\n",
      "\n",
      "\n",
      "\n",
      "Apr 2016 - Mar 2017\n",
      "Software Engineer\n",
      "Individual contributor responsible for completing assigned tasks on time and proactively taking up new tasks.\n",
      "Responsible for building optimized code using JavaScript and debugging for any issues.\n",
      "Understanding the software requirements speciﬁcation @project functionality.\n",
      "Responsible for designing reactive web pages using HTML and CSS.\n",
      "Responsible for doing research on new implementations and ﬁnding out if it ﬁts the current requirement.\n",
      "Participate in daily meetings and give day wise updates to the team.\n",
      "\n",
      "2011-2015\n",
      "Sri Krishna Devaraya College(JNTU)\n",
      "\n",
      "2009-2011\n",
      "\n",
      "Inter,MPC\n",
      "\n",
      "HTML5,CSS3,JavaScript,React js, Bootstrap.\n",
      "\n",
      "E-Services is the project initiated by GOA government.The E-Services portal aims to provide the facility for citizens to submit online forms for the services identiﬁed by the state to be delivered online and through Lok seva kandra(LSKs).\n",
      "\n",
      "\n",
      "\n",
      "CRM processes that help identify and target their best customers.Providing services and products that are exactly what your customers want.CRM processes that help from individualized relationships with\n",
      "Customers(to improve customer satisfaction)and provide the highest level of customer service to the most proﬁtable customers.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "Thirupathamma Balla\n",
      "\n",
      "SUMMARY:\n",
      "\n",
      "2.8 year of IT experience as React Developer. \n",
      "Worked on technologies like React, JavaScript. \n",
      "Experience in developing business applications for the Internet using React.\n",
      "Experience in Object Oriented Programming concepts. \n",
      "Strong Analytical Ability skills.\n",
      "Enthusiastic, eager to meet challenges and quick to learn and assimilate new   concepts and ideas.\n",
      "Ability to work efficiently, either independently or on a team with minimal supervision and without ever missing a deadline.\n",
      "Brief Profile\n",
      "\n",
      "Summary of Skills & Experience\n",
      "\n",
      "Work Experience\n",
      "\n",
      "Technical Skills:\n",
      "\n",
      "Languages \t\t:\tC.\n",
      "Web Technologies\t:\tReact, Bootstrap, Javascript and JSON.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Education\n",
      "\n",
      "\n",
      "\n",
      "Project Details\n",
      "\n",
      "\n",
      "\n",
      "Responsibilities   \t:\n",
      "Responsible to develop reusable React components\n",
      "Responsible for reviewing other developers' code as part of peer-code-review.\n",
      "Responsible to write unit test cases in React\n",
      "Responsible for testing the components in the staging server.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Thirupathamma Balla.\n",
      "\n",
      "Processing text:\n",
      "                                                                                                                                      Vinay Reddy     should register through signup page and login and order the raw materials. And who wants menu and what is Healthy Chef Creations just they can open the home page and see their details.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Ui-Developer/ React JS Developer \n",
      "NAME: KRISHNA \n",
      "PROFESSIONAL SUMMARY:\n",
      "Over all 3.2 years of Extensive experience as a React JS/Web- Developer and 1 year of Experience as React JS Software Developer.\n",
      "Extensive experience in developing web pages using HTML, XML, CSS, JavaScript, React JS, Redux, JSON.\n",
      "Experience in all phase of SDLC like Requirement Analysis, Implementation and Maintenance, and extensive experience with Agile and SCRUM.\n",
      "Extensive knowledge in developing single - page applications (SPAs).\n",
      "Good Expertise in analyzing the Document Object Model (DOM) Layout, DOM Functions, and Java Script functions, Cascading Styles across cross-browser using Fire Bug, Developer Tool Bar.\n",
      "Expertise in React JS framework to develop the SPA.\n",
      "Experienced in React JS and working with React Flux architecture.\n",
      "Experienced in working with redux architecture using complex Object-Oriented concepts in improving the performance of the websites.\n",
      "Experience in using React JS components, Forms, Events, Keys, Router, plus Redux, Animations.\n",
      "Expertise in video coding by using HTML5, CSS3 and JavaScript.\n",
      "Expertise in RESTful, SOAP web services to integrate between Application to Application\n",
      "Experience with front-end development with back-end system integration.\n",
      "TECHNICAL SKILLS:\n",
      "Web Technologies: HTML, CSS3, XML, JavaScript, JSON, React JS, Node.js, GitHub.\n",
      "\n",
      "QUALIFICATION:\n",
      "B-Tech from JNTU-Kakinada University - 2016\n",
      "PROFESSIONAL EXPERIENCE:\n",
      "I have experience as React JS Developer with 3.2 years of experience in the IT Industry and currently working in BOSCH.\n",
      "Current Project: AGSP (Auto Guar age Solution Project)\n",
      "Role: UI Developer/ React JS Developer\n",
      "Responsibilities:\n",
      "Design, develop and test HTML5, CSS3, Bootstrap, JavaScript and React.JS that meets accessibility and web browser standards for website.\n",
      "Developed user interface by using the React JS, Flux for SPA development. \n",
      "Used React-Router to turn application into Single Page Application\n",
      "Worked in using React JS components, Forms, Events, Keys, Router, Animations and Flux concept.\n",
      "Used React flux to polish the data and for single directional flow.\n",
      "Used Object Oriented Programming concepts to develop UI components that could be reused across the Web Application.\n",
      "Extensively used Git for version controlling and regularly pushed the code to GitHub.\n",
      "Used JIRA as the bug tracking system to track and maintain the history of bugs/issues on everyday basis.\n",
      " Environment: HTML5, CSS3, JavaScript, Bootstrap, React JS, Redux, JSON, Git hub, JIRA\n",
      "Previous Project:  SITE WORK PROJECT\n",
      "Role: UI Developer/ React JS Developer\n",
      "Responsibilities:\n",
      "Worked on an Agile (Scrum) Development Team to deliver regular updates to business team and project managers.\n",
      "Involved designing in web pages using HTML 5, CSS3, JavaScript, Bootstrap, React.js, Redux , \n",
      "Worked on React JS Virtual Dom and React views, rendering using components which contains additional components called custom HTML tags.\n",
      "Implemented various screens for the front end using React.js and used various predefined components from NPM (Node Package Manager) and redux library.\n",
      "Worked in using React JS components, Forms, Events, Keys, Router, Animations, and Flux concept.\n",
      "Responsible for React UI and architecture. Building components library, including Tree, Slide-View, and Table Grid.\n",
      "Implemented stable React components and stand-alone functions to be added to any future pages.\n",
      "Used React JS for tinplating for faster compilation and developing reusable components.\n",
      "Used React-Auto complete for creating Google maps location search on the webpage.  Environment: HTML5, CSS3, Bootstrap, GitHub and Jenkins.\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Ui-Developer/ React JS Developer \n",
      "NAME: KRISHNA \n",
      "\n",
      "PROFESSIONAL SUMMARY:\n",
      "Over all 3.2 years of Extensive experience as a React JS/Web- Developer and 1 year of Experience as React JS Software Developer.\n",
      "Extensive experience in developing web pages using HTML, XML, CSS, JavaScript, React JS, Redux, JSON.\n",
      "Experience in all phase of SDLC like Requirement Analysis, Implementation and Maintenance, and extensive experience with Agile and SCRUM.\n",
      "Extensive knowledge in developing single - page applications (SPAs).\n",
      "Good Expertise in analyzing the Document Object Model (DOM) Layout, DOM Functions, and Java Script functions, Cascading Styles across cross-browser using Fire Bug, Developer Tool Bar.\n",
      "Expertise in React JS framework to develop the SPA.\n",
      "Experienced in React JS and working with React Flux architecture.\n",
      "Experienced in working with redux architecture using complex Object-Oriented concepts in improving the performance of the websites.\n",
      "Experience in using React JS components, Forms, Events, Keys, Router, plus Redux, Animations.\n",
      "Expertise in video coding by using HTML5, CSS3 and JavaScript.\n",
      "Expertise in RESTful, SOAP web services to integrate between Application to Application\n",
      "Experience with front-end development with back-end system integration.\n",
      "TECHNICAL SKILLS:\n",
      "Web Technologies: HTML, CSS3, XML, JavaScript, JSON, React JS, Node.js, GitHub.\n",
      "\n",
      "QUALIFICATION:\n",
      "B-Tech from JNTU-Kakinada University - 2016\n",
      "PROFESSIONAL EXPERIENCE:\n",
      "I have experience as React JS Developer with 3.2 years of experience in the IT Industry and currently working in BOSCH.\n",
      "Current Project: AGSP (Auto Guar age Solution Project)\n",
      "Role: UI Developer/ React JS Developer\n",
      "Responsibilities:\n",
      "Design, develop and test HTML5, CSS3, Bootstrap, JavaScript and React.JS that meets accessibility and web browser standards for website.\n",
      "Developed user interface by using the React JS, Flux for SPA development. \n",
      "Used React-Router to turn application into Single Page Application\n",
      "Worked in using React JS components, Forms, Events, Keys, Router, Animations and Flux concept.\n",
      "Used React flux to polish the data and for single directional flow.\n",
      "Used Object Oriented Programming concepts to develop UI components that could be reused across the Web Application.\n",
      "Extensively used Git for version controlling and regularly pushed the code to GitHub.\n",
      "Used JIRA as the bug tracking system to track and maintain the history of bugs/issues on everyday basis.\n",
      " Environment: HTML5, CSS3, JavaScript, Bootstrap, React JS, Redux, JSON, Git hub, JIRA\n",
      "Previous Project:  SITE WORK PROJECT\n",
      "Role: UI Developer/ React JS Developer\n",
      "Responsibilities:\n",
      "Worked on an Agile (Scrum) Development Team to deliver regular updates to business team and project managers.\n",
      "Involved designing in web pages using HTML 5, CSS3, JavaScript, Bootstrap, React.js, Redux , \n",
      "Worked on React JS Virtual Dom and React views, rendering using components which contains additional components called custom HTML tags.\n",
      "Implemented various screens for the front end using React.js and used various predefined components from NPM (Node Package Manager) and redux library.\n",
      "Worked in using React JS components, Forms, Events, Keys, Router, Animations, and Flux concept.\n",
      "Responsible for React UI and architecture. Building components library, including Tree, Slide-View, and Table Grid.\n",
      "Implemented stable React components and stand-alone functions to be added to any future pages.\n",
      "Used React JS for tinplating for faster compilation and developing reusable components.\n",
      "Used React-Auto complete for creating Google maps location search on the webpage.  Environment: HTML5, CSS3, Bootstrap, GitHub and Jenkins.\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\u000b",
      "Date: \t\t\t\t\t\t\t\t(Anjani Priyadarshini)oned particulars are true to my knowledge.sign Guide lines. Developing and maintaining a project Plan. Working with mentor to ensure the project meets its business needs and delivery in time. and music taste, while we design our moto-marine products to be element ready solutions for marine audio, motorcycle audio and UTV audio systems.let, and desktop platforms.\n",
      "\n",
      "Processing text:\n",
      "Kotani Durga Prasad\n",
      "\n",
      "\n",
      "Objective:\n",
      "\n",
      "Aspirant for a position in an organization where I can contribute my skills for organization’s success and synchronize with new technologies while being resourceful, innovative and flexible.\n",
      "\n",
      "Professional Summary:\n",
      "3.1 years of experience as a Software Engineer.\n",
      "Highly creative web designer and front end developer with experience of working on a diverse range of projects from small business websites to large scale websites with a global user base.\n",
      "Excellent knowledge in HTML, HTML5, CSS3, Bootstrap frameworks. Strong hands on experience in hand coding web technologies.\n",
      "Good Knowledge in Designing & Developing the Web pages based on SEO (Search Engine Optimization), W3C Standards and Cross-Browser Compatibility.\n",
      "Very good knowledge in client side programming with JavaScript, jQuery. Working knowledge in React JS.\n",
      "Experience in developing fully Responsive Websites using media queries and flexible layouts.\n",
      "Ability to create pixel to pixel matching web pages.\n",
      "Unmatchable degree of creativity as well as technical production skills. Excellent verbal communication skills including the ability to convey ideas and information clearly, concisely and persuasively.\n",
      "Flexibility, good judgment and attention to the detail essential.\n",
      "Education Details:\n",
      "B.Tech (Computer Science Engineering) from Gudlavalleru Engineering College.\n",
      "Intermediate from Sri Chaitanya Junior College.\n",
      "High School from Viswakavi High School.\n",
      "Professional Experience:\n",
      "\n",
      "Working as Software Engineer in Amaravati Tech Services, Vijayawada from August 2018 to Till Date.\n",
      "\n",
      "Technical Skills:\n",
      "Key Skills:\tHTML5, CSS3, JavaScript, JQuery, Json, Bootstrap and Responsive Design.\n",
      "Frameworks:\tReact Js.\n",
      "OS:\tWindows\n",
      "Dev Tools:\tMicrosoft Visual Studios\n",
      "Oﬃce Tools:\tMicrosoft Oﬃce Suite, Edit Plus, NotePad++\n",
      "\n",
      "Projects:\n",
      "\n",
      "Agro Services:\n",
      "\n",
      "Description:\n",
      "\n",
      "This is E-commerce based Web Application. selling & buying agriculture equipment Pesticides, seeds. Providing these services to client.\n",
      "\n",
      "Role and Responsibilities:\n",
      "\n",
      "Used UI Router for implementing routing in the application.\n",
      "Implemented Validations using pre-defined Validations of React JS Framework. Implemented Validation by using Custom directives in React Js.\n",
      "Used Http services & Pagination. Have an overview, understanding about diﬀerent features of React JS like dependency injection, digest and apply web cycle, two-way data binding. Done curd operation using re-source services.\n",
      "Involved in development, design and implementation of front end part of the application.\n",
      "Developed the User Interactive web pages in a professional manner by using web technologies like HTML5, CSS3 as per company standards.\n",
      "Used Bootstrap and React JS in eﬀective web design. Responsible for creating the look and feel of the public website.\n",
      "Used Ajax, JSON with jQuery for request data and response processing. . Used broadcast, emit & on to share data between diﬀerent modules Interacting with customer along various phases of the project.\n",
      "\n",
      "UI Technologies Used\n",
      "\n",
      "HTML5, CSS3, JavaScript, Bootstrap, JQuery, React JS.\n",
      "\n",
      "My Map Tag:\n",
      "\n",
      "Description:\n",
      "\n",
      "My Map Tag connects people and places, by providing the fastest, easiest way to share directions that eliminate the wasted time and frustration of getting lost. It is an online Directory Service for identifying Places important to you (such as your home, oﬃce, business, etc.),   which is designed for mobile use and optimized to take advantage of the capabilities of smart phones. My Map Tags hold much more information about a Place than just the address. They include things like photos, special instructions, directional helps (such as landmarks and route guide lines), contact details, descriptive information, and of course the GPS coordinates that show you the exact location on a map. The Tags are private and secure and controlled by the Map Tag owner. Individual Map Tags are not accessible to anyone, unless authorized by owner.\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "HTML Development.\n",
      "Fixing alignment Issues and Creating Drop down menus using jQuery.\n",
      "\n",
      "UI Technologies Used:\n",
      "\n",
      "HTML5, CSS3, JavaScript, Bootstrap, JQuery\n",
      "\n",
      "Byron:\n",
      "\n",
      "Description:\n",
      "\n",
      "Byron vision is to serve proper hamburgers the way they should be. It started oﬀ in 2007 in London to do a simple thing well, and do it properly as there weren’t any restaurants oﬀering hamburgers like those at the Silver Top at that moment. Byron site shows menu information, including a price and description for each of the dishes, location information for restaurants in the chain, provide news and stories about the brand and the ability to sign up to receive marketing information from Byron.\n",
      "The site was built using the latest technology, with the experience on capable devices utilizing HTML5 transitions and functionality where needed. Where HTML5 functionality is  not  supported by the device the experience will be degraded to provide usability according to the device capabilities.\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "HTML Development\n",
      "Developing Drop down menus using jQuery\n",
      "Developing dynamic background using JQuery mobile.\n",
      "\n",
      "UI Technologies Used:\n",
      "\n",
      "HTML5, CSS3, JQuery.\n",
      "\n",
      "Personal Details:\n",
      "\n",
      "Nationality: Indian\n",
      "Sex: Male\n",
      "Marital Status: Unmarried\n",
      "Languages Known : English, Hindi, Telugu\n",
      "\n",
      "Declaration:\n",
      "\n",
      "I hereby declare that the information furnished above is true to the best of my knowledge and belief.\n",
      "\n",
      "Date:\n",
      "Place: Vijayawada\tK.Durga Prasad\n",
      "\n",
      "Processing text:\n",
      "Venkatalakshmi Pedireddy\n",
      "Software Developer\n",
      "Experience 3 Years\n",
      "\n",
      "\n",
      "Visakhapatnam, India\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WORK EXPERIENCE\n",
      "Developer\n",
      "Schemax Expert Techno Crafts Pvt. Ltd\n",
      "05/2018 - Present,\tVisakapatnam\n",
      "Achievements/Tasks\n",
      "Worked on both front end and back end\n",
      "Responsible for development and management of the project\n",
      "\n",
      "\n",
      "EDUCATION\n",
      "SSC\n",
      "Z. P. G. H. School\n",
      "08/2011 - 03/2012,\t8.5 CGPA\n",
      "\n",
      "\n",
      "Board Of Intermediate, AP\n",
      "Sri Prakash Junior College\n",
      "08/2012 - 03/2014,\t81.1%\n",
      "\n",
      "\n",
      "B.tech\n",
      "Sri Prakash College Of Engineering\n",
      "08/2014 - 03/2018,\t73.33%\n",
      "SKILLS\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "PERSONAL PROJECTS\n",
      "Purchases Management (03/2021 - 04/2021)\n",
      "It is used for tracking purchases, Pending Payments, Discounts Based on Users (Retailer/Distributor)\n",
      "\n",
      "Corona Awareness Website (03/2020 - 04/2021)\n",
      "To Provide Awereness on Covid https://batvidcoronaawareness.000webhostapp.com\n",
      "\n",
      "\n",
      "\n",
      "PROJECTS\n",
      "Material Management System (08/2018 - 01/2019)\n",
      "MMS is tracking Procurement Material from Indents to Transfers. and to maintain stock for material of the plant - Technologies Used - YII Frame Work, Angular Js, MySql\n",
      "\n",
      "Warehouse Management System (02/2019 - 03/2019)\n",
      "WMS is to Maintain the stock, Sale, Purchase, Dispatch - Technologies Used - YII Frame Work, Angular Js, MySql\n",
      "\n",
      "Board Of Intermediate Support (03/2019 - 04/2019)\n",
      "BOI is to support and track the Employees attendance, Payments to employees -Technologies Used Joomla Frame Work, Mysql\n",
      "\n",
      "Sales (04/2019 - 08/2020)\n",
      "Sales is to track the purchases of two wheeler, three wheeler and transfer between branches - Technologies Used- Nx Repo, React Js, Nest Js, Type ORM, Mysql, Swagger\n",
      "\n",
      "Apparel Management (09/2020 - 04/2021)\n",
      "Apparel Management Is a large Project is used to track Orders, Sewing, Cutting, Embroidery, productivity of Employees tracking for the plant Technologies Used- Nx Repo, React Js, Nest Js, Type ORM, Mysql, Swagger\n",
      "\n",
      "Enterprice resource planning (05/2021 - Present)\n",
      "Erp is used to track the orders, Packing/RM Procurement, Production, logistics -Technologies Used- Nx Repo, React Js, Nest Js, Type ORM, Mysql, Swagger\n",
      "\n",
      "\n",
      "\n",
      "LANGUAGES\n",
      "\n",
      "Telugu\n",
      "Native or Bilingual Proﬁciency\n",
      "English\n",
      "Full Professional Proﬁciency\n",
      "\n",
      "\n",
      "\n",
      "INTERESTS\n",
      "\n",
      "Processing text:\n",
      "KAMBALA SAI SURENDRA   \n",
      " \n",
      "\tMandepeta \t \n",
      "  \n",
      " \n",
      "SUMMARY \n",
      " \n",
      " \n",
      "Project#1 \n",
      "  \n",
      " \n",
      "mA  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Project#2 \n",
      "EDUCATION \t  \t \n",
      "JNTU, KAKINADA \n",
      " \n",
      "2015 – 2018 \n",
      " \n",
      "B.Tech in Computer Science and Engineering \n",
      "Obtained a percentage of 63.80% \n",
      " \n",
      "LEELA KRISHNA BABUJI POLYTECHNIC, RAVULAPALEM \n",
      " \n",
      "2011 – 2014 \n",
      " \n",
      "Diploma Computer Engineer \n",
      "Obtained a percentage of 68.03 % \n",
      "ZP High School,Tapeswaram \n",
      " \n",
      "2001 – 2011 \n",
      " \n",
      "Matriculation \n",
      "Obtained a percentage of 62 % \n",
      " \n",
      "TECHNICAL \t  PROFICIENCIES \n",
      "\tDEVELOPMENT: \tReact Js, Redux, HTML, CSS, Bootstrap, jQuery, JavaScript. \n",
      "\tIDE EXPERIENCE: \tVisual Studio Code (VSCODE). \n",
      " \n",
      "\tLANGUAGES: \tJAVA. \n",
      "OPERATING SYSTEM: Windows XP ,7,8,10. \n",
      " \n",
      "ACADEMIC \t  PARTICIPATIONS \n",
      "Appreciated certificate in “CYBERTHON-2K18” from East Godavari conducted by “APITA”.  \tWorked as COORDINATOR in College Annual Fest. \n",
      "Participated in “Paper Presentation” on “Ethical Hacking” in EPROZYNE2K15 conducted at Pragati Engineering College. \n",
      "Participated in “Poster Presentation” on “Google Glass” in EPROZYNE-2K16 conducted at Pragati Engineering College. \n",
      " \n",
      "\tPERSONAL \t  \n",
      "DETAILS \n",
      " \n",
      " \n",
      "DECLARATION \n",
      " \n",
      "I hereby solemnly affirm that all the details provided above are always true to the best of my knowledge and belief and that, I shall carry myself in a manner that lends dignity to the organization and worthy enough of the person. \n",
      "\n",
      "Processing text:\n",
      "MAREEDU LOKESH BABU\n",
      "PROFESSIONAL OVERVIEW\n",
      "   Around 2  years of experience in software design, development, implementation and maintenance of applications using, HTML, CSS, JavaScript, JQuery, PHP, MySQL, React js , Node Js.\n",
      "Knowledge in Object Oriented PHP Programming.\n",
      "Knowledge in versioning control like GIT.\n",
      "Involved in Responsive web development using Bootstrap.\n",
      "Strong Analytical, Problem solving skills, Presentation skills and  good team player.\n",
      "I can work with independently.\n",
      "\n",
      "\n",
      "SCHOLASTICS\n",
      "                B.Tech (Computer Science Engineering.) from VKR ,VNB & AGK  College of Engineering and Technology,  Gudiwada, affiliated to JNTUK with 76.4% in 2019.\n",
      "TECHNICAL SKILLS\n",
      "Web Technologies\t                :\tHTML, CSS, BOOTSTAP,JAVASCRIPT, JQUERY, \n",
      "                                                                             PHP, React js , Node js.                                                                              \n",
      "Database\t                               :\tMYSQL\n",
      "Operating System\t                :\tWindows\n",
      "IDE\t\t\t\t :\tVisual Studio, NetBeans\n",
      "Code repository Tools                      :             GIT\n",
      "Web Servers\t\t\t :             Apache\n",
      "Installers                                             :             XAMPP\n",
      "PROJECTs\n",
      "Project #1: \n",
      "Name\t\t :             RMC (Redimix Concrete)\n",
      "Duration               :             Sept 2019  - Till now\n",
      "        Team Size\t :\t5\n",
      "        Environment\t :\tHTML, CSS, Bootstrap, MySQL, React js ,Node js.\n",
      "\n",
      "Description:\n",
      "                It is a product built for Instant Redimix Concrete(RMC). This product is  related to construction industry which supplies   redimix concrete  based on customer requirement. . Take orders from Customers, Business or a mix of both.It manages all your sales, stock, accounting, shipping and customer data from a single place. Inventory control improves tracking and control other inventory activities and stock movements.\n",
      "\n",
      "Responsibilities\n",
      "Active Participation in development with timely delivery as per the deadlines.\n",
      "Designed website using HTML and CSS .\n",
      "Programming and coordinating with Team \n",
      "Responsibilities include database design, code profiling and extensive documentation.\n",
      "Review and perform the design validation by working with client.\n",
      "Implemented on validations with required fields dynamically.\n",
      "   Coordinating with team and client for weekly status calls.\n",
      "   .Close follow up with the testing team in resolving issues.\n",
      "    Review with end user on key functionalities of the system and work on improvements of the application technically.\n",
      "\n",
      "Career Profiles\n",
      "Software Developer at Maganti IT Solutions,Vijayawada  from  5th August  2019\n",
      "\n",
      "\n",
      "    DATE:                                                                                                                    Mareedu Lokesh Babu\n",
      "    PLACE:                                                                                                                   SIGNATURE:\n",
      "\n",
      "Processing text:\n",
      "MAREEDU LOKESH BABU\n",
      "\n",
      "PROFESSIONAL OVERVIEW\n",
      "   Around 2  years of experience in software design, development, implementation and maintenance of applications using, HTML, CSS, JavaScript, JQuery, PHP, MySQL, React js , Node Js.\n",
      "Knowledge in Object Oriented PHP Programming.\n",
      "Knowledge in versioning control like GIT.\n",
      "Involved in Responsive web development using Bootstrap.\n",
      "Strong Analytical, Problem solving skills, Presentation skills and  good team player.\n",
      "I can work with independently.\n",
      "\n",
      "\n",
      "SCHOLASTICS\n",
      "                B.Tech (Computer Science Engineering.) from VKR ,VNB & AGK  College of Engineering and Technology,  Gudiwada, affiliated to JNTUK with 76.4% in 2019.\n",
      "TECHNICAL SKILLS\n",
      "Web Technologies\t                :\tHTML, CSS, BOOTSTAP,JAVASCRIPT, JQUERY, \n",
      "                                                                             PHP, React js , Node js.                                                                              \n",
      "Database\t                               :\tMYSQL\n",
      "Operating System\t                :\tWindows\n",
      "IDE\t\t\t\t :\tVisual Studio, NetBeans\n",
      "Code repository Tools                      :             GIT\n",
      "Web Servers\t\t\t :             Apache\n",
      "Installers                                             :             XAMPP\n",
      "PROJECTs\n",
      "Project #1: \n",
      "Name\t\t :             RMC (Redimix Concrete)\n",
      "Duration               :             Sept 2019  - Till now\n",
      "        Team Size\t :\t5\n",
      "        Environment\t :\tHTML, CSS, Bootstrap, MySQL, React js ,Node js.\n",
      "\n",
      "Description:\n",
      "                It is a product built for Instant Redimix Concrete(RMC). This product is  related to construction industry which supplies   redimix concrete  based on customer requirement. . Take orders from Customers, Business or a mix of both.It manages all your sales, stock, accounting, shipping and customer data from a single place. Inventory control improves tracking and control other inventory activities and stock movements.\n",
      "\n",
      "Responsibilities\n",
      "Active Participation in development with timely delivery as per the deadlines.\n",
      "Designed website using HTML and CSS .\n",
      "Programming and coordinating with Team \n",
      "Responsibilities include database design, code profiling and extensive documentation.\n",
      "Review and perform the design validation by working with client.\n",
      "Implemented on validations with required fields dynamically.\n",
      "   Coordinating with team and client for weekly status calls.\n",
      "   .Close follow up with the testing team in resolving issues.\n",
      "    Review with end user on key functionalities of the system and work on improvements of the application technically.\n",
      "\n",
      "Career Profiles\n",
      "Software Developer at Maganti IT Solutions,Vijayawada  from  5th August  2019\n",
      "\n",
      "\n",
      "    DATE:                                                                                                                    Mareedu Lokesh Babu\n",
      "    PLACE:                                                                                                                   SIGNATURE:\n",
      "\n",
      "Processing text:\n",
      "MD KHIZARUDDIN RAUF \n",
      " \t EXPERIENCE \n",
      "     \n",
      "⇨ Currently working in PickupBiz Solution Private Limited, Pune from January 2021 to till date \n",
      "⇨ 9 Months of working as an Intern on UI React JS - Software Developer \n",
      "⇨ Having sound experience and exposure on UI development using React JS, Bootstrap, HTML 5, CSS, React Hooks, and Redux etc. \n",
      "⇨ Ability to work under any given environment \n",
      "⇨ Demonstrated good communication and Analytical skills \n",
      "⇨ Team building skills, emphasizing versatility and adaptability \n",
      "⇨ Dedication and drive as a hard-working individual \n",
      "⇨ Ability to manage multiple tasks in a pressured environment \n",
      "                                                                           \n",
      "Application Development & UI Designing – \n",
      " Coordinated with the development team of 10 to discuss user interface ideas and applications. - Reviewed application requirements and interface designs to ensure compatibility with existing applications.  \n",
      " \n",
      "UI Components Designing & Application Interface Coding –  \n",
      "Identified web-based user interactions and developed highly responsive user interface components via React concepts. - Translated designs & wireframes into high-quality code and wrote application interface via JavaScript following React.js workflows. \n",
      " \n",
      "Code Debugging & Front-end Architecture –  \n",
      "Troubleshoot interface software and debugged application codes to improve functionality and performance. - Developed and implemented front-end architectures to support user interface concepts with accuracy. \n",
      " \n",
      " \n",
      " \n",
      "Career seeking \n",
      " \n",
      "Seeking assignments in an organization that allows me to utilize my skills and can nurture them so that I can contribute highly in the growth of the organization individually as well as in Team, while being resourceful, innovative and flexible. \n",
      " \n",
      " \n",
      "EDUCATION \n",
      "                                                                                                                                                               12/2020 \n",
      " SWAMI RAMANAND TEERTH MARATHWADA UNIVERSITY NANDED \n",
      " BSC. KANDHAR, NANDED, MAHARASHTRA. \n",
      " \n",
      " \n",
      " \n",
      "PERSONAL DOSSIER \n",
      " \n",
      "Total Experience:9 Months as an Internship. \n",
      "Nationality: \n",
      "Indian \n",
      " \n",
      "DOB:  \n",
      "1-06-1998 \n",
      " \n",
      "Marital Status : \n",
      "Unmarried \n",
      " \n",
      "Languages: \n",
      "English, Hindi, Marathi, Urdu \n",
      " \n",
      "Hobbies:  \n",
      "Learning New Technologies like Node JS, MySQL, MongoDB, Playing Cricket. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "SKILLS \n",
      "UI Designing \t• Application Designing \n",
      "Wireframe and design Pattern translation \t• Performance Improvement \n",
      "Webpage Designing \t• Project Delivery \n",
      "Coding \t• Debugging \n",
      "Front-End Architecture \t• Feature Designing • Webpage Optimization \t• Client Surviving \n",
      "2 \n",
      "PROJECTS \n",
      " \n",
      "WORKED ON HIGHLY RESPONSIVE REACT JS PROJECTS AND DESIGNED COMPONENTS USING JAVASCRIPT, BOOTSTRAP, REACT-REDUX AND REACT HOOKS. \n",
      " \n",
      " FOLLOWING ARE SOME PROJECTS WHICH I WORKED ON. \n",
      " \n",
      " E-SUPERMARKET  WEB APP . \n",
      " \n",
      " PDAC APP. \n",
      " \n",
      " E – DICTIONARY. \n",
      " \n",
      " EMPLOYEE SEARCH. \n",
      " \n",
      "EMI CALCULATOR. \n",
      " \n",
      "PIANO. \n",
      " \n",
      " \n",
      " \t \t \t \t \n",
      "I hereby declare that the above information is true to best of my knowledge. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Place: Nanded \n",
      " \n",
      "Date:                                                                                            MD KHIZARUDDIN RAUF \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "3 \n",
      "\n",
      "Processing text:\n",
      "\n",
      "Name: M. Prabakaran \n",
      "Title: UI Developer\n",
      "PROFESSIONAL SUMMARY\n",
      "●2.4+ years of Professional IT experience as a software developer having knowledge on different UI based \tApplication.\n",
      "●Hands on experience in HTML, CSS, JS, ReactJS. \n",
      "●Hands on experience in handling UI interaction, Design methodology.\n",
      "●Handling In-App purchase, uploading and maintaining apps in play store.\n",
      "●Hands on experience with customization over base-product depends on client requirement. ●Cohesive team worker, having strong analytical, problem solving and interpersonal skills.\n",
      "EDUCATION\n",
      "●\tCompleted on 2017 Bachelor of Technology (ECE), PRIST University, Tamil Nadu.\n",
      "●\tCompleted on 2012 Higher Secondary, Mount Park Hr Sec School, Thiyagadurgam, Tamil Nadu.\n",
      "●\tCompleted on 2010 SSLC, Krishnasamy Hr Sec School, Cuddalore, Tamil Nadu.\n",
      "SKILLS \n",
      "PROJECT DETAILS\n",
      "Project 1\n",
      "Page | 1 \n",
      "\n",
      "\n",
      "Project 2\n",
      "Project 3\n",
      "Basic Details: \n",
      "Page | 2 \n",
      "\n",
      "Processing text:\n",
      "\n",
      "Pranish Sonone\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Career summary:\n",
      "\n",
      "\n",
      "Experience of 1 years & 2 months working as Jr. React Developer which includes over 1 year of experience in React JS.\n",
      "Hands on experience in developing web pages using ReactJS, Redux, JavaScript, HTML5,  CSS3.\n",
      "Extensive knowledge of ES6.\n",
      "Analysis and design of reports and user interfaces with  reporting.\n",
      "Good communication, collaboration with proficiency at grasping new technical concepts quickly and\n",
      "utilize the same in a productive manner.\n",
      "Good team player with strong interpersonal skills.\n",
      "\n",
      "\n",
      "Technical skills:\n",
      "\n",
      "Web Technologies: ReactJS,  JavaScript, ES6, HTML5, CSS3.\n",
      "\n",
      "Work experience:\n",
      "\n",
      "Currently working with Saffire Softtech, Pune from August 2020 to till date as Jr. React Developer.\n",
      "\n",
      "Projects:\n",
      "\n",
      "Project 1: Ecommerce Portal\n",
      "Role – React JS Developer\t\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Develop UI as per requirement and mockup using react .\n",
      "Create pages for different screen resolutions using CSS and Material UI.\n",
      "Develop components as per the clients requirement.\n",
      "\n",
      "\n",
      "Project 2: Developing Company Website\n",
      "Role- React JS Developer\n",
      "Roles and Responsibilities:\n",
      "Involved in developing react components for website.\n",
      "Worked in developing various functionalities.\n",
      "Involved in designing website by using CSS and material UI\n",
      "\n",
      "\n",
      "\n",
      "Educational Qualification:\n",
      "\n",
      "\n",
      "Personal Profile:\n",
      "\n",
      "Date of Birth: 8th Oct 95\n",
      "\n",
      "Marital Status: Single\n",
      "\n",
      "Language Known: English, Hindi & Marathi\n",
      "\n",
      "\n",
      "Declaration:\n",
      "\n",
      "I hereby declare that all the above information and particulars are true to the best of my knowledge.\n",
      "\n",
      "Place: Pune\tPranish Sonone\n",
      "\n",
      "Processing text:\n",
      "Ranga Gaganam  \n",
      " \n",
      " \n",
      "Having 1+ years of successful IT experience in all phases of Software Development Life Cycle (SDLC) as a React.JS Developer and JavaScript. \n",
      " \n",
      " \n",
      "Experience in design and configuration for implementation, development, maintenance and support as a React.JS Developer to meet business needs. \n",
      "Good working knowledge on React Hooks, JavaScript, HTML. \n",
      "Developing new user-facing features using React.js \n",
      "Building reusable components and front-end libraries for future use. \n",
      "Strong proficiency in JavaScript, including DOM manipulation. \n",
      "Thorough understanding of React.js and its core principles \n",
      "Familiarity with newer specifications of ECMA Script \n",
      "A proactive learner for adopting emerging trends and addressing industry requirements to achieve the organizational objectives. \n",
      "Good communication, presentation and interpersonal skills. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "PROJECT : \n",
      " \n",
      "\tTitle \t: E care Management System \n",
      "\tOrganizer \t: Metrolabs Services Pvt ltd. \n",
      "\tDesignation \t: Junior UI Developer \n",
      "\tTechnologies \t: REACTJS, HTML5, CSS3, JAVASCRIPT \n",
      " \n",
      "Summary:- \n",
      " \n",
      " In this application there are several modules like Employee, Patients,  Admission,Lab management,prescription Pharmacy management,OT  Management..      \n",
      " \n",
      " My Roles & Responsibilities: \n",
      "Developed the UI components for the web application. \n",
      "Developed signup page for this project , for the login authentications use  the firebase. \n",
      "E care management software is a react application it is used for hospitals to manage all the services and information \n",
      "In this application there are different stake holders like accountant, admin,Doctor,Lab,Technician and Physical.. \n",
      "\n",
      "\n",
      "Processing text:\n",
      "SHAIK ABDUL SHARUK   \n",
      "2 years’ Experience in Wipro \n",
      "Career Objective: \tA challenging pursuit in a reputed organization where I can utilize my skills and strengths and conjunction with common goal and objective for mutual growth \n",
      "LinkedIn Profile:                 https://www.linkedin.com/in/sharuk-abdul-99b754197 \n",
      "GitHub Profile:                   https://github.com/sharukabdul \n",
      "Email Address:                    sharukabdul786@gmail.com \n",
      " \t \n",
      "\n",
      " \t \n",
      "EXPERIENCE: \n",
      " \n",
      "Wipro \tMar-2019 to Feb-2021 \n",
      "Senior Associate \n",
      "JOB RESPONSIBILITIES: \n",
      "Worked on auto machine Waymo Self driving car     \n",
      "Operating the autonomous vehicles by labelling the objects    \n",
      "Test the real time scenario captured by the lidar data     \n",
      "As per the lidar data we need to test and label the object \n",
      " \t \n",
      "\n",
      " \t \n",
      "TECHNICAL SKILLS: \n",
      " \n",
      "\n",
      " \t \n",
      "GITHUB PROJECTS: \n",
      " \n",
      "Blog Application (React JS) To-do List Built in React-Redux    https://github.com/sharukabdul/Todo-List \n",
      "A simple to-do list App built with React, Redux This App is built with following features: \n",
      "User can add, delete and mark complete a to-do item. \n",
      "Redux library is used for state management. \n",
      "Highlight’s to-do status in \"red\" if it crosses completion date. \n",
      " \n",
      " \n",
      " \t \t \n",
      "\n",
      " \t \t \n",
      "\n",
      " \t \n",
      "LANGUAGES: \n",
      "English, Hindi and Telugu \n",
      " (Read, Write and Speak) \n",
      " \t \n",
      "\n",
      " \t \n",
      "DECLARATION: \n",
      "I hereby declare that all the above furnished information is correct and true to best of my knowledge.  \n",
      "Place:  \n",
      "Date: \n",
      " \n",
      "Shaik Abdul Sharuk \n",
      " \n",
      "\n",
      "Processing text:\n",
      "ANIL KUMAR MADDUKURI  \t\t\n",
      "SQL & MSBI Developer   \n",
      "\n",
      "\t\n",
      "\n",
      "Summary\n",
      "\n",
      "2.4 years of experience in MS SQL Server (SSMS) and creating SSIS packages, SSRS Reports by using Microsoft Business Intelligence (MSBI) tools.\n",
      "Expertise in various types of Joins and Sub Queries for writing complex queries involving multiple tables.\n",
      "Handled data manipulation and data consistency by creating Views, Triggers, and Synonyms.\n",
      "Hands on experience in creation, optimization and debugging Stored Procedure and Functions.\n",
      "Familiar in writing queries using CTE, Temporary Tables and Table Variables.\n",
      "Good experience in using Set Operators like Union, Union All, Except and Intersect to assist required data.\n",
      "Experience in manipulate the data from multiple table and report to the client using Aggregate Functions, Windows Functions and String Functions.\n",
      "Worked extensively on Data Extraction, Transformation and Loading (ETL) process in SQL Server Integration Services.\n",
      "Used containers such as for each loop container and sequence container to load the data from multiple source file to Database tables.\n",
      "Expertise in using tasks like  Data flow Task, Execute SQL task ,Control Flow task Execute package task, Execute Process task, Bulk insert Task,  Sends Mail task and FTP Task and Script task at the control flow level .\n",
      "Experience in using Data conversion,OLEDB command, Row count, Union All, Derived Column, Merge, Merge Join, Fuzzy lookup, Conditional Split and various other Transformation to manipulate data in SSIS package at the Data Flow Level for moving typical data from source to destination.\n",
      "Implemented SSIS Loggings, check-points Break points and package configurations source system to another source system and ETL operations.\n",
      "Good experience in developing Table Reports, Sub Reports, Matrix Reports, Drill down Reports, Drill through Reports using SQL Server Reporting Services.\n",
      "Involved in Linked reports, Cache reports, and Snapshot reports in report manager level.\n",
      "Expertise in performing backup and restore the database.\n",
      "Created Indexes like Clustered Index and Non-Clustered Index to improve the performance.\n",
      "\n",
      "Technical Skills\n",
      "Languages\t           :  SQL, T-SQL\n",
      "RDBMS\t           :  SQL Server 2016/2012/2008 \n",
      "ETL Tools\t           :  SQL Server Integration Services (SSIS)\n",
      "Reporting Tools         :  SQL Server Reporting Tools (SSRS)\n",
      "\n",
      "Professional Experience\n",
      "Currently working as Software Engineer in Imagine Technology and Services Pvt. Ltd \n",
      "       Since 2019 to till date.\n",
      "Project Experience\n",
      "Project\t\t\t:  Health Insurance\n",
      "Client\t\t\t:  Aetna, USA\n",
      "Environment\t\t:  MS SQL SERVER 2016, SSIS, SSRS, Visual Studio 2015 \n",
      "Duration\t\t:  April 2019 to Till Date\n",
      "\n",
      "Description: \n",
      "This project is developed for Aetna Insurance. This is an American managed health care company sells traditional and consumer directed health care insurance and related services, Such as medical, dental, long-term care, and disability plans, primarily through employer-paid (fully or partly) insurance and benefit programs. The main goal of this project Implementing Customer Information into Database and Developing mechanism to revert data from database. \n",
      "Responsibilities: \n",
      "\n",
      "Create/update indexes, views, Stored Procedures, user defined functions, common table expressions (CTEs) and Triggers. \n",
      "Develop SSIS Packages by extracting data from diversified sources like Excel, CSV, flat file, Text and load into staging area.\n",
      "Use transformations like Aggregate, Conditional Split, Derived Columns, Row Count, Merge and Merge Join, Multicast, Slowly Changing Dimension to manipulate data in data flow level\n",
      "Implement event handlers for the packages, maintain log information and provide checkpoints in SSIS level. \n",
      "Design packages in control flow levels based on tasks like Data Flow Task, Execute SQL Task, FTP tasks and used For Each Loop Container, Sequential Container.\n",
      "Generate reports in the form of Matrix, Table by using SSRS from SQL Server Database and included various reporting features such as drilldown, drill through, sub reports. \n",
      "Involved in setting up SQL Server Agent Jobs for periodic Backups with backup devices, database maintenance plans and recovery.\n",
      "Maintained / managed database agent jobs, check for failures and resolve failure issues.\n",
      "Used SQL Profiler and query tuning Wizard to troubleshoot problems and queries.\n",
      "\n",
      "Education\n",
      "B.Tech - Velagapudi siddhartha engineering college,Vijayawada\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\n",
      "Aradhana Tripathi\n",
      "\n",
      "Current Location: Gachibowli, Hyderabad\n",
      "\n",
      "Profile Summary:\n",
      "\n",
      "An accomplished data driven analytical professional have more than 4 years of working experience in information technology & Service industry.\n",
      "Currently working as SQL Database Developer and have 3 years of experience in database design, development, analysis and support of using MS SQL Server, MySQL (MariaDB) and Athena (AWS) in development, testing and production environments.\n",
      "Extensive experience in writing complex queries, creating Tables, Views, Union, Triggers, Stored Procedures, User Defined Functions (UDF’s), System Defined Functions, and other T- SQL statements, Constraints and Indexes using various DDL and DML Commands.\n",
      "Experience in using sub-queries and joins to simplify complex queries involving multiple tables.\n",
      "Experience in working on amazon relational database (AWS RDS).\n",
      "Have basic understanding on using analytical tools and technologies such as SAS, R, Bigdata (Hadoop, Hive, HQL query) etc.\n",
      "Had experience in requirement gathering, stakeholder management, account management and business insights visualization preparing dashboard using tableau and Excel.\n",
      "Technical Skills:\n",
      "\n",
      "Languages: SQL, SAS, R, Python\n",
      "DBMS: MS SQL Server, T-SQL, AWS RDS (Athena), MariaDB (Version of MySQL)\n",
      "IDE: SQL Server Management Studio (SSMS), RazorSQL, HeidiSQL, RStudio\n",
      "Visualization Tools: R, Tableau, Excel\n",
      "Domain: Media & Publication, BFSI, Retail\n",
      "Employment History:\n",
      "\n",
      "Currently working with Condé Nast (https://www.condenast.com/) as SQL Database Developer through Jigyasa Analytics, LLC Since Aug 2019.\n",
      "Worked with Tech Mahindra as Business Associate from Apr 2015 to Jan 2017.\n",
      "Worked with People Tech Group as IT Consultant from Jun 2013 to Mar 2015.\n",
      "Project Details:\n",
      "\n",
      "Project: Migration of On-Premises SAS Regression Models to Athena (AWS)\n",
      "Client:  Conde Nast\n",
      "Role: MS SQL developer\n",
      "Project Description: This project is about migration of logistic regression models in SAS to Athena (AWS) and development of new code in SQL Server then Athena (AWS). The purpose of Migration is to take advantage of AWS cloud features like cost optimization, scalability and high availability.\n",
      "Roles & Responsibilities: \n",
      "Developing and designing SQL code for models in MS SQL Server.\n",
      "Developing and designing SQL code for models in MySQL (MariaDB).\n",
      "Final implementation of model in production environment Athena (AWS).\n",
      "Created reusable code in Athena to automate model scoring.\n",
      "Writing query to push data on S3.\n",
      "Model Validation in Stagging environment.\n",
      "Technical Platform: MS SQL Server 2014, MySQL, HeidiSQL, RazorSQL, SAS, Athena (AWS), Excel etc.\n",
      "\n",
      "Project: Retail Sales Portal Development\n",
      "Client:  One of the leading retail Client\n",
      "Role: MS SQL developer\n",
      "Project Description: This project is all about online ecommerce data comprises the details about customer id, country, customer came from source of traffic, which channel used for transactions. Number of purchases made on particular product & services, frequency of visits. Also given the information about total sales, gross profit, net profit made certain period of time and discount offers to customers. Each of these details used to do data analysis that subsequently helps management in decision making.\n",
      "Roles & Responsibilities: \n",
      "Understanding existing functionality and database design.\n",
      "Database design, creating normalize tables using constraints, functions.\n",
      "Develop complex SQL queries, views, triggers, stored procedures.\n",
      "Maintaining data quality and integrity.\n",
      "Technical Platform: MS SQL Server 2014\n",
      "\n",
      "Academic Project - IIIT Bangalore (Jun 2018 to Jul 2019):\n",
      "\n",
      "Project: Human Resource Database Management Systems\n",
      "Project Description: Human Resource Database Management System creates stores and manages all the data needed to describe the personal and their framework within an organization. It includes definition of various levels of hierarchy in an organization, the salary structure pertaining to every element in this hierarchy, the description of every department functioning in the organization and the overall employee database which integrates elements in all the aforementioned.\n",
      "Roles & Responsibilities: \n",
      "Database design and development.\n",
      "Effective data handling.\n",
      "Effective data retrieval and maintenance.\n",
      "Created features to implemented database security.\n",
      "Technical Platform: MS SQL Server, MS Excel, Tableau\n",
      "\n",
      "Project: CredX Risk Analytics\n",
      "Project Description:  Business objective is to help CredX to identify the right customer using predictive models. Used past data of bank’s applicants to determine the factors affecting credit risk and create strategies to mitigate the acquisition risk. \n",
      "Roles & Responsibilities: \n",
      "Business Understanding, Data cleaning and preparation\n",
      "Building predictive models (Logistic regression, random forest, decision tree etc).\n",
      "Deploy the best fitted model.  \n",
      "Technical Platform: RStudio, MS SQL Server, Excel etc.\n",
      "\n",
      "Academic Qualification \n",
      "\n",
      "Post Graduate Diploma in Data Science from IIIT - Bangalore’19, CGPA 3.2/4\n",
      "MCA, Computer Applications & Information Technology and Sciences from AKS University.\n",
      "\n",
      "Processing text:\n",
      "BUDDHA VAMSI                                                            \n",
      "\n",
      "CAREER OBJECTIVE:\n",
      "\n",
      "Have 2.11 years of IT experience as Database Engineer and currently working in Fluentgrid Limited Visakhapatnam from August 2018 as Database Engineer.\n",
      " Having good hands on SQL, PLSQL at various databases like Oracle, MS Sql Server.\n",
      "Expertise in creating/modifying Tables, Views, Stored Procedures, Functions and indexes.\n",
      "Having knowledge on Triggers, Temporary tables, CTE Recursive Methods.\n",
      "Expertise in writing transformations (ETL) using Business Intelligence tools like Pentaho Kettle.\n",
      "\n",
      "\n",
      "\n",
      "ACADEMIC PROFILE:\n",
      "\n",
      "\n",
      "TECHNICAL SKILLS:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ACHIEVEMENTS AND AWARDS:\n",
      "\n",
      "Two day workshop on SIIMAD(Symbyosis Innovation and Intelligene for Moblie Application Development) at Miracle engineering college ----- Mar 2013\n",
      "International workshop on SSE(security and software engineering) at DIET ---- Feb 2013\n",
      "International workshop on BITD(Business Intelligence and Test Driven Development) ---- Dec 2012\n",
      "Cyber Forensics workshop at NIT warangal ----- Aug 2012\n",
      "Ethical Hacking conducted by Cybercure solutions ----- Aug 2012\n",
      "\n",
      "Two day workshop on cloud computing technology at DIET----Jan 2015\n",
      "\n",
      "I   Achieve IBM Bluemix certificate  in cloud computing technology for creating app in cloud\n",
      "I actively participated in DIET-NSS UNIT\n",
      "\n",
      "PERSONAL PROFILE:\n",
      "Name \t\t:  Buddha Vamsi\n",
      "Father’s Name\t:  B.Dharma Raju\n",
      "Mother’s Name      :  B.Jaya Lakshmi \n",
      "DOB\t\t\t :  22-08-1994\n",
      "Sex\t\t\t : male    \n",
      "Marital Status\t : Single\n",
      "Nationality\t\t :  Indian\n",
      "Languages Known\t :  English, Telugu\n",
      "Hobbies \t\t :  Playing Cricket\n",
      "\n",
      "DECLARATION:\n",
      "\n",
      "              I hereby declare that the above information's are true to best of my knowledge.\n",
      "     \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "Processing text:\n",
      "KAMBALLA PRADEEP                                                                   \n",
      "SYNOPSIS\n",
      "\n",
      "Looking forward to aspire a challenging career, where in enhancing my technical   knowledge and work hardly towards the growth of the organization.\n",
      "SUMMARY\n",
      "\n",
      "Having 2.8 years of Professional Software development experience in the areas of developing and supporting applications based on Microsoft SQL Server.\n",
      "Proficient in Relational Database Management Systems (RDBMS).\n",
      "Expertise in Transact-SQL (DDL, DML, DCL) and in Design and Normalization of the database tables.\n",
      "Experience in implementing business logic using Triggers, Indexes, Views and Stored Procedures.\n",
      "Extensive knowledge of advance query concepts (e.g. group By, having clause, union so on).\n",
      "Experience with tools like SQL Server management studio and SQL Server2008r2/2012 Integration (SSIS).\n",
      "Experience in Creating and Updating Clustered and Non-Clustered Indexes to keep up the SQL Server Performance.\n",
      "Self-motivated and ability to learn and grasp new technologies and domain knowledge.\n",
      "Excellent analytical, communication and interpersonal skills. Proficient in technical writing and presentations and a good team player.\n",
      "Experienced in authoring and deploying SQL Server Integration Services (SSIS) packages.\n",
      "Good Experience in optimizing the queries by creating various clustered, non-clustered indexes and indexed views\n",
      "Extensive experience with SQL Server and T-SQL in constructing Procedures, triggers, Tables, Table variables, user defined functions, views, indexes, CTE, temp tables, relational database models.\n",
      "\n",
      "Education Details\n",
      "                        Graduated in B.sc  from Sri Venkateshwara University, Tirupathi,2018.\n",
      "WORK EXPERIENCE\n",
      "\n",
      "Currently working as a software Engineering in Coginic Technologies pvt Ltd., from JUN-2018 to 04th feb 2021 in Hyderabad.\n",
      "TECHNICAL SKILLS\n",
      "\n",
      "\n",
      "Project Details:\n",
      "Project 1:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                       \n",
      "\n",
      "\n",
      "Processing text:\n",
      "B. Tech (Electronics and Communications Engineering ) in 2015na. with date functions. Developed Stored Procedures and using joins, sub queries, functions and views.ss based on their country level applied roles to restrict data to specific region. the reports are pointing either to cube or to relational DB. The major taskis to understand the requirement of report then replicate it in power bi. As both the tools are entirelydifferent, many challenges are handled to achieve the same.Best Customer Report, Best Product sold report, Best Promotion report, etc.\n",
      "\n",
      "Processing text:\n",
      " \n",
      "                                        Resume\n",
      "Name     :  Neeraj Mishra\n",
      "\n",
      "\n",
      "Having 3 year  6 Month of Experience on Oracle Developer.\n",
      "Experience in Oracle 11g, 12c, SQL and PL/SQL programming.\n",
      "Experience in Creation of Tables, Indexes using SQL and PL\\SQL.\n",
      "Extensively worked on Backend Programming using PL/SQL\n",
      " Stored Procedures, Functions, Packages, triggers, Exception Handling.\n",
      "Expertise in creating Oracle Tables, Views, Joins.\n",
      "Experience in Writing SQL Queries, Understanding Requirements.\n",
      "Knowledge on implementing securities using Roles, Privileges and Grants.\n",
      "Good Knowledge on Recursive Query Techniques, Pseudo Column implementations, SET Operators, Understanding Transaction Control, Materialized Views.\n",
      "Extensively worked with DDL, DML and TCL statements.\n",
      "Ability and willingness to learn new technology and acclimatize to any work culture.\n",
      "Able to adapt quickly to the environment and willing to work in shifts.\n",
      "\n",
      "\n",
      "\n",
      "I have completed B.E from RGPV Bhopal in 2013.\n",
      "\n",
      "\n",
      "I am working in oracle developer in Fabex tech solution pvt Ltd from 2017 Till.\n",
      "\n",
      "Operating system             :  Windows \n",
      "Database                            :  Oracle 11g, 18c.\n",
      "Programming Languages:  SQL, PL/SQL, UNIX \n",
      "Technical Skill                    :  Oracle Sql , PL/SQL\n",
      "Tools                                    :  SQL Developer, CRM, Sql* loader\n",
      "Environment                      :   Oracle 11g, Window\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "#           Project Name:  BOLT (Back Office Legacy Transition)\n",
      "Technology     :  SQL, PL/SQL, Oracle\n",
      "Tool\t             :  SQL, Plsql Developer, CRM, Sql*loader\n",
      "Role                  :   Sql & PLSql developer\n",
      "Environment :   Oracle 11g, Windows\n",
      "Team Size        :  8\n",
      "Duration          :  March 2019 to till \n",
      "\n",
      "Description:  BOLT, Back Office Legacy Transition is an application which processes all the orders coming Into D&B through various order entry systems. BOLT is the heart of the back-office application. It is the prime application that is responsible for offers, pricing, transaction, billing and invoicing and doing the revenue recognition. Transaction records from several other systems come into BOLT and get processed. BOLT also Sends feeds to several other systems such as AR, Quantum, and GL etc.\n",
      "\n",
      "Roles &Responsibilities:\n",
      "Involved in writing complex SQL Queries, PLSQL code to implement the business requirements.\n",
      "Perform DML, DDL Operations as per the Business Requirements.\n",
      "Involved in the Development Backend Code, Altered Tables to Add New Columns, Constraints, Sequences and Indexes as per Business Requirements.\n",
      "Resolved Production issues by modifying backend codes as and when required.\n",
      "Involved in Creating the Procedures, Functions, Trigger and Views.\n",
      "All these details we are updating in our database throw the help of sql*loader.\n",
      "Worked with Joins, Sub-Queries/Co-related Sub-queries .\n",
      "Detailed analysis of the change request or project requests received from the users or back end applications, development and implementation of the changes.\n",
      "Experience in Client interaction.\n",
      "\n",
      "\n",
      "#   Project Name:   M-ONE services\n",
      "    Technology    :  SQL, P L/SQL, Oracle \n",
      "    Tool\t                :  SQL, Plsql Developer, CRM, Sql*loader\n",
      "    Role                 :   sql & plsql developer\n",
      "   Environment  :   Oracle 11g, Windows\n",
      "   Team Size        :  8\n",
      "   Duration          :   Oct 2017 to Feb 2019\n",
      "Description:  M-ONE is a web application, exclusively designed for the client MOT. They produce Website Designs and Products to Internet Users. In the process they offer Complete Graphic Design, Website Design and Development, Web Hosting & Maintenance, e Solutions, Various types of Online Requests, etc.\n",
      "  It consists of Services & Admin Module. Services Module deals with maintenance of the user information. MOT provides services to the users based on the information which is maintained in this module from the Database.\n",
      "\n",
      "Roles & Responsibilities:\n",
      "Gathering the requirements from the business users and analyzing them to implement.  Analysis of the Problem Statement and Requirement Gathering.\n",
      "Working upon production incidents, analyzing & resolving them.\n",
      "Working on Change / Business Requirements.\n",
      " Extensively used the Procedures, Functions, Views, Materialized views, Packages.\n",
      "Triggers and Indexes etc to fulfill the business requirements. \n",
      "Used SQL* Loader to load data into different tables.\n",
      "Coordinated with DBA in improving Database Performance. \n",
      "Enhancement of current functionality to improve system performance \n",
      " \n",
      "\n",
      "\n",
      "I hereby declare that the information furnished above is true and correct to the best of my knowledge.\n",
      "\n",
      "Date:\t                                                                                                                       Néeraj Mishra\n",
      "Place:                                                                                                                         Bangalore \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "SQL DEVELOPER\n",
      "Name: -   Bandi prem sai\n",
      "\n",
      "\n",
      "Willing to work under a challenging and professional environment with exposure to new Technologies as a T-SQL in the area of SQL SERVER 2012/2016 with Enterprise Portal and where there is ample scope for Organizational growth as well as individual growth.\n",
      "\n",
      "\n",
      "2.6 years of experience in Microsoft SQL Server environment, with thorough knowledge of SQL Server 2012/2016 databases. \n",
      "Expertise in scripting T-SQL queries, Stored Procedures, User Defined Functions and Triggers.\n",
      "Hands on experience in performing Error Handling and performance tuning in Stored Procedure.\n",
      "Good experienced in creating and using Temporary table, Table Variable and CTE’s (Common table Expressions)\n",
      "Used Sub-Queries, Derived table and Joins to simplify complex queries involving multiple tables.\n",
      "Expertise in creating, maintaining database objects like Indexes, Functions, views, UDF’s, constraints.\n",
      "Good experience in using Ranking Functions, Date Functions, String Functions and Aggregate Functions\n",
      "Good Knowledge in Transactions, Isolation level, Concurrency Problems\n",
      "Very good experience in building the Relationship using Constraints.\n",
      "Good Knowledge in Creating Jobs to automate process using SQL Server Agent.\n",
      "Good Knowledge on new features in SQL Server 2016, 2019.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "B.C.A from Sri Venkateswara University,Tirupathi.\n",
      "\t\n",
      "\n",
      "Worked At TECHASOFT PVT LTD as Software Engineer, Bangalore since OCT-2018 to till date.\n",
      "\n",
      "\n",
      " Project II:-\n",
      "\n",
      "\tProject Name: -   Haematology Solutions\n",
      "\tClient Name \t : -   BRAVO PHARMA\n",
      "\tDomain\t : -    Health Care \n",
      "\tDuration            : -    Feb/2019 – Till date\n",
      "\tRole\t\t : -    SQL Developer \n",
      "\t\n",
      "\tDescription      :- \n",
      "\t\tBravo Pharma cares for the protection and enhancement of human health and well-being on all levels. The spectrum of our activities ranges from supporting education in life sciences and strengthening start-ups in health technologies, offering novel solutions for diagnostics and personalized treatment to production and sales of pharmaceuticals.\n",
      "\tResponsibilities:- \n",
      "Developed and optimized database structures, stored procedures, views, and user-defined functions for the Application.\n",
      "Created some T-SQL queries, Stored Procedures.\n",
      "Design and create SQL tables, indexes. \n",
      "Responsible for Query optimization and Performance tuning. Performing query plans and making sure each and every query is using appropriate useful indexes.\n",
      "Design and create SQL tables, indexes. \n",
      "Responsible for Query optimization and Performance tuning. Performing query plans and making sure each and every query is using appropriate useful indexes.\n",
      "Created Constraints mainly Primary Key and Foreign key.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project I:-\n",
      "\n",
      "\tProject Name: -   Integrated Simple Commerce Solution\n",
      "\tClient Name \t : -   CODI\n",
      "\tDomain\t : -    E- Commerce \n",
      "\tDuration            : -    Nov/2018 – Feb/2019\n",
      "\tRole\t\t : -    SQL Developer \n",
      "\t\n",
      "\tDescription      :- \n",
      "\t\tIntegrated Simple Commerce Solution is an Ecommerce application to sell products (such as Laptop, Printers etc.) through online. Integrated Simple Commerce Solution built with high end technology and it is integrated with many upstream and downstream systems to handle the business and full fill customer needs. Integrated Simple Commerce Solution having millions of customers around 16 countries and provides an easy way to find and buy the products.\n",
      "\tResponsibilities:- \n",
      "Developed and optimized database structures, stored procedures, views, and user-defined functions for the Application.\n",
      "Created some T-SQL queries, Stored Procedures.\n",
      "Design and create SQL tables, indexes. \n",
      "Responsible for Query optimization and Performance tuning. Performing query plans and making sure each and every query is using appropriate useful indexes.\n",
      "Design and create SQL tables, indexes. \n",
      "Responsible for Query optimization and Performance tuning. Performing query plans and making sure each and every query is using appropriate useful indexes.\n",
      "Created Constraints mainly Primary Key and Foreign key.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "PLACE: Hyderabad\t\t\t\t\t\t\t                    (Priyanka L)\ttrue to the best of my knowledge and beliefop container, Derived column, Conditional split, Data conversion, Sort, Merge, and Multicast.Billing), OT Modules etc. Cedars caters primarily to the professionals of Medical, visionary doctors, Nursing, Pharmacy, Physiotherapy, Paramedical, Allied Health, and the related fields. Major Service Offerings are in the fields of Healthcare and Medical Micro job and Journals Publishing, And Research & Publication Consultation and Assistance. We have been a part of your lives and have dispensed quality medical information related to all fields and diseases.\n",
      "\n",
      "Processing text:\n",
      "                                       SQL SERVER DEVELOPER\n",
      "\n",
      "\n",
      "P. Syam Kumar              \t\t\t          \t\t\n",
      "\n",
      "\n",
      "Professional summary:\n",
      "\n",
      "Having 2.3+ years of professional experience in IT industry. Involved in Microsoft SQL SERVER 2008, 2012, 2017 and have trained on ETL tools of SSIS.\n",
      "Good in designing objects of Tables with Constraints, Views.\n",
      "Experience in writing SQL Joins and Set Operators for data pulling and combining from multiple tables.\n",
      "Experience in using system functions (String functions, Date functions, Aggregate functions, Rank functions) to meet business requirement.  \n",
      "Experience with SQL Server in constructing Subqueries, Common Table Expressions (CTE), Temp Tables, and Table Variable with proper naming convention.\n",
      "Good working experience in T-SQL Concepts Stored Procedures, User Defined Functions, while loops, Cursors and Triggers.\n",
      "Knowledge on TCL , Error Handling and using of Magic Tables.\n",
      "Knowledge in creating Indexes and Performance Tuning\n",
      "Worked on data flow transformations like Look up, Sort, Data conversion, union-all and SCD’s.\n",
      "Good in Data Bases Backups, Restores, and Changing Synonyms.\n",
      "Trained on data extraction, transformation and loading (ETL) using SQL server integration services (SSIS) tool using different kinds of Sources and Destinations.\n",
      "Design the packages using Control Flow, Extract the data from source using of different transformations.\n",
      "\n",
      "Technical Profile:\n",
      "\n",
      "Databases\t\t          : SQL Server 2008, 2012, 2017\n",
      "IDE\t\t\t          : MS Visual Studio 2013, SSMS.  \n",
      "Other Tools \t\t          : MS Office Suite (Excel, Word, Notepad).\n",
      "ETL Tool\t\t          : SQL Server Integration Services (SSIS).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Company’s Information:\n",
      "\n",
      "Currently working as Software Engineer in Volaris Group-Tarantula India Pvt.Ltd from April 2019 to till date.\n",
      "\n",
      "Educational Qualification:\n",
      "\n",
      "M.C.A from S.V. University, Tirupathi from 2014- June 2017.\n",
      "\n",
      "Project summary:\n",
      "\n",
      "Project\n",
      "\n",
      "\tProject/ Client\t\t: ATC - American Tower Company.\n",
      "Role\t\t\t: SQL Developer.\n",
      "Team size\t\t: 10.\n",
      "Duration\t\t: April 2019 to till date in Tarantula.\n",
      "\n",
      "Description:\n",
      "\n",
      "ATC is publicly held company, owner and operator of wireless and broadcast communication infrastructure in several countries. The application is built in Software as a Service (SAAS) proposition. It acts as a medium between OpCo and TowerCo to manage mobile towers. The solution comprises innovative workflow-integrated end-to-end software applications. The provided application is completely based on windows authentication.\n",
      "\n",
      "Responsibilities:\n",
      " \n",
      "Involved in developing the new enhancements for the Application.\n",
      "Analyzing the change request (CR’s) requirements and discussed with managers and leads on Functionality.\n",
      "Involved in Production releases for database.\n",
      "Involved in impact analysis, requirement gathering, effort discussions and effort preparations for the new requirement. \n",
      "Involved to create views, writing complex stored procedures, Functions, Tables, using SQL Server 2012.\n",
      "Involved in Configuration of the Jobs as per the requirement and run the reports for QA checking purpose.\n",
      "Worked with integration services for transferring data from sources like flat file, CSV file, Excel file.\n",
      "Project deployment in all environments (Test, UAT, Live).\n",
      "\n",
      "\n",
      "\n",
      "Coordinating the Developing activities with the development team And QA team.\n",
      "Participate in discussions involving the application creation and understand the requirements and provide the back-end functionality for the applications.\n",
      "\n",
      "\n",
      "\n",
      "Declaration:\n",
      "\n",
      "I hereby declare that the information and facts stated above are true and correct to the best of my knowledge and belief.\n",
      "\n",
      "                    \t\t\t\t\t\t\t                    \n",
      " (P. Syam Kumar)\t\n",
      "\n",
      "Processing text:\n",
      " RAJU PAVANA KUMARI\n",
      "\n",
      "\n",
      "Professional Summary:\n",
      "Having 2.10 years of Professional experience in SQL Server 2014/2017.\n",
      "Having experience in creating database objects such as Stored Procedures, Functions, Views,Indexes,Joins to facilitate efficient data Manipulation and Data Consistency.\n",
      "Having good experience in writing complex queries using Derived Table, Sub-Queries, Set Operators and Joins.\n",
      "Having Proficient Experience on Temporary Objects in SQL like CTE,Temporary Table, Table Variable.\n",
      " I have very good experience with SQL Profile by Debugging the Query.\n",
      "Experience in Creating and Updating Clustered and Non-Clustered Indexes to keep up the SQL Server Performance.\n",
      "\n",
      "Professional Experience:\n",
      "\n",
      "Currently working as Software Developer at Square Bridge Technologies PVT LTD, Bangalore since SEP 2018 to till date.\n",
      "Academic Profile: \n",
      " B.Tech in Electronics and communication engineering(ECE) From JNTU Hyderabad.\n",
      " Intermediate in M.P.C from  Narayana Junior College, Hyderabad\n",
      " SSC from   Secondary School Education,  Vardhana school,  Hyderabad\n",
      "Technical Skills:\n",
      "       Microsoft Technologies              :  SQL Server 2014/2012/2017.\n",
      "       Languages\t\t    \t             :  MySQL\n",
      "       Operating Systems\t   \t   :  Windows 2008 Server, Windows XP/   Windows 7.\n",
      "\n",
      "\n",
      "Projects\n",
      "\n",
      "Project#2\t: Healthcare Management\n",
      "Client\t               : Aetna\n",
      "Duration\t: Feb-2020 to Till Date\n",
      "Role\t\t: Sql Developer\n",
      "\n",
      "Description: Aetna is an American managed health care company that sells traditional and consumer directed health care  insurance plans and related services, such as medical, pharmaceutical, dental, behavioral health, long-term care, and disability plans, primarily through employer-paid (fully or partly) insurance and benefit programs, and through Medicare .\n",
      "Responsibilities:\n",
      "Developed physical data models and created DDL scripts to create database schema and database objects\n",
      "Wrote user requirement documents based on functional specification.\n",
      "Created new tables, written stored procedures, triggers for Application Developers and some user defined functions. Created SQL scripts for tuning and scheduling.\n",
      "Developed source to target specifications for Data Transformation Services.\n",
      "Developed functions, views and triggers for automation\n",
      "Extensively used Joins and sub-Queries to simplify complex queries involving multiple tables and also optimized the procedures and triggers to be used in production.\n",
      "Provided disaster recovery procedures and policies for backup and recovery of Databases.\n",
      "Performance Tuning in SQL Server using SQL Profiler and Data Loading.\n",
      "Project#1\t: Workers Compensation management:\n",
      "Client\t               : Stone wood Insurance\n",
      "Duration\t: Sep-2018 to Feb-2020\n",
      "Role\t\t: Software Developer\n",
      "\n",
      "Description: Worker’s compensation is a form of insurance providing wage replacement and medical benefits to employees injured in the course of employment in exchange for mandatory relinquishment of the employee's right to sue their employer for the tort of negligence. The trade-off between assured, limited coverage and lack of recourse outside the worker compensation system is known as \"the compensation bargain\". One of the problems that the compensation bargain solved is the problem of employers becoming insolvent as a result of high damage awards.\n",
      "\n",
      "Responsibilities:\n",
      "Involved in Design, Development and testing of the system\n",
      "Developed SQL Server Stored Procedures, Tuned SQL Queries (using Indexes and Execution Plan)\n",
      "Developed User Defined Functions and created Views\n",
      "Created Triggers to maintain the Referential Integrity.\n",
      "Reviewed existing business procedures and recommended and implemented changes.\n",
      "Responsible for setting preferences for various ad-hoc requests and distribution of tasks.\n",
      "Declaration\n",
      "\tI hereby declare that the information that is provided above is up to date and true. I would be more than happy to provide any additional information, if required.\n",
      "\n",
      "Date:\t\n",
      "Place: Hyderabad\t\t\t\t\t\t\t                  Pavana Kumari\n",
      "\n",
      "\n",
      "Processing text:\n",
      "                                    resume\n",
      "\n",
      "\n",
      "Ramalakshmi K\t\t\t\t  \n",
      " \n",
      "\n",
      "Career Objective :\n",
      "    Professional objective is to pursue a career as Software Developer in the IT Industry and a position that utilizes my education and experience in the field of Information Technology, so that I can contribute to the organization and further enhances my professional skills.\n",
      "\n",
      "Experience Summary:\n",
      "\n",
      "2.5 year of working experience in Microsoft SQLServer /Microsoft BI, AWS-Redshift.\n",
      " Motivated and result-driven BI Developer with a proven track record in Business Intelligence (BI), Data Warehouse (DWH) and Data Analytics related projects. Proven ability to identify business needs and develop valuable solutions to drive accuracy and process efficiency. \n",
      "Have exposure to work in tools such as SQL Server Management Studio, Microsoft Visual Studio, Business Intelligence Development Studio, SQL Server Profiler, SSIS.\n",
      "Wrote scripts and indexing strategy for a migration to Confidential Redshift from SQL Server and MySQL databases.\n",
      "Hands-on experience to creating a packages in SSIS and used different kind of data flow transformations, control flow tasks and maintained.\n",
      "Writing complex SQL queries, joins, importing & exporting the data from one database to another database and through files to databases.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Technical Skills:\n",
      "\n",
      "Languages/Technologies - Python,SQL\n",
      "Libraries - Numpy,Pandas,Matplotlib\n",
      "RDBMS - SQL Server,Mysql,Teradata\n",
      "ETL Tool - SSIS\n",
      "Cloud Platform - AWS Redshift\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Educational Qualifications:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project Details:\n",
      " \n",
      " \n",
      "Employer : Bixware Technologies \n",
      "Project Title : ETL, Cube\n",
      "Client  : More \n",
      "Project Role : Software Developer\n",
      "Period : Jan 2019 - Till date \n",
      "\n",
      " \n",
      "Project Description : \n",
      "\n",
      "More Retail Limited is a retail store brand which was earlier known as Aditya Birla Retail Limited, when it was part of Aditya Birla Group. More Retail Limited (MRL) is the retail formley Aditya Birla Group, a $43 billion corporation. The company ventured into food and grocery retail sectors in 2007 and subsequently expanded its presence across t he country under the brand more with two formats - Supermarkets and Hypermarkets. There are currently 750 Supermarkets and 30 Hypermarkets and Brands aimed to offer a shopping experience that delivers unbeatable value and quality. More is the fourth largest supermarket & Hypermaket chain in the country after Future Group.The company head office stores and maintains all the supermarkets & Hypermarkets stores data into the largest data warehouse and then processing and  provides those data through data marts.Sales Cube is to provide a sales summary to the users efficiently. Inventory Cube is to provide a data of “Inventory on Hand “and “Low Stock” to the users through Office Data Connection (ODC).\n",
      "\n",
      "\n",
      "Role and Responsibilities :\n",
      "\n",
      " • Implementing and Managing ETL solutions and automating operational processes.\n",
      " • Was responsible for ETL and data validation using SQL Server Integration Services\n",
      " • Developing and monitoring the jobs as per daily basis.\n",
      " • Analyzing the daily reports sales data and inventory.\n",
      " • working on Databases for updation of Business required data.\n",
      " • Querying, creating stored procedures and writing T-SQL join to address various reporting operations and also random data requests.\n",
      " • Involved detailed plan describing how to develop, maintain, Deploy, replace and alter or enhance  sales and inventory cube. \n",
      " • Defined and deployed monitoring, metrics, and logging systems on AWS.\n",
      " • Designed and Developed ETL jobs to extract data and load it in data mart in Redshift.\n",
      "\n",
      "\n",
      "\n",
      "Personal Information:\n",
      "\n",
      "Father’s Name\t\t: \tK Narasimha Rao\n",
      "Date of Birth\t\t\t:\t12-May-1996\n",
      "Gender\t            \t:\tFemale\n",
      "Languages Known\t\t:\tTelugu,Hindi,English\n",
      "Permanent address               :           Tipparajuvari Street,VRC center,\n",
      "                                                            Nellore,AP.\n",
      "                                                             \n",
      "Declaration:\n",
      "\n",
      "I hereby declare that all information mentioned above are true and correct to best of my knowledge and belief.\n",
      "\n",
      "\n",
      "\n",
      "Place: Mumbai\t\t\t\t\t\t\t\n",
      "Ramalakshmi K\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Name: Ramesh\n",
      "\n",
      "Career Objective: \n",
      "                To contribute an organization that provides an opportunity to showcase my technical skills and helps me to gain knowledge in domain and technology.\n",
      "Professional Summary:\n",
      "3.5 Years of experience in system Design, Development and Support of Microsoft SQL server 2008, 8R2 and 2012.\n",
      "Extensive experience on Joins, Set Operators, Temporary Tables, Table Variables, CTE/Derived Tables, sub-Queries.\n",
      "Extensive experience on constructing Tables, Views, Indexes, Synonyms, Functions, Cursors and Stored Procedures.\n",
      "Experience on ETL (Data Extraction Transforming and Loading) in BIDS (Business intelligence development studio)/ SSDT (SQL Server Data Tools) using SSIS (SQL Server Integration Services), Bulk Insert, BCP (bulk copy program).\n",
      "Experience on Design and Development of SQL Server Integration Services (SSIS) packages and using various control flow tasks like Data Flow Task, for-each Loop Container, For Loop Container.\n",
      "Experience on different transformations like Data Conversion, Conditional Split, Merge, Merge Join, Union All, Derived Column, Multi-Cast, SCD, Fuzzy Lookup etc.\n",
      "Experience on providing Logging, Error Handling by using Event Handler, Checkpoints, and logging for SSIS Packages.\n",
      "Designed different types of Bulk Insert task, Execute SQL task, FTP task and Send mail tasks.\n",
      "Experience on Deploying the SSIS Packages\n",
      "Experience on all types of reports like Table, Matrix, Sub-Reports, Image etc.,\n",
      "Generated multiple reports using SSRS from SQL Server Database (OLTP) and included various reporting features such as Group-by, Drill-Down, Drill-Through, Cascading Reports, Parameterized Reports and Report builder.\n",
      "Experience on Created Linked Reports, cache Reports.\n",
      "Deployed and processed SSIS packages and SSRS reports weekly to update information (as per business logic) by using SQL server agent and windows scheduler.\n",
      "Knowledge on SQL profiler, performance tuning, Query tuning and new features of advanced versions in SQL server.\n",
      "Excellent Report creation skills using Microsoft Reporting Services (SSRS) 2008/2012.\n",
      "Willing to learn new things and hard working.\n",
      "Excellent communication, ability to deal with different people, interpersonal and analytical skills, and a highly motivated team player with the ability to work independently.\n",
      "\n",
      "\n",
      "Education:  Master of Computer Applications (2018)\n",
      "\n",
      "Technical Skills:\n",
      "Operating Systems\t:   Windows, Unix \n",
      "Database Tools             :  SQL server Management   Studio (SSMS)\n",
      "Languages\t\t:  SQL and T-SQL\n",
      "ETL Tools\t\t:  SQL Server Integration Services (SSIS)\n",
      "Reporting Tools           :  SQL Server Reporting Services (SSRS)\n",
      "Databases\t\t:   MS SQL Server\n",
      "\n",
      "Professional Experience:\n",
      "\n",
      "Currently working as SQL Developer for Tietoevryindia In Bangalore from Feb 2018 To Till Date\n",
      "\n",
      "\n",
      "Project Details:\n",
      "Project# 2\t\n",
      "Title                     :    T-Mobile\n",
      " Client\t                :    T-Mobile\n",
      "Duration            :    April-2020 to till date (1 year 2 months)\n",
      "Skills Used        :     SQL ,SSIS,SSRS\n",
      "Role Played\t :   SQL Server& MSBI Developer \n",
      "\n",
      "\n",
      "Abstract:\t\n",
      "\tIt is an E-commerce web application, consists of two main modules admin module and User module. Inside user module it has multiple components like cart, orders, payment etc. and in Admin module have a component like category, sub-category, products and etc.\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Excellent report creation skills using Microsoft SQL Server Reporting Services (SSRS).\n",
      "Created SQL Server Reports based on the requirements by.\n",
      "Developed reports and deployed them on server using SQL Server Reporting Services (SSRS).\n",
      "Developed Complex Stored Procedures, Views and Temporary Tables as per the requirement.\n",
      "Wrote complex SQL queries using joins, sub queries and correlated sub queries to retrieve data from different SQL Server Databases and Excel files, apply business logic, load in table and create view for end users.\n",
      "Created DDL scripts to create database schema and database objects like tables, stored procedures, views, functions, and triggers using T- SQL.\n",
      "Create the clustered/non-clustered indexes on tables; Trace out for any table required any indexes and determine the type of index on it.\n",
      "Created complex reports which involve more number of groupings and multi-value parameters\n",
      "Developed reports like Claim Statements, Fee Bills Transactions, and some end request user reports on periodic basis.\n",
      "Provided technical guidance and support to end-users by developing documentations required.\n",
      "Experience in creating complex SSIS packages using proper control and data flow elements.\n",
      "Worked extensively on SSIS Package designs for Import/Export from various Data Source Flat file, Excel to MS SQL Server and vice versa and schedule the jobs.\n",
      "\n",
      "Used various Transformations such as Slowly Changing Dimension, Multicast, Merge Join, Lookup, Fuzzy Lookup, Conditional Split, Aggregate, Derived Column, and Data Conversion Transformations.\n",
      "Generated matrix reports, drill down, drill through, sub reports, multi parameterized reports in SSRS\n",
      "Rendering the reports to PDF formats as per the requirement and printing all the reports in a batch process for Monthly Statements. Scheduling the SSIS packages and Jobs.\n",
      "\n",
      "\n",
      "\n",
      "Project #1\t\t\n",
      "\n",
      "       Title                 :   Sales Flash                               \n",
      "       Client\t    :   British Gas\n",
      "       Duration        :   May-2018 to feb-2020(1 year 10 months)\n",
      "       Skills Used    :   MS-SQL SERVER \n",
      "       Role played  :   Associate Software Engineer\n",
      "Abstract:\t\n",
      "\t\tBritish Gas is an energy and home services provider in the United Kingdom. It is the trading name of British Gas Services Limited and British Gas New Heating Limited, both subsidiaries of Centrica. Serving around 12 million homes in the UK, British Gas is the biggest UK energy supplier and is considered one of the Six which dominate the gas and electricity market in the United Kingdom\n",
      "Responsibilities:\n",
      "Determined the SQL Server Installation. Installed SQL Server Management tools using SQL Server Setup Program and Tested the Installation of SQL Server.\n",
      "Create database objects such as tables, views, stored procedures, Triggers etc.\n",
      "Implemented Triggers for checking complex business conditions, providing security for the tables.\n",
      "Created check constraints to maintain data integrity.\n",
      "Created stored procedures and functions to support efficient data storage and manipulation.\n",
      "Planned complete Back-up of Database and Restored the Database from Disaster Recovery.\n",
      "Create the clustered/non-clustered indexes on tables; Trace out for any table required any indexes and determine the type of index on it.\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\t         Current Location \t:\tHyderabad.ish.ent requirement.related sub queries to retrieve data from the database.tead of going there and fixing an appointment. In Doctor’s side they can view their appointments and prescribe medicine for their patients-Knowledge in health care system maintains patient’s prescriptions so that their medical details are always available in internet, which will be more convenient for the patients. This will be more comfortable for the patient. Patient details and prescriptions are maintained confidentially. There are four modules in E-knowledge in Health care system they are Patient module, Doctor module, Administrator module, General  user module\n",
      "\n",
      "Processing text:\n",
      "B. vinod kumar\n",
      "\n",
      "OBJECTIVE:\n",
      "Willing to work under a challenging and professional environment with exposure to new technologies as an SQL and MSBI developer in the area of SQL SERVER 2014, 2016 with Enterprise Portal and where there is a scope for Organizational growth as well as individual growth.\n",
      "Professional summary:\n",
      "Having around 2.2Years of IT Experience in Microsoft Business Intelligence (MSBI) under SQL server environment, with through knowledge of SQL server 2014,2016 databases.\n",
      "Extensive experience on Joins, Set Operators, Table Variables, Temporary Tables, CTE & Sub Queries.\n",
      "Good experience in writing Simple and sample SQL queries.\n",
      "Experience in Developing Stored Procedures and User defined functions.\n",
      "Hands on Experience Triggers , views, cursor and synonyms.\n",
      "Experience on Writing SQL using joins, sub queries.\n",
      "Good at generating multiple reports using SSRS from SQL server database and included various reporting features such as Drill-Down, Drill-Through, Cascading Reports and Sub Reports.\n",
      "Experience in importing/exporting data between different sources like Excel/Flatfile etc.\n",
      "Good experience on Backups & Restoring into different Servers.\n",
      "Hands on Exeperience on different transformations like Data conversion, Derived coloumn, Look up, Merge join, Union All, Sort, Fuzzy lookup.\n",
      "Good Experience on Ranking, Aggregate and String Functions.\n",
      "Experience on Design and development of SQL Server Integration Services(SSIS) packages and using various control flow tasks like Data floe task and Excute SQL task and containres like For Loop container and sequence container and For -each container.\n",
      "Experience on deploying the reports and creating subscriptions to send the reports on schedule basis.\n",
      "\n",
      "EDUCATIONAL BACKGROUND:\n",
      "B.Tech (computer science and engineering),JNTU,Ananthapuramu.\n",
      "\n",
      "PROFESSIONAL EXPERIENCE:\n",
      "Working in united health group as a Software Engineer, Bangalore since may-2019 to till date.\n",
      "\n",
      "\n",
      "TECHNICAL SKILLS:\n",
      "Technologies\t: Microsoft Business Intelligence Tools (MSBI)\n",
      "Languages\t: SQL, T-SQL.\n",
      "ETL Tools\t: SQL Server Integration Services.\n",
      "Reporting Tools\t: SQL Server Reporting Services\n",
      "\n",
      "PROJECT DETAILS:\n",
      "Client: Uk\n",
      "Project: National skill Development corporation\n",
      "Role: SQL Server and SSIS developer\n",
      "Envirnoment : SSIS, SSRS and MS SQL Server.\n",
      "Project 1: National Skill Development Corporation (NSDC)\n",
      "Client\t: National Skill Development Corporation (INDIA) Role\t: SQL Developer\n",
      "Environment\t: SQL Server, Nano-BI. Duration\t: May 2019 to till now.\n",
      "\n",
      "Description:\n",
      "NSDC Provides training / placements to people across the country through SIP across specific skill sets. Under NSDC there are multiple scheme types like PMKVY, Non-PMKVY and Fee-Based, Based on scheme type candidates will enroll to the batches under particular training centres. In every batch minimum 10 candidates can enroll. After enrolling candidates will go for Training then these candidates will go for assessment and Failed candidates can apply for re-assessment and the candidates who are passed will go for the certification. And the certified candidates will get placement through NSDC.\n",
      "\n",
      "ROLES AND RESPONSIBILITIES:\n",
      "By using NANO BI Analytical tool creating tables.\n",
      "Developed ETL Scripts to populate the data from different tables by using joins, CTE’s and Date functions.\n",
      "By using NANO BI Analytical tool creating tables.\n",
      "Involved in Creating analytics with measures and dimensions to populate data and created dashboard to clients by their requirement.\n",
      "Responsible for Creating and Modifying T-SQL stored procedures for validating the integrity of the data.\n",
      "Responsible for writing complex SQL Queries, Joins, Constraints, DDL, DML Date Functions to implement the business logic.\n",
      "\n",
      "Experience in creating different types of Reports according to the user request by using NANO BI Analytical tool.\n",
      "Involved in deploying and scheduling the reports using Report Emailer.\n",
      "Involved in scheduling the Stored procedures to refresh the data on every day using Workflows in NANO BI.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "B. Vinod kumar\n",
      "\n",
      "Processing text:\n",
      "Chinna Subbarayudu M\n",
      "DOB: 06th March 1994\n",
      "Nationality: Indian\n",
      "\t\n",
      "PROFILE SUMMARY:\n",
      "\n",
      "Having around 5.1 years of IT experience in developing and Implementation of ERP technology by using Workday HCM and ETL (informatica) technologies.\n",
      "3.6 years of experience as Workday Integration Consultant and involved in a maintenance and implementation.\n",
      "Experience in all phases in Workday like requirements gathering, Analysis, Design, Development and Testing.\n",
      "Hands on experience in inbound/ outbound integrations using core connector, Workday studio, managing business processes, working with EIB, report writer.\n",
      "Developed and maintained custom-report types (Advanced, Matrix, Composite) using report writer tool.\n",
      "Involved in transformation of XML into XSLT for presenting data for different web Services.\n",
      "Building Workday Integration (EIB), calculated fields, Custom Reports and Writing XSLT transformation code.\n",
      "Developed testing strategies and validation scenarios along with project Scope and Requirement documents\n",
      "Prioritizing, reproducing and verifying bug fixes in different Workday integrations.\n",
      "Having knowledge in XML, WD-SOAP Web Service, and WD- REST Web Service and experienced in using tools such as Soap, XML Exchanger\n",
      "Involved in writing transformation code for converting XML into XSLT\n",
      "for different web services.\n",
      "Performed validation testing and end to end testing and also involved in integration testing\n",
      "Having good experiences in testing, we perform UAT and end to end validation testing\n",
      "Knowledge in Software Development Life Cycle process (Analysis, Design, Development, Testing) for Implementation and Support in different application domain.\n",
      "Experience of working in Production support model.\n",
      "Excellent client interaction skills and proven experience in working independently as well as in a team.\n",
      "\n",
      "TECHNICAL SKILLS:\n",
      "\n",
      "\n",
      "Education Details:\n",
      "Bsc(Computers) from Yogi Vemana University,Kadapa.\n",
      "Work Experience:\n",
      "Working as a Workday Technical Consultant for Progile Infotech pvt ltd  from June - 2016 to till date.        \n",
      "Projects under taken:\n",
      "\n",
      "\n",
      "Client: South West Airlines                                                                                   June2019- Present\n",
      "Role: Workday Technical  Consultant\n",
      "\n",
      "Responsibilities:\n",
      "Integrations in Workday using different tools like CCW, EIB, DT, Custom Report and Workday Studio, Responsible for developing Integrations and testing them.\n",
      "Responsible for supporting the new change requests and enhancements in the project\n",
      "Created calculated fields and Worked on Simple and Advanced Reports.\n",
      "Worked on Integration Systems (EIBs, Core Connectors).\n",
      "Day to day support of Workday Integrations, Security, and Reporting issues.\n",
      "Had knowledge on hire, terminate, data changes etc. of employees\n",
      "Expertise in developing Payroll interfaces using PICOF, PECI with the help of Workday Studio and Document Transformation to meet client’s complex payroll requirements.\n",
      "Design of web services to send/receive data between Workday and Third party system.\n",
      "Developed analytics dashboards utilizing multiple data sources to provide actionable reporting and embedded analytics.\n",
      "Experienced in analyzing and preparing Project Deliverables such as Technical Design Document (TDD) and Functional Design Document (FDD).\n",
      "Created test scripts and coordinated the testing effort with all the stakeholders for System and UAT. \n",
      "\n",
      "\n",
      "Client:  Arbella Insurance Group\t\t\t\t                                Dec2017– May2019\n",
      "Role:  Workday Integration Consultant\n",
      "\n",
      "Responsibilities:\n",
      "Analyzed client’s HCM/Payroll business needs through client working sessions and supported development of new business processes and a future state design.\n",
      "Worked as an Integration Developer for Analysis, design, development, testing and implementation of Workday HCM solutions for Global Implementation in GE. \n",
      "Performance Tuning in Population (2 lakh employees) and Complexity Perspective.\n",
      "Created Multiple CCW Integrations for Demographical data with DT, EIBs with reports\n",
      "Supported on both Inbound and Outbound Studio Integrations, Created security groups, users and configured required security policies in Domain and BP level..\n",
      "Utilize in-depth knowledge of functional and Technical experience in Workday and other leading-edge products and technology in conjunction with industry and business skills to deliver solutions to customer.\n",
      "Built Integrations in Workday using different tools like CCW, EIB, and Reports. Identifying Testing strategy getting sign-off on all project deliverables.\n",
      "Collaborate with the ST (System Testing) and UAT (User Acceptance Testing) teams to test the integration builds. Fix issues encountered in ST and UAT phase.\n",
      "Developed Several Complex Integrations using Workday Studio and EIB.\n",
      "Day to day support of Workday HCM, Security, Payroll, Benefits, Compensation and Reporting issues\n",
      "Involved in the design phase and prototyping for further discussions with the client.\n",
      "Created and used calculated fields in reporting, business processes, integrations and other areas within Workday.\n",
      "\n",
      "Client:  News Technologies  \t\t\t          \t\t\t     June 2016 –Nov 2017\n",
      "Role:  Peoplesoft Consultant          \n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Involved in design and customization of tables and panels and adding new option using People Tools.\n",
      "Responsible for Test Plan, Defect Report Status, and Knowledge Transfer Documents.\n",
      "Uploading the test scripts from MS Excel to Test Director.\n",
      "Developed and executed the SQL queries to fetch the data from PeopleSoft HRMS (Oracle).\n",
      "The fetched data has to be analyzed against the bridge database and it should be reported if there is any deviation.\n",
      "Integrated third party hiring application with PeopleSoft System using Component Interface program and loaded data into PS tables.\n",
      "Unit tested the developed application and created test scripts and test cases for the Unit Testing and System Testing\n",
      "Declaration:\n",
      "                  I hereby declare that the information provided above is true to the best of my knowledge.\n",
      "\n",
      "\n",
      "Date : \t\t\t\t\t\t\t\t\tName: M Chinna Subbarayudus\n",
      "\n",
      "\n",
      "Processing text:\n",
      "\t\n",
      "\n",
      "\n",
      "Name         : Gopi Krishna Reddy\n",
      "\t\t                       \n",
      "\n",
      "PROFESSIONAL SUMMERY:\n",
      "Working as a Workday Consultant with 3+ years as Workday Consultant and good experience on Report Writing, Integration of HCM. \n",
      "\n",
      "Knowledge of the software development life cycle from design through scoping, requirements gathering, analysis, development, testing, user acceptance, deployment, maintenance/support and change management. \n",
      "Good working knowledge on Inbound and Outbound EIB Integration concepts and created various EIB Integrations.\n",
      "Building Core Connector integrations for extracting worker, position, status, leave and absence delta changes.\n",
      "Designed and built all types of integrations using Document Transformation, EIB, PICOF, Cloud Connectors and Custom Report Writer. \n",
      "Having  good knowledge on Workday Studio \n",
      "Experience with XML, XPATH and XSLT and Expert in designing/development of Interfaces with legacy and third party systems. \n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenant to Sandbox and Production using Object Transporter.\n",
      "Experienced in developing Custom Reports, Advanced Reports using Report Writer.\n",
      "Strong experience using technologies involving Workday applications, reporting and analytics. \n",
      "Good experience on create Report Groups and Workbooks to create Excel worksheet groups and create Dashboards.\n",
      "Strong Knowledge on working with CR-Change Requests as per business requirement and Building and moving changes to production.\n",
      "Worked closely with Business and Development Teams for Designed and Documented Enhancements as well as conducted Production Support Troubleshooting around Integrations for Global Workday HCM System.\n",
      "Excellent Interpersonal, Presentation and Communication Skills with the ability to work in a team and a Stand-alone Environment. \n",
      "EDUCATIONAL DETAILS:\n",
      "\n",
      "Completed Bachelor of Degree from JNTU - K University in 2014.\n",
      "\n",
      "TECHNICAL SKILLS:           \n",
      "\n",
      "\n",
      "PROJECT DETAILS:           \n",
      "Company: Tyson Foods, Bangalore                 (May 2018 to Present)\n",
      "Project: Workday Support and Enhancement\t\t\t\t\t\t\t\n",
      "Role: Workday Technical Consultant\n",
      "\n",
      "Responsibilities:\n",
      "Involved in Workday HCM for various HR modules such as Benefits, Compensation, Time Tracking and Absence Management.\n",
      "Worked on Calculated Fields to create Report level and Global level.\n",
      "Monitor daily Schedulers and Report Errors as needed.\n",
      "Design and Build Integrations and worked closely with testing and production teams to solve issues with integrations.\n",
      "Created Custom Reports like Simple, Advanced Reports as per the client requirements and shared with the security groups.\n",
      "Created Reports against the Worker business object and worked on Headcount, Turnover and Compensation Reports.\n",
      "Good experience with Core Connector Worker to work on Employee Demographics and build Benefit Integrations and Account Provisioning Integrations.\n",
      "Created Inbound/Outbound integrations using Workday Studio, Core/Cloud Connectors, EIB’s and Document Transformation Process.\n",
      "Involved in Unit Test on Integrations, UAT support and end user training.\n",
      "Design, build or maintain integrations of all types: Reports, EIB, Core Connectors, Payroll Connectors or Studio.\n",
      "Write / Modify Technical Design/ Specifications as needed\n",
      "Participate in Integration Testing and Peer Testing.\n",
      "Work independently or with minimal supervision with various Stakeholders including the Functional Consultants.\n",
      "Monitor and update ticketing tool on daily basis. Manage work activities and ticket volumes to meet required SLA’s and service delivery measures.\n",
      "Developed Core Connector and Document Transformation integrations to get changes file of CSV format from XML Output.\n",
      "\n",
      "\n",
      "Used sequence generators, generating templates and validating inbound integration system results.\n",
      "Day to day support for Workday HCM, Integrations and Reporting issues.\n",
      "\n",
      "Technical Environment: Workday 30/31/32, Workday Studio, Workday EIB, Workday BIRT, Core Concepts, Document Transformation, Calculated Fields, Oxygen Editor, Workday Report Writer, XML, XSLT.\n",
      "\n",
      "\n",
      "PERSONAL INFORMATION\n",
      "\n",
      "Full Name\t\t\t: \tGopi Krishna Reddy \n",
      "Gender\t\t\t               : \tMale \n",
      "D.O.B\t\t  \t               : \t19-04-1993 \n",
      "Marital Status\t                             : \tMarried\t \n",
      "Nationality\t\t\t: \tIndian \n",
      "Languages Known\t\t: \t English, Telugu and Kannada.\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Environment:PeopleSoft HCM 9.1, People Tools 8.51, Oracle 11iloyee Self Service applicationspplying business expertise and best business practices.ration with PeopleSoftterface Builder (EIB).ed of 364,445 employees worldwide and, as of September 2018, was the sixth-largest company in the world by revenue. As of 2017, Toyota is the world's second-largest automotive manufacturer. Toyota was the world's first automobile manufacturer to produce more than 10 million vehicles per year which it has done since 2012, when it also reported the production of its 200-millionth vehicle. As of July 2014, Toyota was the largest listed company in Japan by revenue.\n",
      "\n",
      "Processing text:\n",
      "                 N T U A),Nandyala.ineering From AVR&SVR College of Engineering&Techologypplication Designer, people code, Application Engine. 2016 to September 2017ing governance model. requirements and regular maintenance (some routine data entry).nt Interface, File Layout.\n",
      "\n",
      "Processing text:\n",
      "Operations - \u000b",
      "  1. Joining formalities.\u000b",
      "  2. Handling Employee Database (Both in Soft Form and Files Management)\u000b",
      "  3. Leaves and Attendance Management\u000b",
      "  4. Confirmations, Performance Appraisals, Performance Management\u000b",
      "  5. Exit-Interviews\u000b",
      "\u000b",
      "\u000b",
      "Employee Relations - \u000b",
      "  1. Handling all the queries of the employees. Be it related to Salary, Leaves, Attendance, and Transfer etc.\u000b",
      "  2. They are also expected to explain the various policies, strategies and benefits to employees.\u000b",
      "  3. They are expected to stop all type of rumours and misleading communications.\u000b",
      "  4. They should motivate the employees on day-to-day basis.\n",
      "\n",
      "Processing text:\n",
      "                                      \n",
      "                                                   G Himaja\n",
      "                                                                                                            \n",
      "\n",
      "\n",
      "Career Objective\n",
      "\n",
      "To work towards achieving the greater success in my career through hard work, consistency and the ability to work with others to achieve organizational goals, aims and objectives.   \n",
      "    \n",
      "Professional Summary\n",
      "\n",
      "Having around 3 Years of IT ERP experience which include 2+ years as workday Integration Consultant and Remaining as HR.\n",
      "\n",
      "Good Involvement in Workday Projects full life cycle, Development / deployment, upgrades, Integrations etc.\n",
      "\n",
      "Good knowledge in the Functional Workday includes HCM, Compensation, Payroll interface, Business Process configurations, etc.\n",
      "\n",
      "Extensively worked on calculated fields used in developing various custom reports.\n",
      "\n",
      "Strong Knowledge on Involved in CR-Change Request as for business requirement and Building and moving changes to production.\n",
      "\n",
      "Good Exposure in Integrations- Inbound and Outbound, Payroll interface implementations.\n",
      "\n",
      "Good Experience in Workday Integration Tools - Connectors, PICOF/PECI, RAAS, EIB, API, Reporting, Document Transformation, STUDIO, XSLT, HTML, Data Load etc., and Third party Integrations for client for various vendors like ADP etc.\n",
      "\n",
      "Worked on Functional Data Inbound data loads via EIB for (Applicant, Dependent, Compensation Data Loads).\n",
      "\n",
      "Good Experience in Outbound integrations using EIB and Document Transformation for sending Demographic data to end vendors.\n",
      "\n",
      "Experience on getting requirement from the client and sharing the work across team.\n",
      "\n",
      "Good Experience in BIRT to generate Bonus Letters using workday Studio. \n",
      "\n",
      "Good Experience in Report designing using workday Studio. \n",
      "\n",
      "Strong Knowledge on Deploy reports in multiple environments (Dev-QA-Prod) Using solution.\n",
      "\n",
      "Proven communication and interpersonal skills.\n",
      "\n",
      "\n",
      "\n",
      "Technical- Skills:\n",
      "\n",
      "\n",
      "Experience Summary:\n",
      "\n",
      "Worked as Software Engineer in Thermo Fisher Scientific from June 2018 – Till date.\n",
      "Education:\n",
      "Completed Degree (BSc. computer science) from S V University, Tirupathi-2018.\n",
      "Project:\n",
      "        Project\t          :     Support &Implementation of workday HCM\n",
      "       Client                 :     Thermo fisher scientific\n",
      "       Role\t          :    Workday Integration Consultant\n",
      "Roles & Responsibilities\n",
      "\n",
      "Understanding the Business Requirements by studying the Functional Documents.\n",
      "Creation of Advanced Custom reports for End user for reporting on Demographic Information.. \n",
      "Hands-on experience in creating the calculated fields using different functions for complete logics. \n",
      "Created EIB Inbound Integrations for loading the employees personal Information like, Emergency contacts, Compensation, One time payments, Bank account information, cost center information.\n",
      "Created EIB outbound Integrations, written XSLT code and sending data from workday to downstream systems.\n",
      "Modified the XSLT code as per CR-request and adding the new XSLT code for Different info types.\n",
      "Created the new outbound integrations to sending the Payroll Information from workday to ADP payroll system.\n",
      "Created Workday Studio inbound studio programs to load compensation information from ADP to workday.\n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenant to Sandbox and Production using Object Transporter\n",
      "\n",
      "Supporting the Different teams in UAT phase as well as with test factory teams during integration testing phase.\n",
      "Involved in calls with client and update the work status as well as clarifications if any.\n",
      "\n",
      "\n",
      "Project    \n",
      "      Client                 :     Thermo fisher scientific\n",
      "       Role\t          :    HR-Executive\n",
      "Roles & Responsibilities\n",
      "\n",
      "• Handling end to end recruitment activities.\n",
      "•   Uploading the profiles on internal recruitment portal to check the duplicity of the profiles.\n",
      "•   Track of all the open requirements.\n",
      "•   Discussion with business about the job requirements/plan of hire.\n",
      "•   Decision on mode and channel of hire based on the requirements.\n",
      "•   Sourcing the profiles through social network, employee references, references from the   \n",
      "  Candidates, Vendors, etc \n",
      "•   Sourcing the profiles through vendors for contract hiring requirements.\n",
      "•   Initial screening and shortlist the profiles for the interview process.\n",
      "•   Interview schedule for the shortlisted candidates.\n",
      "•   Arrangement of logistics for the interviews.\n",
      "•   Arrangement of panels for the Non-technical and managerial interviews.\n",
      "•   Interview coordination.\n",
      "•   Discussion with project team/business unit about the requirements and initiate sourcing as \n",
      "  per the requirement.\n",
      "•   Preparing the report and submitted to Business.\n",
      "\n",
      "Personal Information\n",
      "\n",
      "\n",
      "Declaration:      \n",
      "                   \n",
      "I hereby declare that the information furnished above is true to the best of my Knowledge. \n",
      "                                                                          \n",
      "                                                                                                                                      Yours Faithfully\n",
      "                                                                                                                       G Himaja                                                                                                                                 \n",
      "\n",
      "Processing text:\n",
      "Monitoring and tuning performance.e's health and taking preventive or corrective action as required.York City and head quartered in Boston. As of 2018, the company operates through the following segments: aviation, healthcare, power, renewable energy, digital industry, additive manufacturing and venture capital and finance. Installing Oracle software.ssful product development, launch, tech transfer and reliable global supply.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "JYOTI VERMA\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "3 years of Experience in Workday as Functional HCM Consultant.\n",
      "Good exposure in working on business improvements and process activities.\n",
      "Exceptional ability in understanding the business needs and improving the process.\n",
      "Excellent communication skills and proven experience in working independently as well as in a team.\n",
      "Involved in preparing business requirement documents and analysis of client functional requirements.\n",
      "Extensive knowledge on Complete Tenant configurations – (Supervisory Organizations, Roles, Business Processes)\n",
      "Experience in performing HCM tasks like defining Job Profiles, position creations, employee hiring, transfers, promotions, demotions and terminations etc., as part of Workday Testing requirements.\n",
      "Configuration of Supervisory Organizations, Business Process.\n",
      "Experience working on Workday HCM Global roll out and Support projects\n",
      "Proficient in analyzing and translating business requirements to technical requirements and architectures.\n",
      "Day to day support of Workday HCM, reporting issues and implementing enhancements when needed.\n",
      "Created Custom Reports and scheduled reports as requested by end-users.\n",
      "Exposure on modifying/troubleshooting/enhancing existing custom reports using Calculated Fields.\n",
      "Created and used calculated fields in reporting, business processes, and integrations within Workday.\n",
      "Understanding and careful analysis of the Internal HR team requirements.\n",
      "Exposure on object management skills in Workday like configuring Supervisory/Matrix Organizations (Divide organizations, Inactivate Organizations, create subordinates).\n",
      "Experience in creating Job Profiles, Job Families and Job Family Groups, also worked with the creation and maintenance of position and job staffing models.\n",
      "Experience in maintenance and creation of Workday Supervisory Organizations, Locations, Positions, Cost centers, Cost Center hierarchies\n",
      "Excellent interpersonal skills with a strong desire to achieve specified goals.\n",
      "Knowledge on Compensation (salary plans based on different grades, grade profiles and allowances).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Currently working as a Workday HCM Functional Consultant in Icroz Solutions Pvt Ltd, Hyderabad from September 2018 to till date.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project-1\t:\tSupport of Workday HCM\n",
      "Client\t:\tElectronic Arts\n",
      "Role\t:\tWorkday Consultant Duration\t:\tSept 2018 to Till Date\n",
      "\n",
      "\n",
      "Worked extensively on creating calculated fields and setting up validation rules to  accomplish the Client needs for BP Setup and Reporting needs.\n",
      "Involved in setting up Eligibility Criteria, Workflows and Security Groups to support Business Processes for Core HR.\n",
      "Exposure in developing Standard, Advanced, custom reports  and  thorough understanding  of Workday data sources and business objects.\n",
      "Day to day support of Workday HCM\n",
      "Created Supervisory Organizations, Cost Centers, Cost Center Hierarchies, and location hierarchies and modification of Workday Business Processes and definitions.\n",
      "Creating and maintaining Workday Custom reports like Simple, Advance Reports.\n",
      "Creating supervisory Organizations, creating sub ordinates, assign superior, Move workers, Creating Locations\n",
      "Knowledge on Workday Standard Reports and Custom Reports.\n",
      "Knowledge on Calculated Fields, System wide and Report Specific Fields.\n",
      "Knowledge on Staffing Models, Job profiles, Positions.\n",
      "Knowledge on security policies and security groups\n",
      "Knowledge on EIB integrations\n",
      "\n",
      "\n",
      " Declaration:\t\n",
      "\n",
      "I hereby declare that the information furnished above is true to the best of my Knowledge.\n",
      "\n",
      "     Yours faithfully\n",
      "JYOTI VERMA\n",
      "\n",
      "Processing text:\n",
      "Date:                                                                                                                       Name: Madeeswar A in Informatica Designer.nd UAT. Navy, Intermix, Hill City, and Athleta. Gap Inc. is the largest specialty retailer in the United States.\n",
      "\n",
      "Processing text:\n",
      "\n",
      "\n",
      "Mooraboyina Guravaiah\n",
      "Workday Integration Specialist\t\t\t\t                            \n",
      "\t\n",
      "CARRIER OBJECTIVE: \n",
      "My intention at this step would be to learn new things related to my profession. As it is a    technical field, one has to be updated because the technology changes often. It is my         responsibility to learn and adopt the new technology. It would be profitable for me as well as for my company\n",
      "\n",
      "PROFESSIONAL SUMMARY\n",
      "\n",
      "Having 5+ years of experience in the field of IT, in which 3+ years of experience in providing Workday Technical Development in Workday Support and Enhancement Project.  \n",
      "\n",
      "Technically proficient in customizations, enhancements and Reports using various tools like Report writer, EIB, Core Connector and Studio.\n",
      "\n",
      "Good working knowledge on Inbound and Outbound EIB integration concepts and created various EIB integrations.\n",
      "\n",
      "Building Core Connector integrations for extracting worker, position, status, leave and absence delta changes.\n",
      "\n",
      "Designed and built all types of integrations using Document Transformation, EIB, PICOF, Cloud Connectors and Custom Report Writer. \n",
      "\n",
      "Experience with XML, XPATH and XSLT, and Expert in designing/development of Interfaces with legacy and third party systems. \n",
      "\n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenet to Sandbox and Production using Object Transporter.\n",
      "\n",
      "Experienced in developing Custom Reports, Advanced Reports using Report writer\n",
      "\n",
      "Strong experience using technologies involving Workday applications, reporting and analytics. \n",
      "\n",
      "Good experience on create Report Groups and Workbooks to create Excel worksheet groups. And creating Dashboards.\n",
      "\n",
      "Strong Knowledge on working with CR-Change Requests as per business requirement and Building and moving changes to production.\n",
      "\n",
      "Worked closely with business and development teams, designed and documented \n",
      "enhancements as well as conducted production support troubleshooting around integrations for Global Workday HCM system.\n",
      "\n",
      "Excellent interpersonal, presentation and communication skills with the ability to work in a team and a stand-alone environment. \n",
      "\n",
      "EDUCATION QUALIFICATION\n",
      "\n",
      "Completed B.Sc (Bachelor of Science) from Nagarjuna University - 2013 \n",
      "\n",
      "TECHNICAL SKILLS:   \n",
      "\n",
      "Technical Expertise\t              :  \tXML, XSLT, EIB, Core Connectors, \n",
      "Functional Expertise\t               :  \tCore HCM\n",
      "Reporting Tools\t\t:  \tReport Writer, Crystal Reports11, XMLP\n",
      "Technical Skills\t\t:  \tEIB, Core Connector, DT and Studio\n",
      "\n",
      "Work Experience \n",
      "\n",
      "Currently Working as Workday Consultant in Jade Global, Pune from May’2016 to Till Date \n",
      "Project Details \n",
      "\n",
      "Jade Global, PUNE     ( Apr’2018 to Till Date)\n",
      "Project:                Workday Support and Enhancement \n",
      "Designation:\t Workday Consultant \n",
      "RESPONSIBILITIES\n",
      "\n",
      "Involved in Workday HCM for various HR modules such as Benefits, Compensation, Time tracking and Absence Management.\n",
      "\n",
      "Working on Calculated Fields to create Report level and Global calculated Fields.\n",
      "\n",
      "Monitor daily schedulers and report errors as needed.\n",
      "\n",
      "Design and build integrations and worked closely with testing and production teams to solve issue with integrations.\n",
      "\n",
      "Created Custom reports like Simple, Advanced Reports as per the client requirements and shared with the security groups.\n",
      "\n",
      "Worked on Calculated Fields to create Report level and Global cal Fields.\n",
      "\n",
      "Good experience with Core Connector worker to work on employee demographics and build Benefit integrations and Account provisioning integrations.\n",
      "\n",
      "Created complex Inbound/Outbound integrations using workday studio, core/cloud connectors, using EIB’s, document transformation process.\n",
      "\n",
      "Involved in unit test on Integrations, UAT support and end user training.\n",
      "\n",
      "Design, build or maintain integrations of all types: reports, EIB, Core Connectors, payroll connectors, or Studio.\n",
      "\n",
      "Write / modify Technical Design/ Specifications as needed\n",
      "\n",
      "Participate in integration testing and peer testing.\n",
      "\n",
      "Work independently or with minimal supervision with various stakeholders including the functional consultants.\n",
      "\n",
      "Monitor and update ticketing tool on daily basis. Manage work activities and ticket volumes to meet required SLA’s and service delivery measures.\n",
      "\n",
      "Developed Core connector and Document Transformation integrations to get changes file of CSV format from XML Output.\n",
      "\n",
      "Used sequence generators, generating templates and validating inbound integration system results.\n",
      "\n",
      "Day to day support for Workday HCM, Integrations and Reporting issues.\n",
      "\n",
      "TECHNICAL ENVIRONMENT: Workday 30/31/32/33/34, Workday studio, workday EIB, Workday BIRT, Core concepts, Document transformation, Calculated fields, Oxygen Editor, Workday report writer, XML, XSLT.\n",
      "\n",
      "\n",
      "2.  Jade Global, Pune    (May’16 to Mar’2018)\n",
      "     Project                  :      PeopleSoft Support and Enhancement \n",
      "     Designation         :\tConsultant\n",
      "\n",
      "Have Customized and developed Application engines for loading bulk data from external systems.\n",
      "\n",
      "Track and resolve user support issues with current system Maintain good working relationships with project team members, internal customers (e.g. AP,PO,BI and GL), and external service vendors\n",
      "\n",
      "Have designed technical documents and have worked towards development of interfaces and conversions based on design documents.\n",
      "\n",
      "Modified, designed, configured and built fields, records, sub records, setting up keys to records, assign table edits like prompt table.\n",
      "\n",
      "Involved in online changes to the delivered pages, components, menus and translate values.\n",
      "\n",
      "Have Customized and developed Application engines for loading bulk data from external systems.\n",
      "\n",
      "Developed and modified People Code to implement specific business rules and validations to enable the System to perform the business process.\n",
      "\n",
      "Used File Layout Definition to get data from the legacy system to PeopleSoft tables.\n",
      "\n",
      "Managed and monitored process scheduler for any issues while scheduled interfaces/processes ran and resolved the issues\n",
      "\n",
      "Developed/Modified various PS queries in order to help the client day-to-day activity.\n",
      "\n",
      "Involved in creating PS Query’s and sending it through email to different country FSCM heads.\n",
      "\n",
      "Worked on the reporting tools like PS Query, XML Publisher\n",
      "\n",
      "Have worked on File Layout, Application Engine, Component Interface, File layout, Excel to CI, XML Report\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PERSANAL DETAILS:\n",
      "\n",
      "\tFather’s Name\t         : Danaiah M\n",
      "\tDate of Birth\t         : 15-02-1992\n",
      "                     Gender                                 : Male\n",
      "                     Nationality                          : Indian \n",
      "                       Marital Status                   : Married\n",
      "\n",
      "\n",
      "Declaration:  \n",
      "      I here by declare that all the information furnished is true to by best of my knowledge.\n",
      "\n",
      "Place :\n",
      "Date  :                                                       \n",
      "                       \t\t\t\t\t\t\t\t\t         (Guravaiah M)\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Have worked on File Layout, Application Engine, Component Interface, File layout, Excel to CI, XML Reportved the issues the business process..g. Hire, Absence and performance), and external service vendorse Interface Builder (EIB).\n",
      "\n",
      "Processing text:\n",
      "VENKATA SAIKRISHNA\n",
      " Workday Consultant\n",
      "\n",
      "\n",
      "PROFSSIONAL SUMMARY:\n",
      "\t\n",
      "Over all 3 years of IT experience as a Workday Consultant.\n",
      "Integral in maintenance and creation of Workday Supervisory Organizations, Business Process, Locations, Positions, Company, Cost centers, and Hierarchies.\n",
      "Experience in understanding the Client Business Requirements, Organizational Hierarchy Setup, Configurable Security Setup and Tenant Setup.\n",
      "Worked with different Staffing Models, defining Hire restrictions to Job Management, Position Management.\n",
      "Hands on experience with Compensation Module like creating Compensation Grades, Compensation Eligibility Rules, Allowance Plans, Salary Plans, Hourly Plans.\n",
      "Experience in creating Job Profiles, Job Families, and Job Family Group.\n",
      "Experience with Workday security groups like Role based security, User based Security, Intersection, and Job based Security.\n",
      "Experience with creating Staffing models for Supervisory Orgs, Reorganizations and business process framework, Organization Types, Organization Hierarchies.\n",
      "Strong Experience with Workday Report Writer - Custom Reporting (Calculated Fields, Advanced, Standard Reports).\n",
      "Hands on experience in inbound/ outbound integrations using EIB and core connectors.\n",
      "Troubleshooted day to day issues arising in Workday, reporting issues to identify and fix root causes.\n",
      "\n",
      "TECHNICAL SKILLS:\n",
      "\n",
      "\n",
      "PROFESSIONAL EXPERIENCE:\n",
      "\n",
      "Working as Workday Consultant in Value Momentum, from Aug-2018 to Till Date.\n",
      "Role: Workday Consultant\n",
      "Responsibilities:\n",
      "Created Supervisory Organizations, Cost Centers, Cost Centre Hierarchies, and location hierarchies’ maintenance, Staffing Models, Job details Positions and Job Requisitions.\n",
      "Setup end to end recruiting process for clients from creating business processes like job application, Offer, Hire, and Onboarding, setup external career site, questionnaires, offer letters and review documents. \n",
      "Staffing Movements, An employee changes in position, inbound process and outbound process.\n",
      "Termination Process, initiate termination process, review termination process, to do tasks\n",
      "Worked on the creation of benefit plans, job profiles, and job families.\n",
      "Configured Workday compensation packages including salary, bonus, allowance, commission, and compensation eligibility rules based on management levels, job profile, and job family.\n",
      "Managed job description and workflow of employee data for compensation module including job families, pay ranges and supervisor setup.\n",
      "Setup Merit plans including merit and bonus plan processing and created the business process for bonus plan, merit plan, salary plan and hourly plan.\n",
      "Worked on several calculated fields like look up related value, Evaluate Expression, True or false conditions, Arithmetic Calculation, formatting date fields etc... \n",
      "Performed arithmetic calculation in Matrix report for counting, averaging, summing, ranging between maximum and minimum. \n",
      "Worked with Simple and Advanced Reports, defining columns, business objects, fields.\n",
      "Setup security groups, domain security policies and business process security policies.\n",
      "Worked with Business Process and configurations various business process on Compensation, Talent Management, Recruiting, Benefits. \n",
      "Configuration of Workday’s business process framework configured conditional rules to guide workflow or validate data as required to accommodate desired outcomes.\n",
      "Developing the integrations using tool Enterprise Interface Builder (EIB), Core connector\n",
      "Designed and built both inbound and outbound EIB in various segments of Workday system.\n",
      "Environment: EIB, Web services, Workday Report Writing, custom Reports, calculated fields, compensation, MS PowerPoint, MS Excel, Windows.\n",
      "\n",
      "\n",
      "\n",
      "EDUCATION:\n",
      "MBA in HR and Marketing from KL University in 2018.\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "DECLARATION:\n",
      "\n",
      "I do here by declare that all particulars mentioned above are true to the best of my knowledge.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hyderabad\t\t\t\t\t\t\t\t\t                     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Best Regards, Swetha. all the details and particulars furnished above are true to the best of my knowledge.rsity.ion security group. reporting, work assignments.acks. It provides hardware, software, and services to investigate cybersecurity attacks, protect against malicious software, and analyze IT security risks.\n",
      "\n",
      "Processing text:\n",
      "Rahul  (Techno Functional Consultant)  \n",
      "Professional Summary\t\n",
      "Having Around 5+ years of experience in ERP Experience including 3 years in workday HCM and Expertise in Workday HCM , Benefits, Leave of Absence, Integration , Reporting , workday studio .\n",
      "Core Qualifications & Skills\t\n",
      "Involved in Full life cycle Workday implementation experience from requirement gathering to post deployment product support for HCM modules as well as various integrations in workday.\n",
      "Hands on configuring the Various Core HCM, Benefits ,Recruiting, Payroll ,Talent Modules .\n",
      "Expertise in Report writer, EIB, PICOF, DT, Workday Studio, CCW,CCB,BIRT, Calc Fields. \n",
      "Expertise in Payroll integrations from workday to ADP , PS, by using PICOF and PECI .\n",
      "Developed and maintained custom-report types (Advanced, Matrix) using report writer tool.\n",
      "Hands on experience in creating BIRT layouts using Report Designer, for Using Report Designer.\n",
      "Involved in transformation of XML into XSLT for presenting data for different web Services.\n",
      "Expertise In Workday Security, leave absence, recruiting and Configuring the Befit 401 Plan etc.\n",
      "Good Knowledge  Creating leave families , Leave types , and absence condition rules in Module.\n",
      "Experience in inbound/outbound integration using EIB, CCW/CCB, Report Writing, creating Workday Cal fields, Custom report, (Matrix, Composite, trending, Advanced) BIRT tool .\n",
      "Configured the custom Dashboard and Created Reports and added to the various dash boards.\n",
      "Configured BP for leave of absence , Recuring , core HCM, written condition rules for steps etc.\n",
      "Expertise in building EIBs (Enterprise Interface Builder) integration within WD for sending Data\n",
      "Prioritizing, reproducing, and verifying bug fixes in different Workday integrations, reports BP’s.\n",
      "Ability to work creatively , analytically in a problem-solving workday Production environment,\n",
      "Interaction with all work streams including functional, conversion and project management.\n",
      "Expertise in developing Payroll interfaces using PICOF/ PECI with the help of Workday Studio and Document Transformation to  meet client’s complex payroll requirements using DT, Studio.\n",
      "Experience in understanding and gathering the business requirements, translating Functional\n",
      "specifications and develop code along with detailed design, Performed UTP test cases in wd.\n",
      "Excellent client interaction skills and experience in working independently as well as in a team.\n",
      "Developed Several Complex Integrations using Workday Studio and EIB CCW, PICOF, DT.\n",
      "Have good knowledge ETV/XTT functions in Document transformation for validating the data.\n",
      "Having knowledge in XML, WD-SOAP Web Service, and WD- REST Web Service and\n",
      "Experienced in  using such as Soap UI , Postman , XML Exchanger tools for testing API call .\n",
      "Experience on getting requirement from the client and handing sharing the work across team.\n",
      "Hands on experience in creating New security groups,  or updating security groups with various domains , security polices, activating security policies and identifying the security Objects .\n",
      "Professional \n",
      "Working As software Engineer in  Infosys  From Jun 2016 – Till date.\n",
      "\n",
      "\n",
      "Technical- Skills.\n",
      "\n",
      "\n",
      "Education Details:\n",
      "Completed B-Tech from JNTU Anantapur 2016  with 70 %.\n",
      "Project Profile:-\n",
      "Project-2\t   :   Implementation & Support  workday HCM\n",
      "Client\t                 :  CDK Global .\n",
      "Role\t\t   :  Workday Techno Functional Consultant.\n",
      "\n",
      "Description: CDK Global is the largest global provider of integrated information technology and digital marketing solutions to automotive dealerships and manufacturers in more than 100 countries worldwide for the world’s biggest car brands Although we operate on a global scale we are small by comparison and that is a good thing It means that we are still a business where every person matters and where anyone can make an impact on our growth and success We have opportunities in a wide range of business areas so wherever in the world you join us you will get the support training and tools you need to make significant\n",
      "\n",
      "Role and Responsibilities:\n",
      "Understanding the Business Requirements by studying the Functional Documents.\n",
      "Modified the XSLT code as per CR-request and adding the new XSLT for Different info types. \n",
      "Create the new WD studio programs to sending AI-Statement to worker documents using BIRT.\n",
      "Creating the custom reports as per the client requirement and preparing the UTP documents.\n",
      "Created Workday Studio programs to load compensation data from ADP to workday.\n",
      "Created EIB Inbound Integrations for loading the employees personal Information like, Emergency contacts, , One-time payments, Bank account information, cost center information.\n",
      "Created EIB Integrations, written XSLT code and sending data from WD to downstream systems.\n",
      "Hands-on experience in creating the calculated fields using different functions complete logics. \n",
      "Supporting the Different teams in UAT phase as with test factory teams during integration testing.\n",
      "Involved in calls with client and update the work status as well as clarifications if any.\n",
      "Handled Workday Service Upgrade Testing (WD29, WD30) for all the existing integrations\n",
      "Responsible for supporting the new change requests and enhancements in the project.\n",
      "Created calculated fields and worked on simple and advanced, matrix , Trending  reports.\n",
      "Worked on integrations systems (EIB’s, Core Connectors, PICOF.DT, Workday Studio).\n",
      "Day to day support of workday integrations, security, Business Process, and reporting issues.\n",
      "Coordinated with Onshore on requirements gathering, implementation, testing and enhancement of Integration, reports , business Process, EIB,BIRT and  workday studio integrations .\n",
      "Configured various business processes and created notifications to integrations, Reports etc.\n",
      "Design of web services to send/receive between Workday and Third-party system using API call .\n",
      "Developed analytics dashboards , data sources to provide actionable reporting  analytics.\n",
      "Deployed workday objects using Solutions from implementation to UAT, production tenants by following the change management process, solving the migration issues by using OX.\n",
      "Configured Leave family, leave type, Absence rules for countries as per business requirements\n",
      "Involved in Workday version upgrade testing and Scheduling and Monitoring Integrations.\n",
      "Expertise in developing Payroll interfaces using PICOF, PECI with the help of Workday Studio and DT to meet client’s complex payroll requirements sending to Diff payroll Vendors.\n",
      "Experienced in analyzing and preparing Project Deliverables Technical Design Document (TDD).\n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenet to Sandbox and Production using Object Transporter. \n",
      "Created the new outbound integrations to sending the time off corrections Information from workday to ADP payroll system.\n",
      "Project-2\t   :   Implementation & Support  workday HCM\n",
      "Client\t                 :  CDK Global .\n",
      "Role\t\t   :  Workday  PS  Consultant.\n",
      "\n",
      "Description: CDK Global is the largest global provider of integrated information technology and digital marketing solutions to automotive dealerships and manufacturers in more than 100 countries worldwide for the world’s biggest car brands Although we operate on a global scale we are small by comparison and that is a good thing It means that we are still a business where every person matters and where anyone can make an impact on our growth and success We have opportunities in a wide range of business areas so wherever in the world you join us you will get the support training and tools you need to make significant\n",
      "\n",
      "      Role and Responsibilities:\n",
      "Responsible for various customizations of fields, records, pages, components and menus as per the client requirements by using Application Designer\n",
      "Customized JOB DATA component to accommodate few more fields which are using as inputs for other systems and worked on APP engine, SQER, PS query, component Interface .\n",
      "Created CI with AE to import the JOB Requisitions data into PeopleSoft system from file and performed some validations before inserting to PS system.\n",
      "Was involved in functionality of sending Emails notifications through users with help of Send Mail Function.\n",
      "Used Process Scheduler to run scheduled process at a specific time and/or run recursively at a specific interval and used process Monitor to view status of the process.\n",
      "Creating new application engine program for sending employees data to third party system.\n",
      "Generating the Relocation Letters As per HR request and sending to the Daily Process Report to the client.\n",
      "Developed People Code to implement specific business rules and validations to enable the system to perform the business process.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Ramesh A\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "(Workday HCM Consultant)\n",
      "\n",
      "\n",
      "PROFESSIONAL SUMMARY:\n",
      "An ERP Consultant with overall 5+ years of professional IT experience with 3+ years of extensive Workday experience.\n",
      "Exceptional experience in Workday’s Core HR, Staffing and Compensation Functional areas.\n",
      "Hands on experience in Configuring Organizations, Business process and creation of Custom Reports.\n",
      "Experienced on Compensation elements configurations and updates.\n",
      "Involved in requirements analysis, integrations, testing and system documentation support.\n",
      "Creation of various calculated fields to use in custom reports.\n",
      "Configuring EIB Inbound and Load data into workday with webservices.\n",
      "Creation of various custom reports as per the requirements.\n",
      "Working on various enhancements related to EIB Integrations, Custom Reports and Configuration changes.\n",
      "Experience with creating Staffing models for Supervisory Orgs, Reorganizations and business process framework, Organization Types, Organization Hierarchies.\n",
      "Good experienced in developing technical solutions for the Workday platform using EIB and Web Services.\n",
      "Workday training includes Fundamentals, Simple Inbound Integrations, Business Processes, Calculated Fields, Report Writer, and Security Fundamentals.\n",
      "Experience in writing SQL queries and have exposure to different databases, includes SQL Server.\n",
      "Possess Good communication skills, keen to adapt to new technologies and effective Team Player. \n",
      "\n",
      "TECHNICAL SKILLS:\n",
      "\n",
      "\n",
      "EDUCATION:\n",
      "Bachelor of Technology: Mechanical Engineering from Jawaharlal Nehru Technological University – Kakinada.\n",
      "PROFESSIONAL EXPERIENCE:\n",
      "Tata Consultancy Services  \t\t\t \n",
      "Project: Support/Enhancement of Workday HCM\t                               \t\t\t      (May’ 19 – Till date) \n",
      "AIMS Community College, USA\n",
      "Workday HCM Functional Consultant\n",
      "\n",
      "Roles and Responsibilities:\n",
      "Responsible to work on workday application incidents raised by business end users.\n",
      "Troubleshoot the issue to find the root cause of the incident and provide them a solution.\n",
      "Written custom validations on business process object as per business requirement.\n",
      "Modified Business process as add/remove steps from the existing configurations.\n",
      "Changed the security groups on business process security policy functional areas.\n",
      "Modified step condition rules for existing business processes.\n",
      "Developed custom Integrations to update Compensation Eligibility rules, Grade and Grade profiles.\n",
      "Developed Inbound integrations to load job profile and matrix organization per business requirement.\n",
      "Clarify the end user queries and guide new users about workday system functionality.\n",
      "Communicate end users for better understand of the case and update the status of incident.\n",
      "Responsible to Loaded new set of setup data through EIB.\n",
      "Create and modify condition rules as per new business policy changes.\n",
      "Configured new work schedules as requested by the business operations user.\n",
      "\n",
      "\n",
      "Project: Support of Workday HCM                       \t\t\t\t\t(Nov’17 – May’ 19)\n",
      "Safeway, Phoenix, AZ       \t\t\t\t\t\t\n",
      "Workday Reports Developer.\n",
      "\n",
      "Roles and Responsibilities:\n",
      "Worked on Reports to create custom reports using Workday Report Writer to meet the business needs of HR application report consumer groups. \n",
      "Generate different kinds of reports - Simple, Advanced and Matrix reports to meet client requirements within the workday tenant. \n",
      "Create calculated fields for Custom Reports to ensure required report delivery. \n",
      "Developed advanced custom reports, composite reports and matrix reports in Workday and test developed reports.\n",
      "Designedand built both inbound and outbound EIB integrations in various segments of Workday system.\n",
      "Created Organizations (Locations, Supervisory Orgs, Business Units, Cost Centers, Custom orgs, Organization Hierarchy (Location Hierarchy).\n",
      "Create reports by using appropriate data source and business objects to deliver output for end users.\n",
      "Created report on Employee Convert to Contract to full time Employee List.\n",
      "Created report on Contingent workers, converting the contingent workers into employees.\n",
      "Extensively worked on Workday application in creating reports, calculated fields, basic integrations using EIB, data conversion and Migrations.\n",
      "Developed custom reports for the hcm modules like Core HR.\n",
      "Used Report Writer to create new Custom reports with appropriate Data Sources, Objects and Fields\n",
      "Supported Customer resources in development and troubleshooting of reports and integrations.\n",
      "\n",
      "\n",
      "Project: Support of PeopleSoft HCM\t\t\t\t\t\t\t(April’16 – Oct’17)\n",
      "Amdocs\n",
      "PeopleSoft Developer\n",
      "\n",
      "Responsibilities:\n",
      "Analyzed the requirement documents to understand the customer business requirement.\n",
      "Customized system applications and designed many applications as scratch.\n",
      "Work with incident request raised at user end.\n",
      "Interact with onsite team to know status of project on daily basis.\n",
      "Responsible to work on support issues.\n",
      "Consulting with the Solution Architect on business prospective implementation workflow.\n",
      "Collaborating with overseas team-mates on daily/weekly discussions.\n",
      "Analyzing the issues and providing resolutions reported by users\n",
      "Working on Incidents, Service Request and EWO’s (Enhancement Work Orders).\n",
      "Developed custom advanced custom reports, calculated fields, complex xslt logic \n",
      "Coordinate with other team members for defect deliveries and production support activities.\n",
      "Conduct knowledge sharing sessions to newly joined team members.\n",
      "\n",
      "\n",
      "\n",
      "Processing text:\n",
      "Client Management, Partnering with Managers and Business unit heads to determine staffing needs, provide recruiting expertise, design hiring and sourcing strategies, help build a strong talent force.atisfaction levels.Changes, Location Changes, Pay rule/Function/Business Unit Changes.nologies with key HR processes. Responsible for delivering day-to-day HR systems service delivery activities in support of policies and  practices,  this  role  will  primarily  focus  on  supporting  the  management  of  our  external, contingent workforce within the Workday HR system.\n",
      "\n",
      "Processing text:\n",
      "Bachelors in Electronics & Communication Engineering from JNTU-Kakinada, India in 2017. Document transformation, Calculated fields, Workday report writer, XML, XSLT.con.ound/Outbound, Sup Orgs, Business Objects.e great commitment to implement client’s Workday Strategy.\n",
      "\n",
      "Processing text:\n",
      "Seeking suitable positions in Workday HCM  as Techno functional consultant with a reputed organization that would help me utilize my skills and grow as an individual to deliver more for the organization’s growth.                                                                                  \t\t\t                     \n",
      "PROFESSIONAL EXPERIENCE – 4 + years (Serving  Notice).\n",
      "HIGHLIGHTS\n",
      "Workday Integration, Studio, Core HCM, Recruiting, Benefits, Leave of absence. \n",
      "Trainings on Core Financials Integration, Workday Studio.\n",
      "Strong in EIB Inbound & Outbound, Reports, Calculated Fields, Custom Objects, Business Process, Dashboards, CCW/PICOF, Calc Fields, BIRT,\n",
      "Worked on Implementations and Configuration, security, Business Process.\n",
      "Achievements:\n",
      "Successfully completed 2 major Project’s implementations.\n",
      "KT to the new hires, Provide training Internally  .\n",
      "TECHNICAL SKILLS:\n",
      "\n",
      "Workday HCM, Core HCM, Recruiting , LMS , Report Writer, EIB, Calc Fields, Payment Connectors, Workday Studio, Business process, Security, DT. Benefits , Talent etc.\n",
      "Core Connectors, PICOF, Document Transformation, BIRT.\n",
      "People code, App engine, CI.XML, XSLT. \n",
      "Work Experience :\n",
      "\n",
      "Working As a Workday consultant  at  Wipro technologies from  2018 to till .\n",
      "Worked as Software engineer in Infosys  from  2017 AUG  to JULY  2018.\n",
      "\n",
      "Having 4+ years of experience in ERP Experience and including 3 years in workday HCM, completed Workday Integration and Support to the previous project.\n",
      "Excellent functional skills HCM  modules like Core HCM, Leave of Absence, Recruiting, setup etc.\n",
      "Expertise in Configuring business Process for various business process adding steps condition rules.\n",
      "Involved in the project Implementation, Testing, Managing Business, Troubleshooting the issues during the implementation and post implementation support and involved end to end Implementation .\n",
      "Configured various business process related to Leave of Absence ,Condition rule , business process. \n",
      "Good Knowledge ion Creating leave families , Leave types , and absence condition rules in absence.\n",
      "Hands on experience in inbound/ outbound integrations using connectors, Workday studio, BIRT tools.\n",
      "Developed and maintained custom-report types  like advanced, matrix, Composite using report writer. \n",
      "Expertise in Payroll integrations from WD to ADP , PS, NGA  by using PICOF and PECI connectors.\n",
      "Participate in all activities of Workday Project while working with customers during alignment sessions, discovery meetings, touchpoint meetings, customer configuration, testing production support.\n",
      "Familiar with Ticketing tools like Service now and Salesforce, HPLM  for the incidents and CR’s.\n",
      "Expertise in building EIBs (Enterprise Interface Builder) for integration within WD for sending Data.\n",
      "Good knowledge on ETV/XTT functions in DT while sending data from WD to payroll.\n",
      "Hands on experience in Workday security, Functional area, Security polices, Domains Etc.\n",
      "Expertise In workday Leave of absence, recruiting modules and Configuring the Befit 401 Plan etc.\n",
      "Configured business process for leave of absence , Recuring , core HCM, condition rules for steps  etc.\n",
      "Created complex integration using studio for data syncope integration from WD to Different system.  \n",
      "Experience in inbound/outbound integration using EIB, Core Connector, Report Writing, creating Workday Calculated fields, Custom report, (Matrix, Composite Advanced) and BIRT tool .\n",
      "Monitor Workday community portal to find new enhancements that are delivered during new upgrade and implement required enhancements for our business requirement, identifying the updated changes \n",
      "Excellent analytical, problem solving, communication and interpersonal skills with ability to interact with individuals at all levels.  Consistently meets goals, objectives, and target dates.\n",
      "Involved in Workday update testing for all integrations , Supporting to HRIT team based on request.\n",
      "Motivated team player willing to accept exciting challenges with sound of the IT industry.\n",
      "Involved in transformation of XML into XSLT for presenting data for different web Services.\n",
      "Hands on experience in creating New security groups,  or updating security groups with various domains security polices, activating security policies ,identifying the security for business obj\n",
      "Having knowledge in XML, WD-SOAP Web Service, and WD- REST Web Services.\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Created various EIB outbound integrations for sending employees data from WD to external GDW  .\n",
      "Worked on development to add additional functionalities to the existing different PICOF Integrations either in the Workday Studio code level or Configuration level.\n",
      "Developed various Custom Reports for compensation, transfer, etc.\n",
      "Created New matrix Report and sharing to HRIS team and creating ISU and ISSG for reports.\n",
      "Coordinate with users in UAT phase while testing Change request .\n",
      "Developed the studio integration for merging the multiple reports for STI and LTI Amount using workday studio.\n",
      "Created the PICOF Outbound integration to generate the multiple files like Hire, termination, OTP, Allowance details to third party Payroll system.\n",
      "As per SFDC cases, provided the “Start proxy access “to the KL HRSS team to perform transactions. \n",
      "Worked on  migration of data from Sandbox to Production.\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Create various reports as per business (Advanced, Matrix, Composite, Trending, Dash Boards , BIRT).\n",
      " Prepare business requirement specification document and technical documents\n",
      "Responsible for creating custom reports Advance, Matrix, Search, trending and box reports\n",
      "Involved in building EIB outbound integrations for recruitment, core HCM, compensation modules.\n",
      "Worked on building CCW/PECI integrations for extracting the delta changes from workday To ADP.\n",
      "Having good experience in building Studio inbound and outbound integrations.\n",
      "Utilized DT for converting the CCW, PICOF output XML files into text files\n",
      "Having good knowledge on Functional concepts like Business processes , condition rules , To do steps.\n",
      "Hands-on experience In Migrating the XSLT Code, Reports from  Sandbox and Production \n",
      "Involved in configuring security, roles and access restrictions at domain level and BP level.\n",
      "Provide Day to day support of Workday Integrations, and Reporting issues.\n",
      "\n",
      "English, Hindi & Telugu. \n",
      "                                              \t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "Processing text:\n",
      "\n",
      "WORKDAY | HCM | FCM\n",
      "Name \t\t: Kumar S.S\n",
      "Role \t\t: Workday Consultant \n",
      "\n",
      "Professional Summary:\n",
      "\n",
      "Having 6+ years of experience in Workday as a Workday Consultant, and involved in Workday HCM|FCM,  security ,support and enhancement Projects.\n",
      "\n",
      "Having good understand of various Functional areas in HCM as well as Workday Financial.\n",
      "\n",
      "HCM – Core HCM, Absence, Time Tracking, Recruiting, and Benefits.\n",
      "\n",
      "FCM – Procure to Pay, Payables, Business Assets , Expense, Billing and  Revenue. \n",
      "\n",
      "Technically proficient in customizations, enhancements using various tools like Report writer, Calculated Fields, EIB, Core Connector, DT and Workday Studio. \n",
      "\n",
      "Have good experience in various core connector templates like Core Connector worker, PICOFF and PECI.\n",
      "\n",
      "Good Working knowledge workday studio components like workday-In, workday-out Rest, Workday-out Soap, A-sync mediation, Splitter, aggregator, MVEL, Store, CSV-to-XML in Workday Studio.\n",
      "\n",
      "Good Working knowledge in technologies XML, XSLT, SOAP, Web services.\n",
      "\n",
      "Have working experience on PECI (payroll interface effective changes ) and creating custom objects.\n",
      "\n",
      "Have worked on, business process configurations and security areas based on business requirement.\n",
      "\n",
      "Expertise in Report analyst with using Advanced, Matrix and Composite reports. \n",
      "\n",
      "Have worked with incident and change requests for BAU.\n",
      "\n",
      "Worked on creating Complex Calculated Fields using Single Instance, lookup related Value, Lookup As of date fields in Custom reports in Workday HCM. \n",
      "\n",
      "Worked on EIB Inbound to load the data from file to workday system using Web services for cost center, OTP, transfer, Change Emergency contact information etc.\n",
      "\n",
      "Work experience in configuring Business Processes, Security configurations and Developing Reports.\n",
      "\n",
      "Working experience on creating custom object and custom fields As per requirement. \n",
      "\n",
      "Good working experience on security configurations and creating ISU and creating security groups.\n",
      "\n",
      "Good knowledge in migrating reports from lower tenant to sandbox and production using object transporter.\n",
      "Good problem solving and communication skills.\n",
      "\n",
      "Experience Summary:\n",
      "\n",
      "Currently working as workday consultant in ITC InfoTech, Bengaluru from  Oct’2017 to Till date.\n",
      "Worked as senior software engineer in Wipro from July 2014 to Sep 2017.\n",
      "Technical Skills:\n",
      "    \n",
      "\n",
      "\n",
      "Project Summary:\n",
      "\n",
      "Major Projects executed:\n",
      "Project 3# : \n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "Roles and Responsibilities: \n",
      "\n",
      "Created new integration to pull the new hires information using Core Connector Worker and Document Transformation, which uses connector integrations XML Output as its data source input.\n",
      "\n",
      "Created EIB inbound integration for loading data. \n",
      "\n",
      "Creating core connectors integration using  PECI ( payroll effective change interface) template.\n",
      "\n",
      "Developed simple and secure integrations using Workday Enterprise Interface Builder (EIB).\n",
      "\n",
      "Creating custom objects and custom fields and calculated fields as per requirements. \n",
      "\n",
      "Inbound/Outbound Integration Creation using Workday EIB, Core Connectors.\n",
      "\n",
      "Developed the custom reports for sending the Job Anniversary alerts to the Workers managers for initiation the OTP Plan.\n",
      "\n",
      "Developed various Custom Reports such as Lookup and Audit Reports using Calculated Fields.\n",
      "\n",
      "Creating security groups and adding permissions in domain security policies.\n",
      "\n",
      "Involved in creating the inbound integration using Workday studio and Workday out SOAP, router component to load the Compensation data into workday system.\n",
      "\n",
      "Involved in Loading the data for Emergency contacts, cost center, one time payments, bank account details data through enterprise interface builder(EIB) using web services like add updated org, onetime payments etc.\n",
      "\t\t\n",
      "Modified the XSLT code as per CR-request and adding the new XSLT code for Different info types.\n",
      "\n",
      "Hands on experience in using ETV and XTT functions in Document transformation.\n",
      "\n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenet to Sandbox and Production using Object Transporter.\n",
      "\n",
      "Understanding the Business Requirements by studying the Functional Documents.\n",
      "PROJECT  2#\n",
      "\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Created various EIB outbound integrations for sending customer contract data from workday system to all sales mangers email group.\n",
      "\n",
      "Involved in creating the inbound integration using workday studio and workday out soap, router component to load the currency rates into workday system.\n",
      "\n",
      "Worked on worktag configurations and arrange a posting rule set based on worktag functionality.\n",
      "\n",
      "Have worked custom validations in maintain custom validations based on business requirement. \n",
      "\n",
      "Developed the new custom reports for capturing all business process and transactions based on the client requirement and creating the calculated field for transfer, promotion etc.\n",
      "\n",
      "Developed the new custom reports for Supplier and Customer Aging reports and Trail balance and Cash basis reports based on spend and revenue categories.\n",
      "\n",
      "Scheduling the custom reports on daily, weekly, monthly basis based on client requirement.\n",
      "\n",
      "Understanding the requirements from the client and developing new integrations. Experienced to work with Workday Report Writer and creating custom integrations with third party applications using Enterprise Interface Builder (EIB).\n",
      "\n",
      "Track and resolve user support issues with current system Maintain good working relationships with project team members, internal customers (e.g. BI, AR and AP, PO), and external service vendors.\n",
      "\n",
      "Involved in Finance Audit phase and provide access and created audit report based on business need.\n",
      "\n",
      "Have tested for AP and PO modules for newly created Company.\n",
      "\n",
      " Used sequence generators, generating templates and validating inbound integration system results.\n",
      "\n",
      "Created and used calculated fields in reporting, business processes, integrations and other areas within Workday.\n",
      "\n",
      "Involved in Setup security  and  Workday Business process Configuration.\n",
      "\n",
      "\n",
      "PROJECT  1#\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Worked on Application Engine, File Layout, Component Interface and Integration Broker.\n",
      "Designed technical documents and have worked towards development of interfaces and conversions based on design documents.\n",
      "Modified, designed, configured and built fields, records, sub records, setting up keys to records, assign table edits like prompt table.\n",
      "Involved in online changes to the delivered pages, components, menus and translate values.\n",
      "Have Customized and developed Application engines for loading bulk data from external systems.\n",
      "Developed and modified People Code to implement specific business rules and validations to enable the System to perform the business process.\n",
      "Used File Layout Definition to get data from the legacy system to PeopleSoft tables.\n",
      "Managed and monitored process scheduler for any issues while scheduled interfaces/processes ran and resolved the issues.\n",
      "Developed/Modified various PS queries in order to help the client day-to-day activity.\n",
      "Involved in creating PS Query’s and sending it through email to different country FSCM heads.\n",
      "Worked on the reporting tools like PS Query, XML Publisher.\n",
      "Have worked on File Layout, Application Engine, Component Interface, File layout, Excel to CI, XML Report.\n",
      "\n",
      "Educational Summary:\n",
      "\n",
      "M.Tech in computer science and Engineering (C.S.E) from Bharath  University, Chennai in 2009.\n",
      "B.Tech (PE) from Nagarjuna University, Guntur in 2006.\n",
      "\n",
      "Processing text:\n",
      "\u0007lso having experience in Support activities like fixing the errors, scheduling.t.ls ls \"integrated logistics solutions\" across the Asia Pacific region. The division offers a range of transport, warehousing and value-added services. The division operates a fleet of air, sea, rail and road vehicles and vessels. The fleet has more than 19,000 vehicles including courier trucks, prime movers, b-doubles, and trailers; and 13,000 units of containers, ships, vessels and aeroplanes operating across the Asia Pacific region. In Singapore specifically, TGL was reported in 2011 as owning small cargo ships, which ferry container trucks to and from nearby ports in neighbouring Malaysia and Indonesia and a fleet of trucks consisting of about 70 Hino, Fuso and UD prime movers that have roughly seven single trailers for each mover. In Vietnam TGL has over 300 trucks.\n",
      "\n",
      "Processing text:\n",
      "                                                                          \n",
      "Vinay kumar .v\n",
      "Workday Functional Consultant\n",
      "\n",
      "EXPERTISE SUMMARY\t\n",
      "Having 4.2 years of Total Experience in as a Workday  Functional Consultant.\n",
      "Knowledge on the functional modules of Workday (Core HCM, Supervisory Organization, Delegation, Cost Center, Locations and Knowledge on Security).\n",
      "Experience in implementing Workday Functional and Integrations for various modules including HCM Core, Compensation, Time Tracking and Absence Management, Payroll, Benefits and Performance Management.\n",
      "Having good knowledge on Security Groups: Role Based, User Based & Job Based.\n",
      "Experienced in Report Writing, Custom Reports (Simple, Advanced, Matrix and Composite), Calculated Fields, Integrations, EIB, Connectors, XML, XSLT, Workday web services, Organization Structure & Custom Objects. \n",
      "Hands-on experience In Migrating the XSLT Code, Reports from Lower tenant to Sandbox and Production using Object Transporter.  \n",
      "Excellent object management skills in Workday like configuring Supervisory Organizations, Matrix Organizations, Compensation (salary based on different grades, allowances), Performance Management, Time Management, Business Process (Hiring and Termination).\n",
      "Strong team player with excellent interpersonal, communication and leadership skills and ready to take an independent challenge and has the ability to work in a team.\n",
      "TECHNICAL SKILLS\n",
      "Workday Skills                   : Reports, Studio, Workday Business Processes, Security, Staffing, Report\n",
      "Writer,          ……………………….Calculated Fields, EIB, Core Connector, Web Services, etc.\n",
      "Languages / Tools             : XML, XSLT & Studio.\n",
      "Document Processing     : Microsoft Excel, Microsoft Word, Microsoft PowerPoint.\n",
      "\n",
      "EDUCATION SUMMARY\t\n",
      "Master of business administration from Narayana engineering College in 2017 with  80%\n",
      "\n",
      "WORK EXPERIENCE\t\n",
      "Working as a Workday Consultant in Tech Mahindra from Sep 2017 to Till Date.\n",
      "\n",
      "PROFESSIONAL SUMMARY\t:\n",
      "\n",
      "Project #1:\n",
      "Company        : Tech Mahindra\n",
      "Project Type  : Workday Support and Enhancements\n",
      "Designation   : Workday Consultant\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Develop new Integrations ( EIB, Core connector) and Custom Reports based on business requirements.\n",
      "Modifications and implementing multiple enhancements to existing, Custom Reports, Calculated field and XSLT.\n",
      "Hands-on experience In Migrating the Reports from Lower tenet to Sandbox and Production using Object Transporter.\n",
      "Worked on Core connector for Template Location, worker, and Document Transformation.\n",
      "Worked on Integration system User for transfer the ownership of reports, schedule and Integration.\n",
      "Worked on Inbound and Outbound EIB Integration concepts and created the various EIB integrations.\n",
      "Configure workday configurable security as per client’s business requirements.\n",
      "Created EIB Inbound Integrations for loading the employees personal Information like Emergency contacts, Compensation, One-time payments, Bank account, cost center information.\n",
      "Monitor daily schedulers and report errors as needed.\n",
      "Developed Core Connector and Document Transformation integrations to get changes file of CSV format from XML Output.\n",
      "Strong Knowledge on working with CR-Change Requests as per business requirement and building and moving changes to production.\n",
      "Involved in performing Mass Loading of data using EIBs.\n",
      "Involved in calls with client and update the work status as well as clarifications if any. \n",
      "Day to day support for Workday HCM, Integrations and Reporting issues.\n",
      "\n",
      "Project #2:\n",
      "Company        : Tech Mahindra\n",
      "Project Type  : PeopleSoft Support and Enhancements\n",
      "Designation   : Analyst\n",
      "\n",
      "Roles and Responsibilities:\n",
      "\n",
      "Have Customized and developed Application engines for loading bulk data from external systems.\n",
      "Track and resolve user support issues with current system Maintain good working relationships with project team members, internal customers, and external service vendors\n",
      "Have designed technical documents and have worked towards development of interfaces and conversions based on design documents.\n",
      "Modified, designed, configured and built fields, records, sub records, setting up keys to records, assign table edits like prompt table.\n",
      "Involved in online changes to the delivered pages, components, menus and translate values.\n",
      "Have Customized and developed Application engines for loading bulk data from external systems.\n",
      "Developed and modified People Code to implement specific business rules and validations to enable the System to perform the business process.\n",
      "Used File Layout Definition to get data from the legacy system to PeopleSoft tables.\n",
      "Managed and monitored process scheduler for any issues while scheduled interfaces/processes ran and resolved the issues\n",
      "Developed/Modified various PS queries in order to help the client day-to-day activity.\n",
      "Worked on the reporting tools like PS Query, XML Publisher\n",
      "Have worked on File Layout, Application Engine, Component Interface, File layout, Excel to CI, XML Report\n",
      "\n",
      "\n",
      "\n",
      "DECLARATION:\n",
      "           I hereby declare that all the information furnished is true to by best of my knowledge.\n",
      "\n",
      "Extraction complete. Data saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes(1).csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import win32com.client  # For .doc files on Windows\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the path to your resumes folder\n",
    "folder_path = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume'\n",
    "\n",
    "# List to store extracted information\n",
    "resume_data = []\n",
    "\n",
    "# Function to extract text from .docx files\n",
    "def extract_text_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "# Function to extract text from .doc files\n",
    "def extract_text_doc(file_path):\n",
    "    word = win32com.client.Dispatch(\"Word.Application\")\n",
    "    doc = word.Documents.Open(file_path)\n",
    "    text = doc.Content.Text\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    return text\n",
    "\n",
    "# Function to extract details using regex or keyword matching\n",
    "def extract_details(text):\n",
    "    # Initialize empty details\n",
    "    details = {\n",
    "        'Skills': 'N/A',\n",
    "        'Experience Level': 0,  # Default experience is 0\n",
    "        'Education Level': 'N/A',\n",
    "        'University': 'N/A',\n",
    "        'Year of Passing': 'N/A',\n",
    "        'Percentage': 'N/A'\n",
    "    }\n",
    "\n",
    "    # Print the text for debugging\n",
    "    print(f\"Processing text:\\n{text}\\n\")\n",
    "\n",
    "    # Updated regex to find specific details\n",
    "    skills_match = re.search(r\"(Skills|Skills:|Skills -|Skills are)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    experience_match = re.search(r\"(Experience Level|Experience|Experience:|Exp)[\\s:]*([0-9]+)\", text, re.IGNORECASE)\n",
    "    education_match = re.search(r\"(Education Level|Education|Education:)[\\s:]*([A-Za-z0-9 ]+)\", text, re.IGNORECASE)\n",
    "    university_match = re.search(r\"(University|University:|College)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    year_match = re.search(r\"(Year of Passing|Year)[\\s:]*([0-9]{4})\", text)\n",
    "    percentage_match = re.search(r\"(Percentage|Marks)[\\s:]*([0-9]+\\.?[0-9]*)%\", text)\n",
    "\n",
    "    # Extract Skills\n",
    "    if skills_match:\n",
    "        details['Skills'] = skills_match.group(2).strip()\n",
    "\n",
    "    # Extract Experience\n",
    "    if experience_match:\n",
    "        details['Experience Level'] = int(experience_match.group(2).strip())\n",
    "    \n",
    "    # Extract Education Level\n",
    "    if education_match:\n",
    "        details['Education Level'] = education_match.group(2).strip()\n",
    "\n",
    "        # Year of Passing based on Education Level (assuming the pattern that the year follows the degree)\n",
    "        # This is just an example; you can customize it based on your resume format.\n",
    "        if details['Education Level']:\n",
    "            year_of_passing_match = re.search(r\"(\\d{4})\", details['Education Level'])\n",
    "            if year_of_passing_match:\n",
    "                details['Year of Passing'] = year_of_passing_match.group(0)\n",
    "\n",
    "    # Extract University\n",
    "    if university_match:\n",
    "        details['University'] = university_match.group(2).strip()\n",
    "\n",
    "    # Extract Percentage\n",
    "    if percentage_match:\n",
    "        details['Percentage'] = percentage_match.group(2).strip() + '%'\n",
    "\n",
    "    return details  # Return only extracted details\n",
    "\n",
    "# Traverse through the folder and subfolders\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        text = \"\"\n",
    "\n",
    "        # Check the file type and extract text accordingly\n",
    "        if file.endswith('.docx'):\n",
    "            try:\n",
    "                text = extract_text_docx(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "        elif file.endswith('.doc'):\n",
    "            try:\n",
    "                text = extract_text_doc(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Extract details from the text\n",
    "        details = extract_details(text)\n",
    "\n",
    "        # Append folder name, file name, and extracted details\n",
    "        resume_data.append({\n",
    "            'Folder Name': os.path.basename(root),\n",
    "            'File Name': file,\n",
    "            'Skills': details['Skills'],\n",
    "            'Experience Level': details['Experience Level'],\n",
    "            'Education Level': details['Education Level'],\n",
    "            'University': details['University'],\n",
    "            'Year of Passing': details['Year of Passing'],\n",
    "            'Percentage': details['Percentage'],\n",
    "        })\n",
    "\n",
    "# Convert extracted data to a pandas DataFrame\n",
    "df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Save the extracted data to a CSV file\n",
    "output_file = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes(1).csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Extraction complete. Data saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400f90c0-e9b0-4656-b6d1-2458981048de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_AnubhavSingh.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_AnubhavSingh.docx'\n",
      "Extraction complete. Data saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes(2).csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import win32com.client  # For .doc files on Windows\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the path to your resumes folder\n",
    "folder_path = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume'\n",
    "\n",
    "# List to store extracted information\n",
    "resume_data = []\n",
    "\n",
    "# Function to extract text from .docx files\n",
    "def extract_text_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "# Function to extract text from .doc files\n",
    "def extract_text_doc(file_path):\n",
    "    word = win32com.client.Dispatch(\"Word.Application\")\n",
    "    doc = word.Documents.Open(file_path)\n",
    "    text = doc.Content.Text\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    return text\n",
    "\n",
    "# Function to extract details using regex or keyword matching\n",
    "def extract_details(text):\n",
    "    # Initialize empty details\n",
    "    details = {\n",
    "        'Technical Skills': 'N/A',\n",
    "        'Experience': 0,  # Default experience is 0\n",
    "        'Education Degree': 'N/A',\n",
    "        'Year of Passing': 'N/A',\n",
    "        'Resume Text': text  # Store the full text of the resume\n",
    "    }\n",
    "\n",
    "    # Print the text for debugging (optional)\n",
    "    # print(f\"Processing text:\\n{text}\\n\")\n",
    "\n",
    "    # Extract Technical Skills (Example regex, adjust based on resume format)\n",
    "    skills_match = re.search(r\"(Skills|Technical Skills|Skills:|Skills -)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        details['Technical Skills'] = skills_match.group(2).strip()\n",
    "\n",
    "    # Extract Experience (example: \"3 years\" or \"5+ years\" formats)\n",
    "    experience_match = re.search(r\"(Experience|Exp)[\\s:]*([0-9]+(?:\\s?[-+]\\s?[0-9]+)?\\s?(?:years?|yrs?))\", text, re.IGNORECASE)\n",
    "    if experience_match:\n",
    "        exp_text = experience_match.group(2)\n",
    "        # Try to convert years to a number\n",
    "        exp_years = re.findall(r'\\d+', exp_text)\n",
    "        if exp_years:\n",
    "            details['Experience'] = int(exp_years[0])  # Take the first found number as experience\n",
    "\n",
    "    # Extract Education Degree (Assuming the format contains \"Bachelor's\", \"Master's\", etc.)\n",
    "    education_match = re.search(r\"(Education|Degree|Qualifications)[\\s:]*([A-Za-z0-9' ]+)\", text, re.IGNORECASE)\n",
    "    if education_match:\n",
    "        details['Education Degree'] = education_match.group(2).strip()\n",
    "\n",
    "    # Extract Year of Passing (e.g., \"Graduated in 2020\" or \"2019\")\n",
    "    year_match = re.search(r\"(Year of Passing|Graduated|Year)[\\s:]*([0-9]{4})\", text)\n",
    "    if year_match:\n",
    "        details['Year of Passing'] = year_match.group(2).strip()\n",
    "\n",
    "    return details  # Return only extracted details\n",
    "\n",
    "# Traverse through the folder and subfolders\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        text = \"\"\n",
    "\n",
    "        # Check the file type and extract text accordingly\n",
    "        if file.endswith('.docx'):\n",
    "            try:\n",
    "                text = extract_text_docx(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "        elif file.endswith('.doc'):\n",
    "            try:\n",
    "                text = extract_text_doc(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Extract details from the text\n",
    "        details = extract_details(text)\n",
    "\n",
    "        # Append folder name, file name, and extracted details\n",
    "        resume_data.append({\n",
    "            'Folder Name': os.path.basename(root),\n",
    "            'File Path': file_path,\n",
    "            'Technical Skills': details['Technical Skills'],\n",
    "            'Experience': details['Experience'],\n",
    "            'Education Degree': details['Education Degree'],\n",
    "            'Year of Passing': details['Year of Passing'],\n",
    "            'Resume Text': details['Resume Text'],\n",
    "        })\n",
    "\n",
    "# Convert extracted data to a pandas DataFrame\n",
    "df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Save the extracted data to a CSV file\n",
    "output_file = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes(2).csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Extraction complete. Data saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb06f9-9179-4ff0-a8e8-4d47c78e81ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9200823-b53e-4142-8924-f8d6c118e51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete. Data saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes(3).csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import win32com.client  # For .doc files on Windows\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the path to your resumes folder\n",
    "folder_path = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume'\n",
    "\n",
    "# List to store extracted information\n",
    "resume_data = []\n",
    "\n",
    "# Function to extract text from .docx files\n",
    "def extract_text_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "# Function to extract text from .doc files\n",
    "def extract_text_doc(file_path):\n",
    "    word = win32com.client.Dispatch(\"Word.Application\")\n",
    "    doc = word.Documents.Open(file_path)\n",
    "    text = doc.Content.Text\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    return text\n",
    "\n",
    "# Function to extract details using regex or keyword matching\n",
    "def extract_details(text):\n",
    "    # Initialize empty details\n",
    "    details = {\n",
    "        'Technical Skills': 'N/A',\n",
    "        'Experience': 0,  # Default experience is 0\n",
    "        'Education Degree': 'N/A',\n",
    "        'Year of Passing': 'N/A',\n",
    "        'Resume Text': text  # Store the full text of the resume\n",
    "    }\n",
    "\n",
    "    # Extract Technical Skills\n",
    "    skills_match = re.search(r\"(Skills|Technical Skills|Skills:|Technical Skills:)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        details['Technical Skills'] = skills_match.group(2).strip()\n",
    "\n",
    "    # Extract Experience\n",
    "    experience_match = re.search(r\"(Experience|Exp|Work Experience|Work)[\\s:]*([0-9]+(?:[-+][0-9]+)?\\s?(?:years?|yrs?))\", text, re.IGNORECASE)\n",
    "    if experience_match:\n",
    "        exp_text = experience_match.group(2)\n",
    "        # Extract years as a number\n",
    "        exp_years = re.findall(r'\\d+', exp_text)\n",
    "        if exp_years:\n",
    "            # Calculate total experience if there is a range (e.g., 2-5 years)\n",
    "            if len(exp_years) > 1:\n",
    "                details['Experience'] = int(exp_years[1])  # Use the maximum value in a range\n",
    "            else:\n",
    "                details['Experience'] = int(exp_years[0])  # Take the first found number as experience\n",
    "        else:\n",
    "            if 'Fresher' in exp_text or 'Entry Level' in exp_text:\n",
    "                details['Experience'] = 0  # Indicating freshers\n",
    "\n",
    "    # Extract Education Degree (captures common degrees)\n",
    "    education_match = re.search(r\"(Education|Degree|Qualifications|Academic)[\\s:]*([A-Za-z0-9 '.]+(?:B\\.?Tech|M\\.?Tech|M\\.?CA|B\\.?E|B\\.?Sc|MBA)?)\", text, re.IGNORECASE)\n",
    "    if education_match:\n",
    "        details['Education Degree'] = education_match.group(2).strip()\n",
    "\n",
    "    # Extract Year of Passing (captures phrases like \"Graduated in 2020\", \"Completed in 2021\")\n",
    "    year_match = re.search(r\"(Graduated|Completed|Year of Passing)[\\s:]*([0-9]{4})\", text)\n",
    "    if year_match:\n",
    "        details['Year of Passing'] = year_match.group(2).strip()\n",
    "\n",
    "    return details  # Return only extracted details\n",
    "\n",
    "# Traverse through the folder and subfolders\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        text = \"\"\n",
    "\n",
    "        # Check the file type and extract text accordingly\n",
    "        if file.endswith('.docx'):\n",
    "            try:\n",
    "                text = extract_text_docx(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "        elif file.endswith('.doc'):\n",
    "            try:\n",
    "                text = extract_text_doc(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Extract details from the text\n",
    "        details = extract_details(text)\n",
    "\n",
    "        # Append folder name, file name, and extracted details\n",
    "        resume_data.append({\n",
    "            'Folder Name': os.path.basename(root),\n",
    "            'File Path': file_path,\n",
    "            'Technical Skills': details['Technical Skills'],\n",
    "            'Experience': details['Experience'],\n",
    "            'Education Degree': details['Education Degree'],\n",
    "            'Year of Passing': details['Year of Passing'],\n",
    "            'Resume Text': details['Resume Text'],\n",
    "        })\n",
    "\n",
    "# Convert extracted data to a pandas DataFrame\n",
    "df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Save the extracted data to a CSV file\n",
    "output_file = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes(3).csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Extraction complete. Data saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "746cfbac-37be-492e-a165-a18245204a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-docx) (4.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b4b174-e1a3-4d1a-bff3-92f2d4776362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported file format for: Extracted_Resumes.csv\n",
      "Unsupported file format for: Resumes-Dataset-with-Labels.csv\n",
      "Unsupported file format for: Peoplesoft Admin_G Ananda Rayudu.doc\n",
      "Unsupported file format for: Peoplesoft Admin_Gangareddy.doc\n",
      "Unsupported file format for: Peoplesoft Admin_Priyanka Ramadoss.doc\n",
      "Unsupported file format for: Peoplesoft Admin_srinivasarao.doc\n",
      "Unsupported file format for: Peoplesoft Admin_Vinod Akkala.doc\n",
      "Unsupported file format for: PeopleSoft DBA_Ganesh Alladi.doc\n",
      "Unsupported file format for: Peoplesoft Finance_Arun Venu.doc\n",
      "Unsupported file format for: Peoplesoft Finance_Pritam Biswas.doc\n",
      "Unsupported file format for: Peoplesoft Finance_Rahul Ahuja.doc\n",
      "Unsupported file format for: Peoplesoft FSCM_R Ahmed.doc\n",
      "Unsupported file format for: React Developer_PavasGoswami.doc\n",
      "Unsupported file format for: React Developer_Vinay Reddy.doc\n",
      "Unsupported file format for: React JS Developer_AnjaniPriyadarshini.doc\n",
      "Unsupported file format for: Nazeer Basha.doc\n",
      "Unsupported file format for: Priyanka L.doc\n",
      "Unsupported file format for: Tatikonda Kiran Kumar.doc\n",
      "Unsupported file format for: Hari Krishna M_Hexaware.doc\n",
      "Unsupported file format for: Harikrishna Akula_Hexaware.doc\n",
      "Unsupported file format for: Hima Mendu_Hexaware.doc\n",
      "Unsupported file format for: J. Sumanth Royal_Hexaware.doc\n",
      "Unsupported file format for: Madeeswar A_Hexaware.doc\n",
      "Unsupported file format for: Naresh Babu Cherukuri_Hexaware.doc\n",
      "Unsupported file format for: Punugoti Swetha_Hexaware.doc\n",
      "Unsupported file format for: ShireeshKumar_Hexaware.doc\n",
      "Unsupported file format for: Sri Krishna S_Hexaware.doc\n",
      "Unsupported file format for: Venkateswarlu B_Hexaware.doc\n",
      "Extraction complete. Data saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes(nlp).csv.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_details_with_nlp(text):\n",
    "    details = {\n",
    "        'Resume Text': text,\n",
    "        'Technical Skills': 'N/A',\n",
    "        'Experience': 0,\n",
    "        'Education': 'N/A',\n",
    "        'Year of Passing': 'N/A'\n",
    "    }\n",
    "    \n",
    "    # Process the text using spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract entities using Named Entity Recognition\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ORG\":  # Organization names\n",
    "            details['Company'] = ent.text\n",
    "        elif ent.label_ == \"DATE\":  # Dates (could include year of passing)\n",
    "            details['Year of Passing'] = ent.text\n",
    "        elif ent.label_ == \"PERSON\":  # Person names (could include applicant name)\n",
    "            details['Applicant Name'] = ent.text\n",
    "\n",
    "    # Additional extraction for skills, experience, and education using regex\n",
    "    skills_match = re.search(r\"(Skills|Technical Skills|Skills:|Technical Skills:)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        details['Technical Skills'] = skills_match.group(2).strip()\n",
    "\n",
    "    experience_match = re.search(r\"(Experience|Exp|Work Experience|Work)[\\s:]*([0-9]+(?:[-+][0-9]+)?\\s?(?:years?|yrs?))\", text, re.IGNORECASE)\n",
    "    if experience_match:\n",
    "        exp_text = experience_match.group(2)\n",
    "        exp_years = re.findall(r'\\d+', exp_text)\n",
    "        if exp_years:\n",
    "            details['Experience'] = int(exp_years[-1])  # Use the last number for experience\n",
    "\n",
    "    education_match = re.search(r\"(Education|Degree|Qualifications)[\\s:]*([A-Za-z0-9 '.]+(?:B\\.?Tech|M\\.?Tech|M\\.?CA|B\\.?E|B\\.?Sc|MBA)?)\", text, re.IGNORECASE)\n",
    "    if education_match:\n",
    "        details['Education'] = education_match.group(2).strip()\n",
    "\n",
    "    return details\n",
    "\n",
    "# Define the path to your resumes folder\n",
    "folder_path = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume'\n",
    "\n",
    "# List to store extracted information\n",
    "resume_data = []\n",
    "\n",
    "# Traverse through the folder and subfolders\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        # Read text based on the file extension\n",
    "        text = ''\n",
    "        try:\n",
    "            if file.lower().endswith('.docx'):\n",
    "                # Read .docx files\n",
    "                doc = Document(file_path)\n",
    "                text = '\\n'.join([para.text for para in doc.paragraphs])\n",
    "            elif file.lower().endswith('.txt'):\n",
    "                # Read .txt files with a fallback for different encodings\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read()\n",
    "            else:\n",
    "                print(f\"Unsupported file format for: {file}\")\n",
    "                continue\n",
    "            \n",
    "            # Extract details from the text using the NLP function\n",
    "            details = extract_details_with_nlp(text)\n",
    "\n",
    "            # Append details with folder name and file name\n",
    "            resume_data.append({\n",
    "                'Folder Name': os.path.basename(root),  # Get the folder name\n",
    "                'File Name': file,                      # Get the file name\n",
    "                **details                                # Unpack details into the dictionary\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file}: {e}\")\n",
    "\n",
    "# Convert extracted data to a pandas DataFrame\n",
    "df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Save the extracted data to a CSV file\n",
    "output_file = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Extracted_Resumes(nlp).csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Extraction complete. Data saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185382e6-4333-44c0-b480-6c041140f072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bde72c9f-7f1a-44ec-8200-d3f2a6f356d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete. Saved to extracted_resume_details.csv.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_details_with_nlp(text):\n",
    "    details = {\n",
    "        'Resume Text': text,\n",
    "        'Technical Skills': 'N/A',\n",
    "        'Experience': 0,\n",
    "        'Education': 'N/A',\n",
    "        'Year of Passing': 'N/A',\n",
    "        'Email': 'N/A',\n",
    "        'Phone Number': 'N/A',\n",
    "        'Location': 'N/A',\n",
    "        'Summary/Objective': 'N/A',\n",
    "        'Certifications': 'N/A',\n",
    "        'Projects': 'N/A',\n",
    "        'Languages': 'N/A',\n",
    "        'Hobbies': 'N/A',\n",
    "        'Company': 'N/A',\n",
    "        'Applicant Name': 'N/A'\n",
    "    }\n",
    "    \n",
    "    # Process the text using spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract entities using Named Entity Recognition\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ORG\":  # Organization names\n",
    "            details['Company'] = ent.text\n",
    "        elif ent.label_ == \"DATE\":  # Dates (could include year of passing)\n",
    "            details['Year of Passing'] = ent.text\n",
    "        elif ent.label_ == \"PERSON\":  # Person names (could include applicant name)\n",
    "            details['Applicant Name'] = ent.text\n",
    "        elif ent.label_ == \"GPE\":  # Geopolitical entity (could represent locations)\n",
    "            details['Location'] = ent.text\n",
    "\n",
    "    # Additional extraction for skills, experience, and education using regex\n",
    "    skills_match = re.search(r\"(Skills|Technical Skills|Skills:|Technical Skills:)[\\s:\\n]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    if skills_match:\n",
    "        details['Technical Skills'] = skills_match.group(2).strip()\n",
    "\n",
    "    experience_match = re.search(r\"(Experience|Exp|Work Experience|Work)[\\s:]*([\\s\\S]+?)(?=\\n\\n|\\Z)\", text, re.IGNORECASE)\n",
    "    if experience_match:\n",
    "        exp_text = experience_match.group(2)\n",
    "        exp_years = re.findall(r'\\d+', exp_text)\n",
    "        if exp_years:\n",
    "            details['Experience'] = int(exp_years[-1])  # Use the last number for experience\n",
    "\n",
    "    education_match = re.search(r\"(Education|Degree|Qualifications)[\\s:]*([\\s\\S]+?)(?=\\n\\n|\\Z)\", text, re.IGNORECASE)\n",
    "    if education_match:\n",
    "        details['Education'] = education_match.group(2).strip()\n",
    "\n",
    "    # Extract email addresses\n",
    "    email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
    "    if email_match:\n",
    "        details['Email'] = email_match.group(0)\n",
    "\n",
    "    # Extract phone numbers (basic pattern)\n",
    "    phone_match = re.search(r'\\+?\\d[\\d -]{7,}\\d', text)  # Adjust as necessary for different formats\n",
    "    if phone_match:\n",
    "        details['Phone Number'] = phone_match.group(0)\n",
    "\n",
    "    # Extract summary/objective\n",
    "    summary_match = re.search(r'(Summary|Objective)[\\s:]*([\\s\\S]*?)(?=\\n\\n|\\Z)', text, re.IGNORECASE)\n",
    "    if summary_match:\n",
    "        details['Summary/Objective'] = summary_match.group(2).strip()\n",
    "\n",
    "    # Extract certifications\n",
    "    cert_match = re.search(r\"(Certifications|Cert)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    if cert_match:\n",
    "        details['Certifications'] = cert_match.group(2).strip()\n",
    "\n",
    "    # Extract languages\n",
    "    lang_match = re.search(r\"(Languages|Language)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    if lang_match:\n",
    "        details['Languages'] = lang_match.group(2).strip()\n",
    "\n",
    "    # Extract hobbies/interests\n",
    "    hobbies_match = re.search(r\"(Hobbies|Interests)[\\s:]*([A-Za-z0-9, ]+)\", text, re.IGNORECASE)\n",
    "    if hobbies_match:\n",
    "        details['Hobbies'] = hobbies_match.group(2).strip()\n",
    "\n",
    "    # Print extracted details for debugging\n",
    "    print(\"Extracted Details:\", details)\n",
    "    \n",
    "    return details\n",
    "\n",
    "# Function to read Word documents\n",
    "def read_word_file(file_path):\n",
    "    doc = Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# Example usage\n",
    "resume_directory = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume'  # Adjust your path\n",
    "resume_details = []\n",
    "\n",
    "for file in os.listdir(resume_directory):\n",
    "    if file.endswith('.docx'):\n",
    "        file_path = os.path.join(resume_directory, file)\n",
    "        resume_text = read_word_file(file_path)\n",
    "        \n",
    "        # Debugging: Print the raw text for each resume\n",
    "        print(f\"Processing file: {file}\\nRaw Text:\\n{resume_text}\\n\")\n",
    "        \n",
    "        details = extract_details_with_nlp(resume_text)\n",
    "        resume_details.append(details)\n",
    "\n",
    "# Convert the extracted details to a DataFrame\n",
    "df = pd.DataFrame(resume_details)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('extracted_resume_details.csv(1)', index=False)\n",
    "\n",
    "print(\"Extraction complete. Saved to extracted_resume_details.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66229aa2-1bae-456d-b994-cc14e006cbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4accaf2a-90e7-416d-90e7-6b77ea89385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume data extraction completed and saved to 'resume_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from docx import Document  # For Word files (.docx)\n",
    "import PyPDF2  # For PDF files\n",
    "\n",
    "# Path to the resume directory\n",
    "resume_dir = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume'\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to extract relevant details (can be modified based on resume structure)\n",
    "def extract_resume_details(text):\n",
    "    # Example patterns to extract information (can be adjusted to fit your resume formats)\n",
    "    experience_years = re.search(r'(\\d+)\\+? years? of experience', text, re.IGNORECASE)\n",
    "    roles = re.findall(r'(developer|manager|analyst|engineer|admin)', text, re.IGNORECASE)  # Modify based on role patterns\n",
    "    skills = re.search(r'Skills:(.*)', text, re.IGNORECASE)\n",
    "    education_degree = re.search(r'(B\\.?Sc|M\\.?Sc|B\\.?Tech|M\\.?Tech|MBA|Ph\\.D)', text, re.IGNORECASE)\n",
    "    education_institution = re.search(r'from ([A-Za-z ]+ University|Institute of Technology)', text, re.IGNORECASE)\n",
    "    education_year = re.search(r'(\\d{4})', text)  # First occurrence of year (can be refined)\n",
    "    job_title = re.search(r'(PeopleSoft Admin|Software Engineer|Data Scientist|HR Manager)', text, re.IGNORECASE)\n",
    "    \n",
    "    # Return extracted fields\n",
    "    return {\n",
    "        'Experience Years': experience_years.group(1) if experience_years else None,\n",
    "        'Experience Roles': ', '.join(set(roles)) if roles else None,\n",
    "        'Skills': skills.group(1).strip() if skills else None,\n",
    "        'Education Degree': education_degree.group(1) if education_degree else None,\n",
    "        'Education Institution': education_institution.group(1) if education_institution else None,\n",
    "        'Education Year': education_year.group(1) if education_year else None,\n",
    "        'Job Title': job_title.group(1) if job_title else None\n",
    "    }\n",
    "\n",
    "# List to store the extracted resume data\n",
    "resume_data = []\n",
    "\n",
    "# Loop through all files in the resume directory\n",
    "for root, dirs, files in os.walk(resume_dir):\n",
    "    for file in files:\n",
    "        # Get file path and name\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_name = os.path.splitext(file)[0]\n",
    "        \n",
    "        # Extract text based on file extension\n",
    "        if file.endswith('.docx'):\n",
    "            resume_text = extract_text_from_docx(file_path)\n",
    "        elif file.endswith('.pdf'):\n",
    "            resume_text = extract_text_from_pdf(file_path)\n",
    "        else:\n",
    "            continue  # Skip non-docx/pdf files\n",
    "        \n",
    "        # Extract resume details\n",
    "        details = extract_resume_details(resume_text)\n",
    "        \n",
    "        # Append the extracted details to resume_data\n",
    "        resume_data.append({\n",
    "            'file_path': file_path,\n",
    "            'file_name': file_name,\n",
    "            **details  # Unpack the extracted details\n",
    "        })\n",
    "\n",
    "# Create a pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('resume_dataset.csv', index=False)\n",
    "\n",
    "print(\"Resume data extraction completed and saved to 'resume_dataset.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dee03c5-47c7-4344-99e6-5b4695de60cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unsupported file format: Extracted_Resumes.csv\n",
      "Skipping unsupported file format: Resumes-Dataset-with-Labels.csv\n",
      "Skipping unsupported file format: Peoplesoft Admin_G Ananda Rayudu.doc\n",
      "Skipping unsupported file format: Peoplesoft Admin_Gangareddy.doc\n",
      "Skipping unsupported file format: Peoplesoft Admin_Priyanka Ramadoss.doc\n",
      "Skipping unsupported file format: Peoplesoft Admin_srinivasarao.doc\n",
      "Skipping unsupported file format: Peoplesoft Admin_Vinod Akkala.doc\n",
      "Skipping unsupported file format: PeopleSoft DBA_Ganesh Alladi.doc\n",
      "Skipping unsupported file format: Peoplesoft Finance_Arun Venu.doc\n",
      "Skipping unsupported file format: Peoplesoft Finance_Pritam Biswas.doc\n",
      "Skipping unsupported file format: Peoplesoft Finance_Rahul Ahuja.doc\n",
      "Skipping unsupported file format: Peoplesoft FSCM_R Ahmed.doc\n",
      "Skipping unsupported file format: React Developer_PavasGoswami.doc\n",
      "Skipping unsupported file format: React Developer_Vinay Reddy.doc\n",
      "Skipping unsupported file format: React JS Developer_AnjaniPriyadarshini.doc\n",
      "Skipping unsupported file format: Nazeer Basha.doc\n",
      "Skipping unsupported file format: Priyanka L.doc\n",
      "Skipping unsupported file format: Tatikonda Kiran Kumar.doc\n",
      "Skipping unsupported file format: Hari Krishna M_Hexaware.doc\n",
      "Skipping unsupported file format: Harikrishna Akula_Hexaware.doc\n",
      "Skipping unsupported file format: Hima Mendu_Hexaware.doc\n",
      "Skipping unsupported file format: J. Sumanth Royal_Hexaware.doc\n",
      "Skipping unsupported file format: Madeeswar A_Hexaware.doc\n",
      "Skipping unsupported file format: Naresh Babu Cherukuri_Hexaware.doc\n",
      "Skipping unsupported file format: Punugoti Swetha_Hexaware.doc\n",
      "Skipping unsupported file format: ShireeshKumar_Hexaware.doc\n",
      "Skipping unsupported file format: Sri Krishna S_Hexaware.doc\n",
      "Skipping unsupported file format: Venkateswarlu B_Hexaware.doc\n",
      "Resume data extraction completed and saved to 'resume_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from docx import Document  # For Word files (.docx)\n",
    "import PyPDF2  # For PDF files\n",
    "\n",
    "# Path to the resume directory\n",
    "resume_dir = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume'\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to extract relevant details (can be modified based on resume structure)\n",
    "def extract_resume_details(text):\n",
    "    # Example patterns to extract information (can be adjusted to fit your resume formats)\n",
    "    experience_years = re.search(r'(\\d+)\\+? years? of experience', text, re.IGNORECASE)\n",
    "    roles = re.findall(r'(developer|manager|analyst|engineer|admin)', text, re.IGNORECASE)  # Modify based on role patterns\n",
    "    skills = re.search(r'Skills:(.*)', text, re.IGNORECASE)\n",
    "    education_degree = re.search(r'(B\\.?Sc|M\\.?Sc|B\\.?Tech|M\\.?Tech|MBA|Ph\\.D)', text, re.IGNORECASE)\n",
    "    education_institution = re.search(r'from ([A-Za-z ]+ University|Institute of Technology)', text, re.IGNORECASE)\n",
    "    education_year = re.search(r'(\\d{4})', text)  # First occurrence of year (can be refined)\n",
    "    job_title = re.search(r'(PeopleSoft Admin|Software Engineer|Data Scientist|HR Manager)', text, re.IGNORECASE)\n",
    "    \n",
    "    # Return extracted fields\n",
    "    return {\n",
    "        'Experience Years': experience_years.group(1) if experience_years else None,\n",
    "        'Experience Roles': ', '.join(set(roles)) if roles else None,\n",
    "        'Skills': skills.group(1).strip() if skills else None,\n",
    "        'Education Degree': education_degree.group(1) if education_degree else None,\n",
    "        'Education Institution': education_institution.group(1) if education_institution else None,\n",
    "        'Education Year': education_year.group(1) if education_year else None,\n",
    "        'Job Title': job_title.group(1) if job_title else None\n",
    "    }\n",
    "\n",
    "# List to store the extracted resume data\n",
    "resume_data = []\n",
    "\n",
    "# Loop through all files in the resume directory\n",
    "for root, dirs, files in os.walk(resume_dir):\n",
    "    folder_name = os.path.basename(root)  # Get folder name\n",
    "    for file in files:\n",
    "        # Get file path and name\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        # Extract text based on file extension\n",
    "        try:\n",
    "            if file.endswith('.docx'):\n",
    "                resume_text = extract_text_from_docx(file_path)\n",
    "            elif file.endswith('.pdf'):\n",
    "                resume_text = extract_text_from_pdf(file_path)\n",
    "            else:\n",
    "                print(f\"Skipping unsupported file format: {file}\")\n",
    "                continue  # Skip non-docx/pdf files\n",
    "\n",
    "            # Extract resume details\n",
    "            details = extract_resume_details(resume_text)\n",
    "\n",
    "            # Append the extracted details to resume_data\n",
    "            resume_data.append({\n",
    "                'file_path': file_path,\n",
    "                'folder_name': folder_name,  # Adding folder name\n",
    "                'resume_text': resume_text,  # Adding resume text\n",
    "                **details  # Unpack the extracted details\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Create a pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('resume_dataset.csv', index=False)\n",
    "\n",
    "print(\"Resume data extraction completed and saved to 'resume_dataset.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84fb1da2-6d1c-455e-96de-701650bf349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume data extraction completed and saved to 'resume_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from docx import Document  # For Word files (.docx)\n",
    "import PyPDF2  # For PDF files\n",
    "import win32com.client  # For .doc files (Windows only)\n",
    "\n",
    "# Path to the resume directory\n",
    "resume_dir = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes'\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to extract text from DOC (using Microsoft Word)\n",
    "def extract_text_from_doc(file_path):\n",
    "    word = win32com.client.Dispatch(\"Word.Application\")\n",
    "    word.Visible = False  # Do not display the Word application\n",
    "    doc = word.Documents.Open(file_path)\n",
    "    text = doc.Content.Text\n",
    "    doc.Close(False)\n",
    "    word.Quit()\n",
    "    return text\n",
    "\n",
    "# Function to extract relevant details (modified based on requirements)\n",
    "def extract_resume_details(text):\n",
    "    # Experience: If not found, set to 0\n",
    "    experience_years = re.search(r'(\\d+)\\+? years? of experience', text, re.IGNORECASE)\n",
    "    experience_years = experience_years.group(1) if experience_years else '0'\n",
    "\n",
    "    # Roles: Extract common roles such as developer, manager, analyst, etc.\n",
    "    roles = re.findall(r'(developer|manager|analyst|engineer|admin)', text, re.IGNORECASE)\n",
    "    roles = ', '.join(set(roles)) if roles else None\n",
    "\n",
    "    # Skills: Try to extract skills after \"Skills:\" or similar wording\n",
    "    skills = re.search(r'Skills:(.*)', text, re.IGNORECASE)\n",
    "    skills = skills.group(1).strip() if skills else None\n",
    "\n",
    "    # Education details\n",
    "    education_degree = re.search(r'(B\\.?Sc|M\\.?Sc|B\\.?Tech|M\\.?Tech|MBA|Ph\\.D)', text, re.IGNORECASE)\n",
    "    education_institution = re.search(r'from ([A-Za-z ]+ University|Institute of Technology)', text, re.IGNORECASE)\n",
    "    education_year = re.search(r'(\\d{4})', text)\n",
    "\n",
    "    return {\n",
    "        'Experience Years': experience_years,\n",
    "        'Experience Roles': roles,\n",
    "        'Skills': skills,\n",
    "        'Education Degree': education_degree.group(1) if education_degree else None,\n",
    "        'Education Institution': education_institution.group(1) if education_institution else None,\n",
    "        'Education Year': education_year.group(1) if education_year else None\n",
    "    }\n",
    "\n",
    "# List to store the extracted resume data\n",
    "resume_data = []\n",
    "\n",
    "# Loop through all files in the resume directory\n",
    "for root, dirs, files in os.walk(resume_dir):\n",
    "    folder_name = os.path.basename(root)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        try:\n",
    "            # Extract text based on file format\n",
    "            if file.endswith('.docx'):\n",
    "                resume_text = extract_text_from_docx(file_path)\n",
    "            elif file.endswith('.doc'):\n",
    "                resume_text = extract_text_from_doc(file_path)\n",
    "            elif file.endswith('.pdf'):\n",
    "                resume_text = extract_text_from_pdf(file_path)\n",
    "            else:\n",
    "                print(f\"Skipping unsupported file format: {file}\")\n",
    "                continue  # Skip unsupported file types\n",
    "\n",
    "            # Extract resume details\n",
    "            details = extract_resume_details(resume_text)\n",
    "\n",
    "            # Append the extracted details to resume_data (excluding Job Title)\n",
    "            resume_data.append({\n",
    "                'file_path': file_path,\n",
    "                'folder_name': folder_name,\n",
    "                'resume_text': resume_text,\n",
    "                **details\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Create a pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Remove the 'Job Title' column (if it exists)\n",
    "if 'Job Title' in df.columns:\n",
    "    df = df.drop(columns=['Job Title'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('resume_dataset.csv', index=False)\n",
    "\n",
    "print(\"Resume data extraction completed and saved to 'resume_dataset.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d9a259c-6762-4fde-aae9-74e27d65d104",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Resume_ID', 'Skills_Section', 'Skills'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m resumes_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(resume_data)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Display the DataFrame with relevant columns\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28mprint\u001b[39m(resumes_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResume_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkills_Section\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkills\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Save the DataFrame to a CSV for future use\u001b[39;00m\n\u001b[0;32m     92\u001b[0m resumes_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDell\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mResume\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mresumes_extracted_skil.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Resume_ID', 'Skills_Section', 'Skills'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import win32com.client as win32\n",
    "import re\n",
    "\n",
    "# Define your skill keywords (expand this list as needed)\n",
    "skill_keywords = [\n",
    "    \"Python\", \"Java\", \"JavaScript\", \"C++\", \"C#\", \"HTML\", \"CSS\",\n",
    "    \"SQL\", \"Data Analysis\", \"Machine Learning\", \"Deep Learning\",\n",
    "    \"Project Management\", \"Team Leadership\", \"Communication\", \n",
    "    \"Excel\", \"Pandas\", \"Numpy\", \"R\", \"Django\", \"Flask\"\n",
    "]\n",
    "\n",
    "# Function to extract text from .docx files\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    return '\\n'.join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# Function to extract text from .doc files\n",
    "def extract_text_from_doc(file_path):\n",
    "    word = win32.gencache.EnsureDispatch('Word.Application')\n",
    "    doc = word.Documents.Open(file_path)\n",
    "    text = doc.Content.Text\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    return text\n",
    "\n",
    "# Function to extract skills directly from the skills section\n",
    "def extract_skills_section(text):\n",
    "    skills_section = ''\n",
    "    \n",
    "    # Look for a 'Skills' section in the text using regex\n",
    "    pattern = r'(?:skills|technical skills|core competencies)(.*?)(?=\\n\\n|\\Z)'\n",
    "    match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        skills_section = match.group(1)\n",
    "    \n",
    "    return skills_section.strip()\n",
    "\n",
    "# Function to parse skills from the skills section\n",
    "def parse_skills(skills_text, skill_keywords):\n",
    "    found_skills = []\n",
    "    skills_text = skills_text.lower()\n",
    "    \n",
    "    # Check for each skill in the list\n",
    "    for skill in skill_keywords:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', skills_text):\n",
    "            found_skills.append(skill)\n",
    "    \n",
    "    return found_skills\n",
    "\n",
    "# Directory containing resumes\n",
    "directory = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes'\n",
    "\n",
    "# Prepare a list to hold resume data\n",
    "resume_data = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.docx'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    elif filename.endswith('.doc'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        text = extract_text_from_doc(file_path)\n",
    "    else:\n",
    "        continue  # Skip non-doc files\n",
    "\n",
    "    # Extract skills section from the text\n",
    "    skills_section = extract_skills_section(text)\n",
    "    \n",
    "    # Parse skills from the skills section\n",
    "    skills = parse_skills(skills_section, skill_keywords)\n",
    "\n",
    "    # Append the resume data including extracted skills\n",
    "    resume_data.append({\n",
    "        'Resume_ID': filename,\n",
    "        'Text': text,\n",
    "        'Skills_Section': skills_section,\n",
    "        'Skills': skills\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "resumes_df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Display the DataFrame with relevant columns\n",
    "print(resumes_df[['Resume_ID', 'Skills_Section', 'Skills']].head())\n",
    "\n",
    "# Save the DataFrame to a CSV for future use\n",
    "resumes_df.to_csv(r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\resumes_extracted_skil.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "006de776-3969-459c-aaff-d4b8fc13db63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: ['Peoplesoft resumes', 'React js', 'SQL Developer Lightning insight', 'workday resumes']\n",
      "DataFrame Columns: RangeIndex(start=0, stop=0, step=1)\n",
      "First few rows of the DataFrame:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import win32com.client as win32\n",
    "import re\n",
    "\n",
    "# Define your skill keywords (expand this list as needed)\n",
    "skill_keywords = [\n",
    "    \"Python\", \"Java\", \"JavaScript\", \"C++\", \"C#\", \"HTML\", \"CSS\",\n",
    "    \"SQL\", \"Data Analysis\", \"Machine Learning\", \"Deep Learning\",\n",
    "    \"Project Management\", \"Team Leadership\", \"Communication\", \n",
    "    \"Excel\", \"Pandas\", \"Numpy\", \"R\", \"Django\", \"Flask\"\n",
    "]\n",
    "\n",
    "# Function to extract text from .docx files\n",
    "def extract_text_from_docx(file_path):\n",
    "    try:\n",
    "        doc = Document(file_path)\n",
    "        return '\\n'.join([para.text for para in doc.paragraphs])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from .doc files\n",
    "def extract_text_from_doc(file_path):\n",
    "    try:\n",
    "        word = win32.gencache.EnsureDispatch('Word.Application')\n",
    "        doc = word.Documents.Open(file_path)\n",
    "        text = doc.Content.Text\n",
    "        doc.Close()\n",
    "        word.Quit()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract skills directly from the skills section\n",
    "def extract_skills_section(text):\n",
    "    skills_section = ''\n",
    "    \n",
    "    # Look for a 'Skills' section in the text using regex\n",
    "    pattern = r'(?:skills|technical skills|core competencies)(.*?)(?=\\n\\n|\\Z)'\n",
    "    match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        skills_section = match.group(1)\n",
    "    \n",
    "    return skills_section.strip()\n",
    "\n",
    "# Function to parse skills from the skills section\n",
    "def parse_skills(skills_text, skill_keywords):\n",
    "    found_skills = []\n",
    "    skills_text = skills_text.lower()\n",
    "    \n",
    "    # Check for each skill in the list\n",
    "    for skill in skill_keywords:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', skills_text):\n",
    "            found_skills.append(skill)\n",
    "    \n",
    "    return found_skills\n",
    "\n",
    "# Directory containing resumes\n",
    "directory = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes'\n",
    "\n",
    "# Debug: Check files in directory\n",
    "print(\"Files in directory:\", os.listdir(directory))\n",
    "\n",
    "# Prepare a list to hold resume data\n",
    "resume_data = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.docx'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        text = extract_text_from_docx(file_path)\n",
    "        print(f\"Extracted from {filename}: {text[:100]}...\")  # Print first 100 characters\n",
    "    elif filename.endswith('.doc'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        text = extract_text_from_doc(file_path)\n",
    "        print(f\"Extracted from {filename}: {text[:100]}...\")  # Print first 100 characters\n",
    "    else:\n",
    "        continue  # Skip non-doc files\n",
    "\n",
    "    # Extract skills section from the text\n",
    "    skills_section = extract_skills_section(text)\n",
    "    print(f\"Skills Section for {filename}: {skills_section}\")  # Debug print\n",
    "\n",
    "    # Parse skills from the skills section\n",
    "    skills = parse_skills(skills_section, skill_keywords)\n",
    "    print(f\"Skills Found for {filename}: {skills}\")  # Debug print\n",
    "\n",
    "    # Append the resume data including extracted skills\n",
    "    resume_data.append({\n",
    "        'Resume_ID': filename,\n",
    "        'Text': text,\n",
    "        'Skills_Section': skills_section,\n",
    "        'Skills': skills\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "resumes_df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Check the columns in the DataFrame to debug\n",
    "print(\"DataFrame Columns:\", resumes_df.columns)\n",
    "print(\"First few rows of the DataFrame:\\n\", resumes_df.head())  # Display the first few rows to see the data\n",
    "\n",
    "# Save the DataFrame to a CSV for future use\n",
    "resumes_df.to_csv(r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\resumes_extracted_skills.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7328b1-d815-4826-b278-170f95d07e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import win32com.client as win32\n",
    "import re\n",
    "\n",
    "# Define your skill keywords (expand this list as needed)\n",
    "skill_keywords = [\n",
    "    \"Python\", \"Java\", \"JavaScript\", \"C++\", \"C#\", \"HTML\", \"CSS\",\n",
    "    \"SQL\", \"Data Analysis\", \"Machine Learning\", \"Deep Learning\",\n",
    "    \"Project Management\", \"Team Leadership\", \"Communication\", \n",
    "    \"Excel\", \"Pandas\", \"Numpy\", \"R\", \"Django\", \"Flask\"\n",
    "]\n",
    "\n",
    "# Function to extract text from .docx files\n",
    "def extract_text_from_docx(file_path):\n",
    "    try:\n",
    "        doc = Document(file_path)\n",
    "        return '\\n'.join([para.text for para in doc.paragraphs])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from .doc files\n",
    "def extract_text_from_doc(file_path):\n",
    "    try:\n",
    "        word = win32.gencache.EnsureDispatch('Word.Application')\n",
    "        doc = word.Documents.Open(file_path)\n",
    "        text = doc.Content.Text\n",
    "        doc.Close()\n",
    "        word.Quit()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract skills directly from the skills section\n",
    "def extract_skills_section(text):\n",
    "    skills_section = ''\n",
    "    \n",
    "    # Look for a 'Skills' section in the text using regex\n",
    "    pattern = r'(?:skills|technical skills|core competencies)(.*?)(?=\\n\\n|\\Z)'\n",
    "    match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        skills_section = match.group(1)\n",
    "    \n",
    "    return skills_section.strip()\n",
    "\n",
    "# Function to parse skills from the skills section\n",
    "def parse_skills(skills_text, skill_keywords):\n",
    "    found_skills = []\n",
    "    skills_text = skills_text.lower()\n",
    "    \n",
    "    # Check for each skill in the list\n",
    "    for skill in skill_keywords:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', skills_text):\n",
    "            found_skills.append(skill)\n",
    "    \n",
    "    return found_skills\n",
    "\n",
    "# Function to extract experience, education, and year of passing\n",
    "def extract_experience_education(text):\n",
    "    experience = re.findall(r'(?i)(?<=experience)(.*?)(?=\\n\\n|\\Z)', text, re.DOTALL)\n",
    "    education = re.findall(r'(?i)(?<=education)(.*?)(?=\\n\\n|\\Z)', text, re.DOTALL)\n",
    "    year_of_passing = re.findall(r'(?i)(\\d{4})', text)  # Extract any 4-digit number\n",
    "\n",
    "    return experience[0].strip() if experience else '', education[0].strip() if education else '', year_of_passing[-1] if year_of_passing else ''\n",
    "\n",
    "# Directory containing resumes\n",
    "main_directory = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes'\n",
    "\n",
    "# Prepare a list to hold resume data\n",
    "resume_data = []\n",
    "\n",
    "# Loop through all directories and files in the main directory\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.docx'):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            text = extract_text_from_docx(file_path)\n",
    "        elif filename.endswith('.doc'):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            text = extract_text_from_doc(file_path)\n",
    "        else:\n",
    "            continue  # Skip non-doc files\n",
    "\n",
    "        # Extract skills section from the text\n",
    "        skills_section = extract_skills_section(text)\n",
    "\n",
    "        # Parse skills from the skills section\n",
    "        skills = parse_skills(skills_section, skill_keywords)\n",
    "\n",
    "        # Extract experience, education, and year of passing\n",
    "        experience, education, year_of_passing = extract_experience_education(text)\n",
    "\n",
    "        # Append the resume data including extracted details\n",
    "        resume_data.append({\n",
    "            'Folder_Name': os.path.basename(root),\n",
    "            'File_Path': file_path,\n",
    "            'Skills_Section': skills_section,\n",
    "            'Skills': skills,\n",
    "            'Experience': experience,\n",
    "            'Education': education,\n",
    "            'Year_of_Passing': year_of_passing\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "resumes_df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Check the columns in the DataFrame to debug\n",
    "print(\"DataFrame Columns:\", resumes_df.columns)\n",
    "print(\"First few rows of the DataFrame:\\n\", resumes_df.head())  # Display the first few rows to see the data\n",
    "\n",
    "# Save the DataFrame to a CSV for future use\n",
    "resumes_df.to_csv(r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\resumes_extracted_details.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ee9dc-1ff1-41d6-aa45-f1a3ca540367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946932e1-ed90-4ab5-9c0c-490849e2c0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textract\n",
      "  Using cached textract-1.6.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached textract-1.6.4.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring version 1.6.5 of textract since it has invalid metadata:\n",
      "Requested textract from https://files.pythonhosted.org/packages/6b/3e/ac16b6bf28edf78296aea7d0cb416b49ed30282ac8c711662541015ee6f3/textract-1.6.5-py3-none-any.whl has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    extract-msg (<=0.29.*)\n",
      "                 ~~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [1 lines of output]\n",
      "  ERROR: Can not execute `setup.py` since setuptools is not available in the build environment.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install textract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62cdde8f-bdf8-4f08-b0a7-393da405d0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resumes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Resumes: 100%|█████████████████████████████████████████████████████████████████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported file format: extracted_resumes_data(new).csv\n",
      "Unsupported file format: extracted_resumes_data(new_1).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  17%|████████▌                                        | 4/23 [00:00<00:02,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_G Ananda Rayudu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Gangareddy.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Priyanka Ramadoss.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  26%|████████████▊                                    | 6/23 [00:00<00:02,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_srinivasarao.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  35%|█████████████████                                | 8/23 [00:01<00:02,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Vinod Akkala.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from PeopleSoft DBA_Ganesh Alladi.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  65%|███████████████████████████████▎                | 15/23 [00:02<00:00,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Arun Venu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Pritam Biswas.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Rahul Ahuja.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  83%|███████████████████████████████████████▋        | 19/23 [00:02<00:00,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft FSCM_R Ahmed.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes: 100%|████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ~$oplesoft Admin_Gangareddy.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ~$oplesoft Admin_Priyanka Ramadoss.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx'\n",
      "No text extracted from ~$oplesoft Admin_Varkala Vikas.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  33%|███████████████████▋                                       | 8/24 [00:00<00:01, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React Developer_PavasGoswami.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  50%|█████████████████████████████                             | 12/24 [00:01<00:01, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React Developer_Vinay Reddy.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  58%|█████████████████████████████████▊                        | 14/24 [00:01<00:00, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React JS Developer_AnjaniPriyadarshini.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js: 100%|██████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.43it/s]\n",
      "Processing in SQL Developer Lightning insight:  40%|██████████████▍                     | 6/15 [00:00<00:00, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Nazeer Basha.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight:  53%|███████████████████▏                | 8/15 [00:00<00:00, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Priyanka L.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight: 100%|███████████████████████████████████| 15/15 [00:01<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Tatikonda Kiran Kumar.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx'\n",
      "No text extracted from ~$mballapradeep.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  27%|██████████████▏                                     | 6/22 [00:00<00:01, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Hari Krishna M_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Harikrishna Akula_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Hima Mendu_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from J. Sumanth Royal_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  36%|██████████████████▉                                 | 8/22 [00:00<00:01, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Madeeswar A_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  45%|███████████████████████▏                           | 10/22 [00:00<00:01, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Naresh Babu Cherukuri_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  55%|███████████████████████████▊                       | 12/22 [00:01<00:00, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Punugoti Swetha_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  82%|█████████████████████████████████████████▋         | 18/22 [00:01<00:00, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ShireeshKumar_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Sri Krishna S_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  95%|████████████████████████████████████████████████▋  | 21/22 [00:02<00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Venkateswarlu B_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes: 100%|███████████████████████████████████████████████████| 22/22 [00:02<00:00,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx'\n",
      "No text extracted from ~$oraboyinaGuravaiah_Hexaware.docx\n",
      "\n",
      "Extracted Resume Data:\n",
      "                                  file_name         folder_name  \\\n",
      "0        Peoplesoft Admin_AnubhavSingh.docx  Peoplesoft resumes   \n",
      "1              Peoplesoft Admin_Murali.docx  Peoplesoft resumes   \n",
      "2  Peoplesoft Admin_SirazuddinMohammad.docx  Peoplesoft resumes   \n",
      "3       Peoplesoft Admin_Varkala Vikas.docx  Peoplesoft resumes   \n",
      "4     PeopleSoft DBA_Vivekanand Sayana.docx  Peoplesoft resumes   \n",
      "\n",
      "                                         resume_text  experience_years  \\\n",
      "0  Anubhav Kumar Singh\\t\\t   To work in a globall...                 0   \n",
      "1  Murali Experience Summary  I have 6 years of e...                 6   \n",
      "2  PROFILE SUMMARY I have overall 6.8 years’ expe...                 0   \n",
      "3  PeopleSoft Admin VARKALA VIKAS Career Objectiv...                 2   \n",
      "4  PeopleSoft Administration   Vivekanand Sayana ...                 5   \n",
      "\n",
      "                                     experience_role  \\\n",
      "0  PeopleSoft Internet Architecture; Technical/De...   \n",
      "1                                         Developers   \n",
      "2  PeopleSoft Internet Architecture; Engineering;...   \n",
      "3  developers; internal consistency; PeopleSoft d...   \n",
      "4  architecture; Associate - PeopleSoft Administr...   \n",
      "\n",
      "                                              skills  \n",
      "0  peoplesoft fscm, integration, oracle database,...  \n",
      "1  data mover, integration, application designer,...  \n",
      "2  data mover, integration, application designer,...  \n",
      "3  data mover, integration, application designer,...  \n",
      "4  data mover, integration, application designer,...  \n",
      "\n",
      "Extracted resume data saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Extracted_Resumes(new_2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import docx\n",
    "from PyPDF2 import PdfReader\n",
    "import textract\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize spaCy and download necessary models\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print(\"Downloading 'en_core_web_sm' model for spaCy...\")\n",
    "    from spacy.cli import download\n",
    "    download('en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the directory containing resumes\n",
    "RESUME_DIR = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes'\n",
    "\n",
    "# Define a list of common skills (extend this list as needed)\n",
    "COMMON_SKILLS = [\n",
    "    # PeopleSoft and Workday Specific Skills\n",
    "    'PeopleSoft HRMS', 'PeopleSoft FSCM', 'PeopleSoft CRM', \n",
    "    'PeopleSoft HCM', 'PeopleSoft Portal', 'PeopleTools', \n",
    "    'Integration Broker', 'Application Designer', 'PeopleSoft Update Manager', \n",
    "    'Data Mover', 'Workday HCM', 'Core HR', 'Benefits', \n",
    "    'Compensation', 'Time Tracking', 'Absence Management', \n",
    "    'Calculated Fields', 'EIB Inbound', 'EIB Outbound', \n",
    "    'Core Connectors', 'Studio', 'XML', 'XSLT', \n",
    "    'SOAP', 'REST', 'Reporting', 'Integration', \n",
    "    'Business Objects', 'Change Deduction',\n",
    "\n",
    "    # Technical Skills\n",
    "    'SQL', 'T-SQL', 'SSIS', 'MySQL', \n",
    "    'MS SQL Server', 'SQL Server 2012', 'SQL Server 2016', \n",
    "    'Oracle Database', 'Oracle 10gR2', 'Oracle 11gR2', \n",
    "    'Oracle 12c', 'Oracle Enterprise Linux', \n",
    "    'Windows Server 2003', 'Windows Server 2008R2', \n",
    "    'Windows Server 2012', 'HP-UX 11.31',\n",
    "    'Unix/Linux', 'Shell Scripting', 'Active Directory', \n",
    "\n",
    "    # Reporting and ETL Tools\n",
    "    'SQL Server Analysis Services', 'SQL Server Integration Services', \n",
    "    'SQL Server Reporting Services', 'Report Builder', \n",
    "    'Crystal Reports', 'XML Publisher', 'Report Writer',\n",
    "    'Power BI', 'Tableau', 'QlikView',\n",
    "\n",
    "    # Programming Languages\n",
    "    'Java', 'Python', 'C++', 'JavaScript', 'React', \n",
    "    'Node.js', 'Django', 'Flask', 'Ruby', \n",
    "    'Go', 'Scala', 'Swift', 'C#', 'PHP', \n",
    "    'R', 'MATLAB', 'TypeScript', 'Bash', \n",
    "    'HTML', 'CSS',\n",
    "\n",
    "    # Data and Cloud Technologies\n",
    "    'Machine Learning', 'Data Science', 'Data Analysis', \n",
    "    'Data Visualization', 'Tableau', 'Spark', 'AWS', \n",
    "    'Docker', 'Kubernetes', 'NoSQL', 'MongoDB', \n",
    "    'PostgreSQL', 'REST API', 'GraphQL', \n",
    "    'Azure', 'Google Cloud Platform', 'Data Warehousing', \n",
    "    'ETL Processes',\n",
    "\n",
    "    # Soft Skills\n",
    "    'Communication', 'Leadership', 'Project Management', \n",
    "    'Change Management', 'Performance Tuning', \n",
    "    'Backup and Recovery', 'Security Management', \n",
    "    'Understanding of HR Processes', 'Data Modeling', \n",
    "    'User Interface Design', 'Analytical Thinking', \n",
    "    'Problem Solving', 'Team Collaboration', \n",
    "    'Agile Methodologies', 'Customer Relationship Management (CRM)',\n",
    "    \n",
    "    # Additional Skills\n",
    "    'API Development', 'User Acceptance Testing (UAT)', \n",
    "    'Version Control (Git)', 'Continuous Integration/Continuous Deployment (CI/CD)', \n",
    "    'Business Process Reengineering', 'Regulatory Compliance', \n",
    "    'Quality Assurance', 'Systems Analysis', \n",
    "    'Digital Transformation', 'Training and Development',\n",
    "    'Stakeholder Management', 'Documentation Skills'\n",
    "]\n",
    "\n",
    "# Preprocess skills for matching\n",
    "COMMON_SKILLS = [skill.lower() for skill in COMMON_SKILLS]\n",
    "\n",
    "# Function to extract text from PDF using PyPDF2\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting PDF {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOCX using python-docx\n",
    "def extract_text_from_docx(docx_path):\n",
    "    try:\n",
    "        doc = docx.Document(docx_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs if para.text])\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOCX {docx_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOC using textract\n",
    "def extract_text_from_doc(doc_path):\n",
    "    try:\n",
    "        text = textract.process(doc_path).decode('utf-8')\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOC {doc_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract experience years using regex\n",
    "def extract_experience_years(text):\n",
    "    # Patterns like \"5 years of experience\", \"5+ years\", \"five years experience\"\n",
    "    patterns = [\n",
    "        r'(\\d+)\\+?\\s+years? of experience',\n",
    "        r'(\\d+)\\+?\\s+years? experience',\n",
    "        r'(\\d+)\\+?\\s+yrs? experience',\n",
    "        r'(\\d+)\\+?\\s+years? working',\n",
    "        r'(\\d+)\\+?\\s+years? in the industry'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text.lower())\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    return 0\n",
    "\n",
    "# Function to extract skills\n",
    "def extract_skills(text):\n",
    "    text = text.lower()\n",
    "    skills_found = set()\n",
    "    for skill in COMMON_SKILLS:\n",
    "        # Use word boundaries to match whole words\n",
    "        if re.search(r'\\b' + re.escape(skill) + r'\\b', text):\n",
    "            skills_found.add(skill)\n",
    "    return \", \".join(skills_found) if skills_found else \"None\"\n",
    "\n",
    "# Function to extract experience roles using spaCy's noun chunks\n",
    "def extract_experience_roles(text):\n",
    "    doc = nlp(text)\n",
    "    roles = set()\n",
    "    # Define keywords that often precede job titles\n",
    "    role_keywords = ['software engineer', 'data scientist', 'developer', 'manager', \n",
    "                     'analyst', 'consultant', 'intern', 'engineer', 'specialist', \n",
    "                     'director', 'lead', 'administrator', 'architect']\n",
    "    \n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_text = chunk.text.lower()\n",
    "        for keyword in role_keywords:\n",
    "            if keyword in chunk_text:\n",
    "                roles.add(chunk.text.strip())\n",
    "    \n",
    "    return \"; \".join(roles) if roles else \"None\"\n",
    "\n",
    "# Function to extract all required information from resume text\n",
    "def parse_resume(text):\n",
    "    experience_years = extract_experience_years(text)\n",
    "    skills = extract_skills(text)\n",
    "    experience_roles = extract_experience_roles(text)\n",
    "    return experience_years, experience_roles, skills\n",
    "\n",
    "# Initialize a list to hold all resume data\n",
    "resume_data = []\n",
    "\n",
    "# Traverse the directory and process each resume file\n",
    "print(\"Processing resumes...\")\n",
    "for root, dirs, files in os.walk(RESUME_DIR):\n",
    "    folder_name = os.path.basename(root)\n",
    "    for file in tqdm(files, desc=f\"Processing in {folder_name}\"):\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_extension = os.path.splitext(file)[1].lower()\n",
    "        resume_text = \"\"\n",
    "        \n",
    "        # Check for file types and extract text accordingly\n",
    "        if file_extension == '.pdf':\n",
    "            resume_text = extract_text_from_pdf(file_path)\n",
    "        elif file_extension == '.docx':\n",
    "            resume_text = extract_text_from_docx(file_path)\n",
    "        elif file_extension == '.doc':\n",
    "            resume_text = extract_text_from_doc(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file}\")\n",
    "            continue  # Skip unsupported formats\n",
    "        \n",
    "        # Handle cases with no text extracted\n",
    "        if not resume_text.strip():\n",
    "            print(f\"No text extracted from {file}\")\n",
    "            continue  # Skip if no text extracted\n",
    "        \n",
    "        # Parse the resume for experience, roles, and skills\n",
    "        experience_years, experience_roles, skills = parse_resume(resume_text)\n",
    "        \n",
    "        # Create an entry for the resume data\n",
    "        resume_entry = {\n",
    "            'file_name': file,\n",
    "            'folder_name': folder_name,\n",
    "            'resume_text': resume_text.replace('\\n', ' ').strip(),\n",
    "            'experience_years': experience_years,\n",
    "            'experience_role': experience_roles,\n",
    "            'skills': skills\n",
    "        }\n",
    "        \n",
    "        resume_data.append(resume_entry)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(resume_data, columns=[\n",
    "    'file_name',\n",
    "    'folder_name',\n",
    "    'resume_text',\n",
    "    'experience_years',\n",
    "    'experience_role',\n",
    "    'skills'\n",
    "])\n",
    "\n",
    "# Display the first few entries\n",
    "print(\"\\nExtracted Resume Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Extracted_Resumes(new_2).csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nExtracted resume data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e00cdc-6480-40ae-b2ff-a33c6dc722e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processing file: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caa3ff84-17e4-499c-9f03-173ed2c132c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 22 files in workday resumes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes: 100%|████████████████████████████████████████████████| 22/22 [00:00<00:00, 22075.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No text extracted from ChinnaSubbarayuduM_Hexaware.docx. Skipping...\n",
      "No text extracted from Gopi Krishna_Hexaware.docx. Skipping...\n",
      "No text extracted from Hari Krishna M_Hexaware.doc. Skipping...\n",
      "No text extracted from Harikrishna Akula_Hexaware.doc. Skipping...\n",
      "No text extracted from Hima Mendu_Hexaware.doc. Skipping...\n",
      "No text extracted from Himaja G_(Hexaware).docx. Skipping...\n",
      "No text extracted from J. Sumanth Royal_Hexaware.doc. Skipping...\n",
      "No text extracted from Jyotiverma_Heaware.docx. Skipping...\n",
      "No text extracted from Madeeswar A_Hexaware.doc. Skipping...\n",
      "No text extracted from MooraboyinaGuravaiah_Hexaware.docx. Skipping...\n",
      "No text extracted from Naresh Babu Cherukuri_Hexaware.doc. Skipping...\n",
      "No text extracted from P V Sai Krishna_ Hexaware.docx. Skipping...\n",
      "No text extracted from Punugoti Swetha_Hexaware.doc. Skipping...\n",
      "No text extracted from RahulM_Hexaware.docx. Skipping...\n",
      "No text extracted from RameshP_Hexaware.docx. Skipping...\n",
      "No text extracted from ShireeshKumar_Hexaware.doc. Skipping...\n",
      "No text extracted from Sri Krishna S_Hexaware.doc. Skipping...\n",
      "No text extracted from Srikanth-Hexaware.docx. Skipping...\n",
      "No text extracted from SSKumar_Hexaware.docx. Skipping...\n",
      "No text extracted from Venkateswarlu B_Hexaware.doc. Skipping...\n",
      "No text extracted from Vinay Kumar_Hexaware.docx. Skipping...\n",
      "No text extracted from ~$oraboyinaGuravaiah_Hexaware.docx. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processing {len(files)} files in {folder_name}...\")\n",
    "for file in tqdm(files, desc=f\"Processing in {folder_name}\"):\n",
    "    ...\n",
    "    if resume_text.strip() == \"\":\n",
    "        print(f\"No text extracted from {file}. Skipping...\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Successfully extracted text from {file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68d98327-88fe-4553-a251-b61b89279580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resumes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Resumes: 100%|████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 674.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported file format: extracted_resumes_data(new).csv\n",
      "Unsupported file format: extracted_resumes_data(new_1).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:   4%|██▏                                              | 1/23 [00:00<00:09,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_G Ananda Rayudu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Gangareddy.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  17%|████████▌                                        | 4/23 [00:00<00:02,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Priyanka Ramadoss.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  26%|████████████▊                                    | 6/23 [00:00<00:02,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_srinivasarao.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  35%|█████████████████                                | 8/23 [00:01<00:02,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Vinod Akkala.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from PeopleSoft DBA_Ganesh Alladi.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  48%|██████████████████████▉                         | 11/23 [00:02<00:02,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Arun Venu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Pritam Biswas.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Rahul Ahuja.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  83%|███████████████████████████████████████▋        | 19/23 [00:02<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft FSCM_R Ahmed.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes: 100%|████████████████████████████████████████████████| 23/23 [00:03<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ~$oplesoft Admin_Gangareddy.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ~$oplesoft Admin_Priyanka Ramadoss.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx'\n",
      "No text extracted from ~$oplesoft Admin_Varkala Vikas.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  33%|███████████████████▋                                       | 8/24 [00:01<00:01,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React Developer_PavasGoswami.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  50%|█████████████████████████████                             | 12/24 [00:01<00:01,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React Developer_Vinay Reddy.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  54%|███████████████████████████████▍                          | 13/24 [00:01<00:01,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React JS Developer_AnjaniPriyadarshini.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js: 100%|██████████████████████████████████████████████████████████| 24/24 [00:03<00:00,  7.18it/s]\n",
      "Processing in SQL Developer Lightning insight:  27%|█████████▌                          | 4/15 [00:00<00:01,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Nazeer Basha.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight:  60%|█████████████████████▌              | 9/15 [00:01<00:00,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Priyanka L.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight: 100%|███████████████████████████████████| 15/15 [00:02<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Tatikonda Kiran Kumar.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx'\n",
      "No text extracted from ~$mballapradeep.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  25%|█████████████                                       | 6/24 [00:00<00:01, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Hari Krishna M_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Harikrishna Akula_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Hima Mendu_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  33%|█████████████████▎                                  | 8/24 [00:00<00:01, 12.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from J. Sumanth Royal_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Madeeswar A_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  50%|█████████████████████████▌                         | 12/24 [00:01<00:01, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Naresh Babu Cherukuri_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Punugoti Swetha_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  62%|███████████████████████████████▉                   | 15/24 [00:01<00:01,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ShireeshKumar_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Sri Krishna S_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes: 100%|███████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Venkateswarlu B_Hexaware.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx'\n",
      "No text extracted from ~$innaSubbarayuduM_Hexaware.docx\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx'\n",
      "No text extracted from ~$oraboyinaGuravaiah_Hexaware.docx\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx'\n",
      "No text extracted from ~$pi Krishna_Hexaware.docx\n",
      "\n",
      "Extracted Resume Data:\n",
      "                                  file_name         folder_name  \\\n",
      "0        Peoplesoft Admin_AnubhavSingh.docx  Peoplesoft resumes   \n",
      "1              Peoplesoft Admin_Murali.docx  Peoplesoft resumes   \n",
      "2  Peoplesoft Admin_SirazuddinMohammad.docx  Peoplesoft resumes   \n",
      "3       Peoplesoft Admin_Varkala Vikas.docx  Peoplesoft resumes   \n",
      "4     PeopleSoft DBA_Vivekanand Sayana.docx  Peoplesoft resumes   \n",
      "\n",
      "                                         resume_text  experience_years  \\\n",
      "0  Anubhav Kumar Singh\\t\\t   To work in a globall...                 0   \n",
      "1  Murali Experience Summary  I have 6 years of e...                 6   \n",
      "2  PROFILE SUMMARY I have overall 6.8 years’ expe...                 0   \n",
      "3  PeopleSoft Admin VARKALA VIKAS Career Objectiv...                 2   \n",
      "4  PeopleSoft Administration   Vivekanand Sayana ...                 5   \n",
      "\n",
      "                                     experience_role  \\\n",
      "0  PeopleSoft Internet Architecture; Technical/De...   \n",
      "1                                         Developers   \n",
      "2  PeopleSoft Internet Architecture; Engineering;...   \n",
      "3  developers; internal consistency; PeopleSoft d...   \n",
      "4  architecture; Associate - PeopleSoft Administr...   \n",
      "\n",
      "                                              skills  \n",
      "0  peoplesoft fscm, integration, oracle database,...  \n",
      "1  data mover, integration, application designer,...  \n",
      "2  data mover, integration, application designer,...  \n",
      "3  data mover, integration, application designer,...  \n",
      "4  data mover, integration, application designer,...  \n",
      "\n",
      "Extracted resume data saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Extracted_Resumes(new_3).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import docx\n",
    "from PyPDF2 import PdfReader\n",
    "import textract\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize spaCy and download necessary models\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print(\"Downloading 'en_core_web_sm' model for spaCy...\")\n",
    "    from spacy.cli import download\n",
    "    download('en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the directory containing resumes\n",
    "RESUME_DIR = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes'\n",
    "\n",
    "# Define a list of common skills (extend this list as needed)\n",
    "COMMON_SKILLS = [\n",
    "    # PeopleSoft and Workday Specific Skills\n",
    "    'PeopleSoft HRMS', 'PeopleSoft FSCM', 'PeopleSoft CRM', \n",
    "    'PeopleSoft HCM', 'PeopleSoft Portal', 'PeopleTools', \n",
    "    'Integration Broker', 'Application Designer', 'PeopleSoft Update Manager', \n",
    "    'Data Mover', 'Workday HCM', 'Core HR', 'Benefits', \n",
    "    'Compensation', 'Time Tracking', 'Absence Management', \n",
    "    'Calculated Fields', 'EIB Inbound', 'EIB Outbound', \n",
    "    'Core Connectors', 'Studio', 'XML', 'XSLT', \n",
    "    'SOAP', 'REST', 'Reporting', 'Integration', \n",
    "    'Business Objects', 'Change Deduction',\n",
    "\n",
    "    # Technical Skills\n",
    "    'SQL', 'T-SQL', 'SSIS', 'MySQL', \n",
    "    'MS SQL Server', 'SQL Server 2012', 'SQL Server 2016', \n",
    "    'Oracle Database', 'Oracle 10gR2', 'Oracle 11gR2', \n",
    "    'Oracle 12c', 'Oracle Enterprise Linux', \n",
    "    'Windows Server 2003', 'Windows Server 2008R2', \n",
    "    'Windows Server 2012', 'HP-UX 11.31',\n",
    "    'Unix/Linux', 'Shell Scripting', 'Active Directory', \n",
    "\n",
    "    # Reporting and ETL Tools\n",
    "    'SQL Server Analysis Services', 'SQL Server Integration Services', \n",
    "    'SQL Server Reporting Services', 'Report Builder', \n",
    "    'Crystal Reports', 'XML Publisher', 'Report Writer',\n",
    "    'Power BI', 'Tableau', 'QlikView',\n",
    "\n",
    "    # Programming Languages\n",
    "    'Java', 'Python', 'C++', 'JavaScript', 'React', \n",
    "    'Node.js', 'Django', 'Flask', 'Ruby', \n",
    "    'Go', 'Scala', 'Swift', 'C#', 'PHP', \n",
    "    'R', 'MATLAB', 'TypeScript', 'Bash', \n",
    "    'HTML', 'CSS',\n",
    "\n",
    "    # Data and Cloud Technologies\n",
    "    'Machine Learning', 'Data Science', 'Data Analysis', \n",
    "    'Data Visualization', 'Tableau', 'Spark', 'AWS', \n",
    "    'Docker', 'Kubernetes', 'NoSQL', 'MongoDB', \n",
    "    'PostgreSQL', 'REST API', 'GraphQL', \n",
    "    'Azure', 'Google Cloud Platform', 'Data Warehousing', \n",
    "    'ETL Processes',\n",
    "\n",
    "    # Soft Skills\n",
    "    'Communication', 'Leadership', 'Project Management', \n",
    "    'Change Management', 'Performance Tuning', \n",
    "    'Backup and Recovery', 'Security Management', \n",
    "    'Understanding of HR Processes', 'Data Modeling', \n",
    "    'User Interface Design', 'Analytical Thinking', \n",
    "    'Problem Solving', 'Team Collaboration', \n",
    "    'Agile Methodologies', 'Customer Relationship Management (CRM)',\n",
    "    \n",
    "    # Additional Skills\n",
    "    'API Development', 'User Acceptance Testing (UAT)', \n",
    "    'Version Control (Git)', 'Continuous Integration/Continuous Deployment (CI/CD)', \n",
    "    'Business Process Reengineering', 'Regulatory Compliance', \n",
    "    'Quality Assurance', 'Systems Analysis', \n",
    "    'Digital Transformation', 'Training and Development',\n",
    "    'Stakeholder Management', 'Documentation Skills'\n",
    "]\n",
    "\n",
    "# Preprocess skills for matching\n",
    "COMMON_SKILLS = [skill.lower() for skill in COMMON_SKILLS]\n",
    "\n",
    "# Function to extract text from PDF using PyPDF2\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting PDF {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOCX using python-docx\n",
    "def extract_text_from_docx(docx_path):\n",
    "    try:\n",
    "        doc = docx.Document(docx_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs if para.text])\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOCX {docx_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOC using textract\n",
    "def extract_text_from_doc(doc_path):\n",
    "    try:\n",
    "        text = textract.process(doc_path).decode('utf-8')\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOC {doc_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract experience years using regex\n",
    "def extract_experience_years(text):\n",
    "    patterns = [\n",
    "        r'(\\d+)\\+?\\s+years? of experience',\n",
    "        r'(\\d+)\\+?\\s+years? experience',\n",
    "        r'(\\d+)\\+?\\s+yrs? experience',\n",
    "        r'(\\d+)\\+?\\s+years? working',\n",
    "        r'(\\d+)\\+?\\s+years? in the industry'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text.lower())\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    return 0\n",
    "\n",
    "# Function to extract skills\n",
    "def extract_skills(text):\n",
    "    text = text.lower()\n",
    "    skills_found = {skill for skill in COMMON_SKILLS if re.search(r'\\b' + re.escape(skill) + r'\\b', text)}\n",
    "    return \", \".join(skills_found) if skills_found else \"None\"\n",
    "\n",
    "# Function to extract experience roles using spaCy's noun chunks\n",
    "def extract_experience_roles(text):\n",
    "    doc = nlp(text)\n",
    "    roles = set()\n",
    "    role_keywords = ['software engineer', 'data scientist', 'developer', 'manager', \n",
    "                     'analyst', 'consultant', 'intern', 'engineer', 'specialist', \n",
    "                     'director', 'lead', 'administrator', 'architect']\n",
    "    \n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_text = chunk.text.lower()\n",
    "        for keyword in role_keywords:\n",
    "            if keyword in chunk_text:\n",
    "                roles.add(chunk.text.strip())\n",
    "    \n",
    "    return \"; \".join(roles) if roles else \"None\"\n",
    "\n",
    "# Function to extract all required information from resume text\n",
    "def parse_resume(text):\n",
    "    experience_years = extract_experience_years(text)\n",
    "    skills = extract_skills(text)\n",
    "    experience_roles = extract_experience_roles(text)\n",
    "    return experience_years, experience_roles, skills\n",
    "\n",
    "# Initialize a list to hold all resume data\n",
    "resume_data = []\n",
    "\n",
    "# Traverse the directory and process each resume file\n",
    "print(\"Processing resumes...\")\n",
    "for root, dirs, files in os.walk(RESUME_DIR):\n",
    "    folder_name = os.path.basename(root)\n",
    "    for file in tqdm(files, desc=f\"Processing in {folder_name}\"):\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_extension = os.path.splitext(file)[1].lower()\n",
    "        resume_text = \"\"\n",
    "        \n",
    "        # Check for file types and extract text accordingly\n",
    "        if file_extension == '.pdf':\n",
    "            resume_text = extract_text_from_pdf(file_path)\n",
    "        elif file_extension == '.docx':\n",
    "            resume_text = extract_text_from_docx(file_path)\n",
    "        elif file_extension == '.doc':\n",
    "            resume_text = extract_text_from_doc(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file}\")\n",
    "            continue  # Skip unsupported formats\n",
    "        \n",
    "        # Handle cases with no text extracted\n",
    "        if not resume_text.strip():\n",
    "            print(f\"No text extracted from {file}\")\n",
    "            continue  # Skip if no text extracted\n",
    "        \n",
    "        # Parse the resume for experience, roles, and skills\n",
    "        experience_years, experience_roles, skills = parse_resume(resume_text)\n",
    "        \n",
    "        # Create an entry for the resume data\n",
    "        resume_entry = {\n",
    "            'file_name': file,\n",
    "            'folder_name': folder_name,\n",
    "            'resume_text': resume_text.replace('\\n', ' ').strip(),\n",
    "            'experience_years': experience_years,\n",
    "            'experience_role': experience_roles,\n",
    "            'skills': skills\n",
    "        }\n",
    "        \n",
    "        resume_data.append(resume_entry)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(resume_data, columns=[\n",
    "    'file_name',\n",
    "    'folder_name',\n",
    "    'resume_text',\n",
    "    'experience_years',\n",
    "    'experience_role',\n",
    "    'skills'\n",
    "])\n",
    "\n",
    "# Display the first few entries\n",
    "print(\"\\nExtracted Resume Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Extracted_Resumes(new_3).csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nExtracted resume data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51dce21e-16d0-4c3c-aee8-1246d77b8e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resumes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Resumes: 100%|█████████████████████████████████████████████████████████████████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported file format: extracted_resumes_data(new).csv\n",
      "Unsupported file format: extracted_resumes_data(new_1).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:   4%|██▏                                              | 1/23 [00:00<00:08,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_G Ananda Rayudu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Gangareddy.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  17%|████████▌                                        | 4/23 [00:00<00:02,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Priyanka Ramadoss.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  26%|████████████▊                                    | 6/23 [00:01<00:03,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_srinivasarao.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  35%|█████████████████                                | 8/23 [00:01<00:02,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Vinod Akkala.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from PeopleSoft DBA_Ganesh Alladi.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  65%|███████████████████████████████▎                | 15/23 [00:02<00:01,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Arun Venu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Pritam Biswas.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Rahul Ahuja.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  83%|███████████████████████████████████████▋        | 19/23 [00:02<00:00,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft FSCM_R Ahmed.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes: 100%|████████████████████████████████████████████████| 23/23 [00:03<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ~$oplesoft Admin_Gangareddy.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ~$oplesoft Admin_Priyanka Ramadoss.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx'\n",
      "No text extracted from ~$oplesoft Admin_Varkala Vikas.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  33%|███████████████████▋                                       | 8/24 [00:01<00:01, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React Developer_PavasGoswami.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  42%|████████████████████████▏                                 | 10/24 [00:01<00:01,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React Developer_Vinay Reddy.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  54%|███████████████████████████████▍                          | 13/24 [00:01<00:01,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React JS Developer_AnjaniPriyadarshini.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js: 100%|██████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.79it/s]\n",
      "Processing in SQL Developer Lightning insight:  27%|█████████▌                          | 4/15 [00:00<00:01,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Nazeer Basha.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight:  60%|█████████████████████▌              | 9/15 [00:01<00:00,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Priyanka L.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight: 100%|███████████████████████████████████| 15/15 [00:02<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Tatikonda Kiran Kumar.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx'\n",
      "No text extracted from ~$mballapradeep.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  25%|█████████████                                       | 6/24 [00:00<00:01, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Hari Krishna M_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Harikrishna Akula_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Hima Mendu_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from J. Sumanth Royal_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  33%|█████████████████▎                                  | 8/24 [00:00<00:01, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Madeeswar A_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  42%|█████████████████████▎                             | 10/24 [00:00<00:01,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Naresh Babu Cherukuri_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  50%|█████████████████████████▌                         | 12/24 [00:01<00:01,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Punugoti Swetha_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  75%|██████████████████████████████████████▎            | 18/24 [00:01<00:00,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ShireeshKumar_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Sri Krishna S_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes: 100%|███████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Venkateswarlu B_Hexaware.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx'\n",
      "No text extracted from ~$innaSubbarayuduM_Hexaware.docx\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx'\n",
      "No text extracted from ~$oraboyinaGuravaiah_Hexaware.docx\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx'\n",
      "No text extracted from ~$pi Krishna_Hexaware.docx\n",
      "\n",
      "Extracted Resume Data:\n",
      "                                  file_name         folder_name  \\\n",
      "0        Peoplesoft Admin_AnubhavSingh.docx  Peoplesoft resumes   \n",
      "1              Peoplesoft Admin_Murali.docx  Peoplesoft resumes   \n",
      "2  Peoplesoft Admin_SirazuddinMohammad.docx  Peoplesoft resumes   \n",
      "3       Peoplesoft Admin_Varkala Vikas.docx  Peoplesoft resumes   \n",
      "4     PeopleSoft DBA_Vivekanand Sayana.docx  Peoplesoft resumes   \n",
      "\n",
      "                                         resume_text  experience_years  \\\n",
      "0  Anubhav Kumar Singh\\t\\t   To work in a globall...               0.0   \n",
      "1  Murali Experience Summary  I have 6 years of e...               6.0   \n",
      "2  PROFILE SUMMARY I have overall 6.8 years’ expe...               6.8   \n",
      "3  PeopleSoft Admin VARKALA VIKAS Career Objectiv...               4.2   \n",
      "4  PeopleSoft Administration   Vivekanand Sayana ...               7.5   \n",
      "\n",
      "                                     experience_role                    skills  \n",
      "0  PeopleSoft Internet Architecture; Technical/De...                      None  \n",
      "1                                         Developers                      None  \n",
      "2  PeopleSoft Internet Architecture; Engineering;...  sql, java, communication  \n",
      "3  developers; internal consistency; PeopleSoft d...                      None  \n",
      "4  architecture; Associate - PeopleSoft Administr...             communication  \n",
      "\n",
      "Extracted resume data saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Extracted_Resumes(new_4).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import docx\n",
    "from PyPDF2 import PdfReader\n",
    "import textract\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize spaCy and download necessary models\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print(\"Downloading 'en_core_web_sm' model for spaCy...\")\n",
    "    from spacy.cli import download\n",
    "    download('en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the directory containing resumes\n",
    "RESUME_DIR = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes'\n",
    "\n",
    "# Define a list of common skills (extend this list as needed)\n",
    "COMMON_SKILLS = [\n",
    "    # Add your common skills here\n",
    "    \"python\", \"java\", \"sql\", \"c++\", \"project management\", \"data analysis\",\n",
    "    \"machine learning\", \"deep learning\", \"communication\", \"teamwork\", \"agile\", \"scrum\"\n",
    "]\n",
    "\n",
    "# Preprocess skills for matching\n",
    "COMMON_SKILLS = [skill.lower() for skill in COMMON_SKILLS]\n",
    "\n",
    "# Function to extract text from PDF using PyPDF2\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting PDF {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOCX using python-docx\n",
    "def extract_text_from_docx(docx_path):\n",
    "    try:\n",
    "        doc = docx.Document(docx_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs if para.text])\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOCX {docx_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOC using textract\n",
    "def extract_text_from_doc(doc_path):\n",
    "    try:\n",
    "        text = textract.process(doc_path).decode('utf-8')\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOC {doc_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract experience years using regex\n",
    "def extract_experience_years(text):\n",
    "    # Patterns like \"5 years of experience\", \"5+ years\", \"six years experience\"\n",
    "    patterns = [\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:of experience)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*yrs? ?(?:of experience)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:working)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:in the industry)?'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text.lower())\n",
    "        if match:\n",
    "            try:\n",
    "                # Convert matched experience to a float (to handle cases like 6.5 years)\n",
    "                return float(match.group(1))\n",
    "            except ValueError:\n",
    "                continue  # If conversion fails, continue to the next match\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# Function to extract skills\n",
    "def extract_skills(text):\n",
    "    text = text.lower()\n",
    "    skills_found = set()\n",
    "    for skill in COMMON_SKILLS:\n",
    "        # Use word boundaries to match whole words\n",
    "        if re.search(r'\\b' + re.escape(skill) + r'\\b', text):\n",
    "            skills_found.add(skill)\n",
    "    return \", \".join(skills_found) if skills_found else \"None\"\n",
    "\n",
    "# Function to extract experience roles using spaCy's noun chunks\n",
    "def extract_experience_roles(text):\n",
    "    doc = nlp(text)\n",
    "    roles = set()\n",
    "    # Define keywords that often precede job titles\n",
    "    role_keywords = ['software engineer', 'data scientist', 'developer', 'manager', \n",
    "                     'analyst', 'consultant', 'intern', 'engineer', 'specialist', \n",
    "                     'director', 'lead', 'administrator', 'architect']\n",
    "    \n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_text = chunk.text.lower()\n",
    "        for keyword in role_keywords:\n",
    "            if keyword in chunk_text:\n",
    "                roles.add(chunk.text.strip())\n",
    "    \n",
    "    return \"; \".join(roles) if roles else \"None\"\n",
    "\n",
    "# Function to extract all required information from resume text\n",
    "def parse_resume(text):\n",
    "    experience_years = extract_experience_years(text)\n",
    "    skills = extract_skills(text)\n",
    "    experience_roles = extract_experience_roles(text)\n",
    "    return experience_years, experience_roles, skills\n",
    "\n",
    "# Initialize a list to hold all resume data\n",
    "resume_data = []\n",
    "\n",
    "# Traverse the directory and process each resume file\n",
    "print(\"Processing resumes...\")\n",
    "for root, dirs, files in os.walk(RESUME_DIR):\n",
    "    folder_name = os.path.basename(root)\n",
    "    for file in tqdm(files, desc=f\"Processing in {folder_name}\"):\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_extension = os.path.splitext(file)[1].lower()\n",
    "        resume_text = \"\"\n",
    "        \n",
    "        # Check for file types and extract text accordingly\n",
    "        if file_extension == '.pdf':\n",
    "            resume_text = extract_text_from_pdf(file_path)\n",
    "        elif file_extension == '.docx':\n",
    "            resume_text = extract_text_from_docx(file_path)\n",
    "        elif file_extension == '.doc':\n",
    "            resume_text = extract_text_from_doc(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file}\")\n",
    "            continue  # Skip unsupported formats\n",
    "        \n",
    "        # Handle cases with no text extracted\n",
    "        if not resume_text.strip():\n",
    "            print(f\"No text extracted from {file}\")\n",
    "            continue  # Skip if no text extracted\n",
    "        \n",
    "        # Parse the resume for experience, roles, and skills\n",
    "        experience_years, experience_roles, skills = parse_resume(resume_text)\n",
    "        \n",
    "        # Create an entry for the resume data\n",
    "        resume_entry = {\n",
    "            'file_name': file,\n",
    "            'folder_name': folder_name,\n",
    "            'resume_text': resume_text.replace('\\n', ' ').strip(),\n",
    "            'experience_years': experience_years,\n",
    "            'experience_role': experience_roles,\n",
    "            'skills': skills\n",
    "        }\n",
    "        \n",
    "        resume_data.append(resume_entry)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(resume_data, columns=[\n",
    "    'file_name',\n",
    "    'folder_name',\n",
    "    'resume_text',\n",
    "    'experience_years',\n",
    "    'experience_role',\n",
    "    'skills'\n",
    "])\n",
    "\n",
    "# Display the first few entries\n",
    "print(\"\\nExtracted Resume Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Extracted_Resumes(new_4).csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nExtracted resume data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de3f53-c6a5-4825-91de-a0e8b079d816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aa513bf-e8a4-43e6-b51a-caeac1b48b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resumes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Resumes: 100%|█████████████████████████████████████████████████████████████████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported file format: extracted_resumes_data(new).csv\n",
      "Unsupported file format: extracted_resumes_data(new_1).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  17%|████████▌                                        | 4/23 [00:00<00:02,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_G Ananda Rayudu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Gangareddy.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Priyanka Ramadoss.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  26%|████████████▊                                    | 6/23 [00:00<00:02,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_srinivasarao.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  35%|█████████████████                                | 8/23 [00:01<00:02,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Admin_Vinod Akkala.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from PeopleSoft DBA_Ganesh Alladi.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  48%|██████████████████████▉                         | 11/23 [00:02<00:02,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Arun Venu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Pritam Biswas.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft Finance_Rahul Ahuja.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  83%|███████████████████████████████████████▋        | 19/23 [00:03<00:00,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Peoplesoft FSCM_R Ahmed.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes: 100%|████████████████████████████████████████████████| 23/23 [00:03<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ~$oplesoft Admin_Gangareddy.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ~$oplesoft Admin_Priyanka Ramadoss.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx'\n",
      "No text extracted from ~$oplesoft Admin_Varkala Vikas.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  33%|███████████████████▋                                       | 8/24 [00:01<00:01,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React Developer_PavasGoswami.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  38%|██████████████████████▏                                    | 9/24 [00:01<00:02,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React Developer_Vinay Reddy.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  54%|███████████████████████████████▍                          | 13/24 [00:01<00:01,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from React JS Developer_AnjaniPriyadarshini.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js: 100%|██████████████████████████████████████████████████████████| 24/24 [00:03<00:00,  7.83it/s]\n",
      "Processing in SQL Developer Lightning insight:  40%|██████████████▍                     | 6/15 [00:00<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Nazeer Basha.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight:  60%|█████████████████████▌              | 9/15 [00:01<00:00,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Priyanka L.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight: 100%|███████████████████████████████████| 15/15 [00:01<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Tatikonda Kiran Kumar.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx'\n",
      "No text extracted from ~$mballapradeep.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  25%|█████████████                                       | 6/24 [00:00<00:01, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Hari Krishna M_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Harikrishna Akula_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Hima Mendu_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  33%|█████████████████▎                                  | 8/24 [00:00<00:01, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from J. Sumanth Royal_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Madeeswar A_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  50%|█████████████████████████▌                         | 12/24 [00:01<00:01, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Naresh Babu Cherukuri_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Punugoti Swetha_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  62%|███████████████████████████████▉                   | 15/24 [00:01<00:01,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from ShireeshKumar_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Sri Krishna S_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes: 100%|███████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from Venkateswarlu B_Hexaware.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx'\n",
      "No text extracted from ~$innaSubbarayuduM_Hexaware.docx\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx'\n",
      "No text extracted from ~$oraboyinaGuravaiah_Hexaware.docx\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx'\n",
      "No text extracted from ~$pi Krishna_Hexaware.docx\n",
      "\n",
      "Extracted Resume Data:\n",
      "                                  file_name         folder_name  \\\n",
      "0        Peoplesoft Admin_AnubhavSingh.docx  Peoplesoft resumes   \n",
      "1              Peoplesoft Admin_Murali.docx  Peoplesoft resumes   \n",
      "2  Peoplesoft Admin_SirazuddinMohammad.docx  Peoplesoft resumes   \n",
      "3       Peoplesoft Admin_Varkala Vikas.docx  Peoplesoft resumes   \n",
      "4     PeopleSoft DBA_Vivekanand Sayana.docx  Peoplesoft resumes   \n",
      "\n",
      "                                         resume_text  experience_years  \\\n",
      "0  Anubhav Kumar Singh\\t\\t   To work in a globall...               0.0   \n",
      "1  Murali Experience Summary  I have 6 years of e...               6.0   \n",
      "2  PROFILE SUMMARY I have overall 6.8 years’ expe...               6.8   \n",
      "3  PeopleSoft Admin VARKALA VIKAS Career Objectiv...               4.2   \n",
      "4  PeopleSoft Administration   Vivekanand Sayana ...               7.5   \n",
      "\n",
      "                                     experience_role  \\\n",
      "0  PeopleSoft Internet Architecture; Technical/De...   \n",
      "1                                         Developers   \n",
      "2  PeopleSoft Internet Architecture; Engineering;...   \n",
      "3  developers; internal consistency; PeopleSoft d...   \n",
      "4  architecture; Associate - PeopleSoft Administr...   \n",
      "\n",
      "                                              skills  \n",
      "0  peoplesoft fscm, integration, oracle database,...  \n",
      "1  data mover, integration, application designer,...  \n",
      "2  data mover, oracle database, application desig...  \n",
      "3  data mover, oracle database, application desig...  \n",
      "4  data mover, integration, application designer,...  \n",
      "\n",
      "Data saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Extracted_Resumes(new_new).csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import docx\n",
    "from PyPDF2 import PdfReader\n",
    "import textract\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize spaCy and download necessary models\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print(\"Downloading 'en_core_web_sm' model for spaCy...\")\n",
    "    from spacy.cli import download\n",
    "    download('en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the directory containing resumes\n",
    "RESUME_DIR = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes'\n",
    "\n",
    "# Expanded list of common skills\n",
    "COMMON_SKILLS = [\n",
    "    # PeopleSoft and Workday Specific Skills\n",
    "    'PeopleSoft HRMS', 'PeopleSoft FSCM', 'PeopleSoft CRM', \n",
    "    'PeopleSoft HCM', 'PeopleSoft Portal', 'PeopleTools', \n",
    "    'Integration Broker', 'Application Designer', 'PeopleSoft Update Manager', \n",
    "    'Data Mover', 'Workday HCM', 'Core HR', 'Benefits',\n",
    "    \n",
    "    # Technical Skills\n",
    "    'SQL', 'T-SQL', 'SSIS', 'MySQL', \n",
    "    'MS SQL Server', 'SQL Server 2012', 'SQL Server 2016', \n",
    "    'Oracle Database', 'Oracle 10gR2', 'Oracle 11gR2', \n",
    "    'Oracle 12c', 'Oracle Enterprise Linux', \n",
    "    'Windows Server 2003', 'Windows Server 2008R2', \n",
    "    'Windows Server 2012', 'HP-UX 11.31',\n",
    "    'Unix/Linux', 'Shell Scripting', 'Active Directory', \n",
    "\n",
    "    # Reporting and ETL Tools\n",
    "    'SQL Server Analysis Services', 'SQL Server Integration Services', \n",
    "    'SQL Server Reporting Services', 'Report Builder', \n",
    "    'Crystal Reports', 'XML Publisher', 'Report Writer',\n",
    "    'Power BI', 'Tableau', 'QlikView',\n",
    "\n",
    "    # Programming Languages\n",
    "    'Java', 'Python', 'C++', 'JavaScript', 'React', \n",
    "    'Node.js', 'Django', 'Flask', 'Ruby', \n",
    "    'Go', 'Scala', 'Swift', 'C#', 'PHP', \n",
    "    'R', 'MATLAB', 'TypeScript', 'Bash', \n",
    "    'HTML', 'CSS',\n",
    "\n",
    "    # Compensation and Management Skills\n",
    "    'Compensation', 'Time Tracking', 'Absence Management', \n",
    "    'Calculated Fields', 'EIB Inbound', 'EIB Outbound', \n",
    "    'Core Connectors', 'Studio', 'XML', 'XSLT', \n",
    "    'SOAP', 'REST', 'Reporting', 'Integration', \n",
    "    'Business Objects', 'Change Deduction',\n",
    "\n",
    "    # Data and Cloud Technologies\n",
    "    'Machine Learning', 'Data Science', 'Data Analysis', \n",
    "    'ETL Processes', 'Data Visualization', 'Spark', \n",
    "    'AWS', 'Docker', 'Kubernetes', 'NoSQL', \n",
    "    'MongoDB', 'PostgreSQL', 'REST API', \n",
    "    'GraphQL', 'Azure', 'Google Cloud Platform', \n",
    "    'Data Warehousing',\n",
    "\n",
    "    # Soft Skills\n",
    "    'Communication', 'Leadership', 'Project Management', \n",
    "    'Change Management', 'Performance Tuning', \n",
    "    'Backup and Recovery', 'Security Management', \n",
    "    'Understanding of HR Processes', 'Data Modeling', \n",
    "    'User Interface Design', 'Analytical Thinking', \n",
    "    'Problem Solving', 'Team Collaboration', \n",
    "    'Agile Methodologies', 'Customer Relationship Management (CRM)',\n",
    "    \n",
    "    # Additional Skills\n",
    "    'API Development', 'User Acceptance Testing (UAT)', \n",
    "    'Version Control (Git)', 'Continuous Integration/Continuous Deployment (CI/CD)', \n",
    "    'Business Process Reengineering', 'Regulatory Compliance', \n",
    "    'Quality Assurance', 'Systems Analysis', \n",
    "    'Digital Transformation', 'Training and Development',\n",
    "    'Stakeholder Management', 'Documentation Skills'\n",
    "]\n",
    "\n",
    "# Preprocess skills for matching\n",
    "COMMON_SKILLS = [skill.lower() for skill in COMMON_SKILLS]\n",
    "\n",
    "# Function to extract text from PDF using PyPDF2\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting PDF {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOCX using python-docx\n",
    "def extract_text_from_docx(docx_path):\n",
    "    try:\n",
    "        doc = docx.Document(docx_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs if para.text])\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOCX {docx_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOC using textract\n",
    "def extract_text_from_doc(doc_path):\n",
    "    try:\n",
    "        text = textract.process(doc_path).decode('utf-8')\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOC {doc_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract experience years using regex\n",
    "def extract_experience_years(text):\n",
    "    patterns = [\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:of experience)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*yrs? ?(?:of experience)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:working)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:in the industry)?'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text.lower())\n",
    "        if match:\n",
    "            try:\n",
    "                return float(match.group(1))\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# Function to extract skills\n",
    "def extract_skills(text):\n",
    "    text = text.lower()\n",
    "    skills_found = set()\n",
    "    for skill in COMMON_SKILLS:\n",
    "        if re.search(r'\\b' + re.escape(skill) + r'\\b', text):\n",
    "            skills_found.add(skill)\n",
    "    return \", \".join(skills_found) if skills_found else \"None\"\n",
    "\n",
    "# Function to extract experience roles using spaCy's noun chunks\n",
    "def extract_experience_roles(text):\n",
    "    doc = nlp(text)\n",
    "    roles = set()\n",
    "    role_keywords = ['software engineer', 'data scientist', 'developer', 'manager', \n",
    "                     'analyst', 'consultant', 'intern', 'engineer', 'specialist', \n",
    "                     'director', 'lead', 'administrator', 'architect']\n",
    "    \n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_text = chunk.text.lower()\n",
    "        for keyword in role_keywords:\n",
    "            if keyword in chunk_text:\n",
    "                roles.add(chunk.text.strip())\n",
    "    \n",
    "    return \"; \".join(roles) if roles else \"None\"\n",
    "\n",
    "# Function to extract all required information from resume text\n",
    "def parse_resume(text):\n",
    "    experience_years = extract_experience_years(text)\n",
    "    skills = extract_skills(text)\n",
    "    experience_roles = extract_experience_roles(text)\n",
    "    return experience_years, experience_roles, skills\n",
    "\n",
    "# Initialize a list to hold all resume data\n",
    "resume_data = []\n",
    "\n",
    "# Traverse the directory and process each resume file\n",
    "print(\"Processing resumes...\")\n",
    "for root, dirs, files in os.walk(RESUME_DIR):\n",
    "    folder_name = os.path.basename(root)\n",
    "    for file in tqdm(files, desc=f\"Processing in {folder_name}\"):\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_extension = os.path.splitext(file)[1].lower()\n",
    "        resume_text = \"\"\n",
    "        \n",
    "        if file_extension == '.pdf':\n",
    "            resume_text = extract_text_from_pdf(file_path)\n",
    "        elif file_extension == '.docx':\n",
    "            resume_text = extract_text_from_docx(file_path)\n",
    "        elif file_extension == '.doc':\n",
    "            resume_text = extract_text_from_doc(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file}\")\n",
    "            continue\n",
    "        \n",
    "        if not resume_text.strip():\n",
    "            print(f\"No text extracted from {file}\")\n",
    "            continue\n",
    "        \n",
    "        experience_years, experience_roles, skills = parse_resume(resume_text)\n",
    "        \n",
    "        resume_entry = {\n",
    "            'file_name': file,\n",
    "            'folder_name': folder_name,\n",
    "            'resume_text': resume_text.replace('\\n', ' ').strip(),\n",
    "            'experience_years': experience_years,\n",
    "            'experience_role': experience_roles,\n",
    "            'skills': skills\n",
    "        }\n",
    "        \n",
    "        resume_data.append(resume_entry)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(resume_data, columns=[\n",
    "    'file_name',\n",
    "    'folder_name',\n",
    "    'resume_text',\n",
    "    'experience_years',\n",
    "    'experience_role',\n",
    "    'skills'\n",
    "])\n",
    "\n",
    "# Display the first few entries\n",
    "print(\"\\nExtracted Resume Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Extracted_Resumes(new_new).csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nData saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce80226-24a4-4fa7-b0f5-eee820401f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff6176c6-6068-41cb-8c52-f9d156f7c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resumes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Resumes: 100%|███████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 2006.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported file format: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\extracted_resumes_data(new).csv\n",
      "Unsupported file format: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\extracted_resumes_data(new_1).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:   4%|██▏                                              | 1/23 [00:00<00:10,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  17%|████████▌                                        | 4/23 [00:00<00:03,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  26%|████████████▊                                    | 6/23 [00:01<00:02,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  35%|█████████████████                                | 8/23 [00:01<00:02,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  65%|███████████████████████████████▎                | 15/23 [00:02<00:01,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  83%|███████████████████████████████████████▋        | 19/23 [00:02<00:00,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes: 100%|████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx'\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  33%|███████████████████▋                                       | 8/24 [00:00<00:01, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  50%|█████████████████████████████                             | 12/24 [00:01<00:01, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  58%|█████████████████████████████████▊                        | 14/24 [00:01<00:00, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js: 100%|██████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.80it/s]\n",
      "Processing in SQL Developer Lightning insight:  40%|██████████████▍                     | 6/15 [00:00<00:00,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight:  60%|█████████████████████▌              | 9/15 [00:01<00:00,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight: 100%|███████████████████████████████████| 15/15 [00:01<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx'\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  25%|█████████████                                       | 6/24 [00:00<00:01, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  33%|█████████████████▎                                  | 8/24 [00:00<00:01, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  50%|█████████████████████████▌                         | 12/24 [00:01<00:01, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  62%|███████████████████████████████▉                   | 15/24 [00:01<00:01,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  88%|████████████████████████████████████████████▋      | 21/24 [00:02<00:00,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes: 100%|███████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx'\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx'\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx'\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx\n",
      "Resume data extracted successfully.\n",
      "                                  File Name  Experience Years  \\\n",
      "0        Peoplesoft Admin_AnubhavSingh.docx               0.0   \n",
      "1              Peoplesoft Admin_Murali.docx               6.0   \n",
      "2  Peoplesoft Admin_SirazuddinMohammad.docx               6.8   \n",
      "3       Peoplesoft Admin_Varkala Vikas.docx               4.2   \n",
      "4     PeopleSoft DBA_Vivekanand Sayana.docx               7.5   \n",
      "\n",
      "                                    Experience Roles  \\\n",
      "0  PeopleSoft Internet Architecture; Technical/De...   \n",
      "1                                         Developers   \n",
      "2  PeopleSoft Internet Architecture; Engineering;...   \n",
      "3  developers; internal consistency; PeopleSoft d...   \n",
      "4  architecture; Associate - PeopleSoft Administr...   \n",
      "\n",
      "                                              Skills  \n",
      "0  peoplesoft fscm, integration, oracle database,...  \n",
      "1  data mover, integration, application designer,...  \n",
      "2  data mover, oracle database, application desig...  \n",
      "3  data mover, oracle database, application desig...  \n",
      "4  data mover, integration, application designer,...  \n",
      "Resume data saved to: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\extracted_resumes(new_new_1).xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import docx\n",
    "from PyPDF2 import PdfReader\n",
    "import textract\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize spaCy and download necessary models\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print(\"Downloading 'en_core_web_sm' model for spaCy...\")\n",
    "    from spacy.cli import download\n",
    "    download('en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the directory containing resumes\n",
    "RESUME_DIR = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes'\n",
    "\n",
    "# Expanded list of common skills\n",
    "COMMON_SKILLS = [skill.lower() for skill in [\n",
    "    # PeopleSoft and Workday Specific Skills\n",
    "    'PeopleSoft HRMS', 'PeopleSoft FSCM', 'PeopleSoft CRM', \n",
    "    'PeopleSoft HCM', 'PeopleSoft Portal', 'PeopleTools', \n",
    "    'Integration Broker', 'Application Designer', 'PeopleSoft Update Manager', \n",
    "    'Data Mover', 'Workday HCM', 'Core HR', 'Benefits',\n",
    "    \n",
    "    # Technical Skills\n",
    "    'SQL', 'T-SQL', 'SSIS', 'MySQL', \n",
    "    'MS SQL Server', 'SQL Server 2012', 'SQL Server 2016', \n",
    "    'Oracle Database', 'Oracle 10gR2', 'Oracle 11gR2', \n",
    "    'Oracle 12c', 'Oracle Enterprise Linux', \n",
    "    'Windows Server 2003', 'Windows Server 2008R2', \n",
    "    'Windows Server 2012', 'HP-UX 11.31',\n",
    "    'Unix/Linux', 'Shell Scripting', 'Active Directory', \n",
    "\n",
    "    # Reporting and ETL Tools\n",
    "    'SQL Server Analysis Services', 'SQL Server Integration Services', \n",
    "    'SQL Server Reporting Services', 'Report Builder', \n",
    "    'Crystal Reports', 'XML Publisher', 'Report Writer',\n",
    "    'Power BI', 'Tableau', 'QlikView',\n",
    "\n",
    "    # Programming Languages\n",
    "    'Java', 'Python', 'C++', 'JavaScript', 'React', \n",
    "    'Node.js', 'Django', 'Flask', 'Ruby', \n",
    "    'Go', 'Scala', 'Swift', 'C#', 'PHP', \n",
    "    'R', 'MATLAB', 'TypeScript', 'Bash', \n",
    "    'HTML', 'CSS',\n",
    "\n",
    "    # Compensation and Management Skills\n",
    "    'Compensation', 'Time Tracking', 'Absence Management', \n",
    "    'Calculated Fields', 'EIB Inbound', 'EIB Outbound', \n",
    "    'Core Connectors', 'Studio', 'XML', 'XSLT', \n",
    "    'SOAP', 'REST', 'Reporting', 'Integration', \n",
    "    'Business Objects', 'Change Deduction',\n",
    "\n",
    "    # Data and Cloud Technologies\n",
    "    'Machine Learning', 'Data Science', 'Data Analysis', \n",
    "    'ETL Processes', 'Data Visualization', 'Spark', \n",
    "    'AWS', 'Docker', 'Kubernetes', 'NoSQL', \n",
    "    'MongoDB', 'PostgreSQL', 'REST API', \n",
    "    'GraphQL', 'Azure', 'Google Cloud Platform', \n",
    "    'Data Warehousing',\n",
    "\n",
    "    # Soft Skills\n",
    "    'Communication', 'Leadership', 'Project Management', \n",
    "    'Change Management', 'Performance Tuning', \n",
    "    'Backup and Recovery', 'Security Management', \n",
    "    'Understanding of HR Processes', 'Data Modeling', \n",
    "    'User Interface Design', 'Analytical Thinking', \n",
    "    'Problem Solving', 'Team Collaboration', \n",
    "    'Agile Methodologies', 'Customer Relationship Management (CRM)',\n",
    "    \n",
    "    # Additional Skills\n",
    "    'API Development', 'User Acceptance Testing (UAT)', \n",
    "    'Version Control (Git)', 'Continuous Integration/Continuous Deployment (CI/CD)', \n",
    "    'Business Process Reengineering', 'Regulatory Compliance', \n",
    "    'Quality Assurance', 'Systems Analysis', \n",
    "    'Digital Transformation', 'Training and Development',\n",
    "    'Stakeholder Management', 'Documentation Skills'\n",
    "]]\n",
    "\n",
    "# Function to extract text from PDF using PyPDF2\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting PDF {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOCX using python-docx\n",
    "def extract_text_from_docx(docx_path):\n",
    "    try:\n",
    "        doc = docx.Document(docx_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs if para.text])\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOCX {docx_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOC using textract\n",
    "def extract_text_from_doc(doc_path):\n",
    "    try:\n",
    "        text = textract.process(doc_path).decode('utf-8')\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOC {doc_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract experience years using regex\n",
    "def extract_experience_years(text):\n",
    "    patterns = [\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:of experience)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*yrs? ?(?:of experience)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:working)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:in the industry)?'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text.lower())\n",
    "        if match:\n",
    "            try:\n",
    "                return float(match.group(1))\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# Function to extract skills\n",
    "def extract_skills(text):\n",
    "    text = text.lower()\n",
    "    skills_found = set()\n",
    "    for skill in COMMON_SKILLS:\n",
    "        if re.search(r'\\b' + re.escape(skill) + r'\\b', text):\n",
    "            skills_found.add(skill)\n",
    "    return \", \".join(skills_found) if skills_found else \"None\"\n",
    "\n",
    "# Function to extract experience roles using spaCy's noun chunks\n",
    "def extract_experience_roles(text):\n",
    "    doc = nlp(text)\n",
    "    roles = set()\n",
    "    role_keywords = ['software engineer', 'data scientist', 'developer', 'manager', \n",
    "                     'analyst', 'consultant', 'intern', 'engineer', 'specialist', \n",
    "                     'director', 'lead', 'administrator', 'architect']\n",
    "    \n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_text = chunk.text.lower()\n",
    "        for keyword in role_keywords:\n",
    "            if keyword in chunk_text:\n",
    "                roles.add(chunk.text.strip())\n",
    "    \n",
    "    return \"; \".join(roles) if roles else \"None\"\n",
    "\n",
    "# Function to extract all required information from resume text\n",
    "def parse_resume(text):\n",
    "    experience_years = extract_experience_years(text)\n",
    "    skills = extract_skills(text)\n",
    "    experience_roles = extract_experience_roles(text)\n",
    "    return experience_years, experience_roles, skills\n",
    "\n",
    "# Initialize a list to hold all resume data\n",
    "resume_data = []\n",
    "\n",
    "# Traverse the directory and process each resume file\n",
    "print(\"Processing resumes...\")\n",
    "for root, dirs, files in os.walk(RESUME_DIR):\n",
    "    folder_name = os.path.basename(root)\n",
    "    for file in tqdm(files, desc=f\"Processing in {folder_name}\"):\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_extension = os.path.splitext(file)[1].lower()\n",
    "        resume_text = \"\"\n",
    "        \n",
    "        if file_extension == '.pdf':\n",
    "            resume_text = extract_text_from_pdf(file_path)\n",
    "        elif file_extension == '.docx':\n",
    "            resume_text = extract_text_from_docx(file_path)\n",
    "        elif file_extension == '.doc':\n",
    "            resume_text = extract_text_from_doc(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file_path}\")\n",
    "            continue  # Skip unsupported formats\n",
    "        \n",
    "        # If text extraction was successful, parse the resume\n",
    "        if resume_text:\n",
    "            experience_years, experience_roles, skills = parse_resume(resume_text)\n",
    "            resume_data.append({\n",
    "                'File Name': file,\n",
    "                'Experience Years': experience_years,\n",
    "                'Experience Roles': experience_roles,\n",
    "                'Skills': skills\n",
    "            })\n",
    "        else:\n",
    "            print(f\"No text extracted from: {file_path}\")\n",
    "\n",
    "# Create a DataFrame from the extracted resume data\n",
    "resume_df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Check if DataFrame is empty\n",
    "if resume_df.empty:\n",
    "    print(\"No resume data extracted.\")\n",
    "else:\n",
    "    print(\"Resume data extracted successfully.\")\n",
    "    print(resume_df.head())  # Display the first few rows\n",
    "\n",
    "# Save the resume DataFrame to an Excel file\n",
    "excel_path = os.path.join(RESUME_DIR, 'extracted_resumes(new_new_1).xlsx')\n",
    "resume_df.to_excel(excel_path, index=False)\n",
    "print(f\"Resume data saved to: {excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e41073-d391-423f-8f8c-1daa4ab34fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d888f26-6f5a-4547-802c-ee6ff5157352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resumes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Resumes: 100%|█████████████████████████████████████████████████████████████████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported file format: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\extracted_resumes(new_new_1).xlsx\n",
      "Unsupported file format: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\extracted_resumes_data(new).csv\n",
      "Unsupported file format: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\extracted_resumes_data(new_1).csv\n",
      "Unsupported file format: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\~$extracted_resumes(new_new_1).xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  17%|████████▌                                        | 4/23 [00:00<00:02,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_G Ananda Rayudu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Gangareddy.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Priyanka Ramadoss.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  26%|████████████▊                                    | 6/23 [00:00<00:01,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_srinivasarao.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  35%|█████████████████                                | 8/23 [00:00<00:01,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Admin_Vinod Akkala.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\PeopleSoft DBA_Ganesh Alladi.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  65%|███████████████████████████████▎                | 15/23 [00:01<00:00, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Arun Venu.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Pritam Biswas.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft Finance_Rahul Ahuja.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes:  83%|███████████████████████████████████████▋        | 19/23 [00:02<00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\Peoplesoft FSCM_R Ahmed.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Peoplesoft resumes: 100%|████████████████████████████████████████████████| 23/23 [00:02<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Gangareddy.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Priyanka Ramadoss.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx'\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\Peoplesoft resumes\\~$oplesoft Admin_Varkala Vikas.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  33%|███████████████████▋                                       | 8/24 [00:00<00:01, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_PavasGoswami.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  50%|█████████████████████████████                             | 12/24 [00:01<00:01, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React Developer_Vinay Reddy.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js:  58%|█████████████████████████████████▊                        | 14/24 [00:01<00:00, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\React js\\React JS Developer_AnjaniPriyadarshini.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in React js: 100%|██████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.04it/s]\n",
      "Processing in SQL Developer Lightning insight:  40%|██████████████▍                     | 6/15 [00:00<00:00,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Nazeer Basha.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight:  60%|█████████████████████▌              | 9/15 [00:01<00:00,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Priyanka L.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in SQL Developer Lightning insight: 100%|███████████████████████████████████| 15/15 [00:01<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\Tatikonda Kiran Kumar.doc\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx'\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\SQL Developer Lightning insight\\~$mballapradeep.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  25%|█████████████                                       | 6/24 [00:00<00:01, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hari Krishna M_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Harikrishna Akula_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Hima Mendu_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\J. Sumanth Royal_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  33%|█████████████████▎                                  | 8/24 [00:00<00:01, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Madeeswar A_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  50%|█████████████████████████▌                         | 12/24 [00:01<00:01, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Naresh Babu Cherukuri_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Punugoti Swetha_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  62%|███████████████████████████████▉                   | 15/24 [00:01<00:01,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\ShireeshKumar_Hexaware.doc\n",
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Sri Krishna S_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes:  79%|████████████████████████████████████████▍          | 19/24 [00:02<00:00,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOC C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc: The command `antiword C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc` failed with exit code 127\n",
      "------------- stdout -------------\n",
      "------------- stderr -------------\n",
      "\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\Venkateswarlu B_Hexaware.doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in workday resumes: 100%|███████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx'\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$innaSubbarayuduM_Hexaware.docx\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx'\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$oraboyinaGuravaiah_Hexaware.docx\n",
      "Error extracting DOCX C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx: Package not found at 'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx'\n",
      "No text extracted from: C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\workday resumes\\~$pi Krishna_Hexaware.docx\n",
      "Resume data extracted successfully.\n",
      "                                  File Name         Folder Name  \\\n",
      "0        Peoplesoft Admin_AnubhavSingh.docx  Peoplesoft resumes   \n",
      "1              Peoplesoft Admin_Murali.docx  Peoplesoft resumes   \n",
      "2  Peoplesoft Admin_SirazuddinMohammad.docx  Peoplesoft resumes   \n",
      "3       Peoplesoft Admin_Varkala Vikas.docx  Peoplesoft resumes   \n",
      "4     PeopleSoft DBA_Vivekanand Sayana.docx  Peoplesoft resumes   \n",
      "\n",
      "                                         Resume Text  Experience Years  \\\n",
      "0  Anubhav Kumar Singh\\t\\t\\n  To work in a global...               0.0   \n",
      "1  Murali\\nExperience Summary \\nI have 6 years of...               6.0   \n",
      "2  PROFILE SUMMARY\\nI have overall 6.8 years’ exp...               6.8   \n",
      "3  PeopleSoft Admin\\nVARKALA VIKAS\\nCareer Object...               4.2   \n",
      "4  PeopleSoft Administration\\n \\nVivekanand Sayan...               7.5   \n",
      "\n",
      "                                    Experience Roles  \\\n",
      "0  PeopleSoft Internet Architecture; Technical/De...   \n",
      "1                                         Developers   \n",
      "2  PeopleSoft Internet Architecture; Engineering;...   \n",
      "3  developers; internal consistency; PeopleSoft d...   \n",
      "4  architecture; Associate - PeopleSoft Administr...   \n",
      "\n",
      "                                              Skills  \n",
      "0  peoplesoft fscm, integration, oracle database,...  \n",
      "1  data mover, integration, application designer,...  \n",
      "2  data mover, oracle database, application desig...  \n",
      "3  data mover, oracle database, application desig...  \n",
      "4  data mover, integration, application designer,...  \n",
      "Resume data saved to C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes\\extracted_resumes(new_new_22).xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import docx\n",
    "from PyPDF2 import PdfReader\n",
    "import textract\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize spaCy and download necessary models\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print(\"Downloading 'en_core_web_sm' model for spaCy...\")\n",
    "    from spacy.cli import download\n",
    "    download('en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the directory containing resumes\n",
    "RESUME_DIR = r'C:\\Users\\Dell\\OneDrive\\Desktop\\Resume\\Resumes'\n",
    "\n",
    "# Expanded list of common skills\n",
    "COMMON_SKILLS = [skill.lower() for skill in [\n",
    "    # PeopleSoft and Workday Specific Skills\n",
    "    'PeopleSoft HRMS', 'PeopleSoft FSCM', 'PeopleSoft CRM', \n",
    "    'PeopleSoft HCM', 'PeopleSoft Portal', 'PeopleTools', \n",
    "    'Integration Broker', 'Application Designer', 'PeopleSoft Update Manager', \n",
    "    'Data Mover', 'Workday HCM', 'Core HR', 'Benefits',\n",
    "    \n",
    "    # Technical Skills\n",
    "    'SQL', 'T-SQL', 'SSIS', 'MySQL', \n",
    "    'MS SQL Server', 'SQL Server 2012', 'SQL Server 2016', \n",
    "    'Oracle Database', 'Oracle 10gR2', 'Oracle 11gR2', \n",
    "    'Oracle 12c', 'Oracle Enterprise Linux', \n",
    "    'Windows Server 2003', 'Windows Server 2008R2', \n",
    "    'Windows Server 2012', 'HP-UX 11.31',\n",
    "    'Unix/Linux', 'Shell Scripting', 'Active Directory', \n",
    "\n",
    "    # Reporting and ETL Tools\n",
    "    'SQL Server Analysis Services', 'SQL Server Integration Services', \n",
    "    'SQL Server Reporting Services', 'Report Builder', \n",
    "    'Crystal Reports', 'XML Publisher', 'Report Writer',\n",
    "    'Power BI', 'Tableau', 'QlikView',\n",
    "\n",
    "    # Programming Languages\n",
    "    'Java', 'Python', 'C++', 'JavaScript', 'React', \n",
    "    'Node.js', 'Django', 'Flask', 'Ruby', \n",
    "    'Go', 'Scala', 'Swift', 'C#', 'PHP', \n",
    "    'R', 'MATLAB', 'TypeScript', 'Bash', \n",
    "    'HTML', 'CSS',\n",
    "\n",
    "    # Compensation and Management Skills\n",
    "    'Compensation', 'Time Tracking', 'Absence Management', \n",
    "    'Calculated Fields', 'EIB Inbound', 'EIB Outbound', \n",
    "    'Core Connectors', 'Studio', 'XML', 'XSLT', \n",
    "    'SOAP', 'REST', 'Reporting', 'Integration', \n",
    "    'Business Objects', 'Change Deduction',\n",
    "\n",
    "    # Data and Cloud Technologies\n",
    "    'Machine Learning', 'Data Science', 'Data Analysis', \n",
    "    'ETL Processes', 'Data Visualization', 'Spark', \n",
    "    'AWS', 'Docker', 'Kubernetes', 'NoSQL', \n",
    "    'MongoDB', 'PostgreSQL', 'REST API', \n",
    "    'GraphQL', 'Azure', 'Google Cloud Platform', \n",
    "    'Data Warehousing',\n",
    "\n",
    "    # Soft Skills\n",
    "    'Communication', 'Leadership', 'Project Management', \n",
    "    'Change Management', 'Performance Tuning', \n",
    "    'Backup and Recovery', 'Security Management', \n",
    "    'Understanding of HR Processes', 'Data Modeling', \n",
    "    'User Interface Design', 'Analytical Thinking', \n",
    "    'Problem Solving', 'Team Collaboration', \n",
    "    'Agile Methodologies', 'Customer Relationship Management (CRM)',\n",
    "    \n",
    "    # Additional Skills\n",
    "    'API Development', 'User Acceptance Testing (UAT)', \n",
    "    'Version Control (Git)', 'Continuous Integration/Continuous Deployment (CI/CD)', \n",
    "    'Business Process Reengineering', 'Regulatory Compliance', \n",
    "    'Quality Assurance', 'Systems Analysis', \n",
    "    'Digital Transformation', 'Training and Development',\n",
    "    'Stakeholder Management', 'Documentation Skills'\n",
    "]]\n",
    "\n",
    "# Function to extract text from PDF using PyPDF2\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting PDF {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOCX using python-docx\n",
    "def extract_text_from_docx(docx_path):\n",
    "    try:\n",
    "        doc = docx.Document(docx_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs if para.text])\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOCX {docx_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from DOC using textract\n",
    "def extract_text_from_doc(doc_path):\n",
    "    try:\n",
    "        text = textract.process(doc_path).decode('utf-8')\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting DOC {doc_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract experience years using regex\n",
    "def extract_experience_years(text):\n",
    "    patterns = [\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:of experience)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*yrs? ?(?:of experience)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:working)?',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[-+]*\\s*years? ?(?:in the industry)?'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text.lower())\n",
    "        if match:\n",
    "            try:\n",
    "                return float(match.group(1))\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# Function to extract skills\n",
    "def extract_skills(text):\n",
    "    text = text.lower()\n",
    "    skills_found = set()\n",
    "    for skill in COMMON_SKILLS:\n",
    "        if re.search(r'\\b' + re.escape(skill) + r'\\b', text):\n",
    "            skills_found.add(skill)\n",
    "    return \", \".join(skills_found) if skills_found else \"None\"\n",
    "\n",
    "# Function to extract experience roles using spaCy's noun chunks\n",
    "def extract_experience_roles(text):\n",
    "    doc = nlp(text)\n",
    "    roles = set()\n",
    "    role_keywords = ['software engineer', 'data scientist', 'developer', 'manager', \n",
    "                     'analyst', 'consultant', 'intern', 'engineer', 'specialist', \n",
    "                     'director', 'lead', 'administrator', 'architect']\n",
    "    \n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_text = chunk.text.lower()\n",
    "        for keyword in role_keywords:\n",
    "            if keyword in chunk_text:\n",
    "                roles.add(chunk.text.strip())\n",
    "    \n",
    "    return \"; \".join(roles) if roles else \"None\"\n",
    "\n",
    "# Function to extract all required information from resume text\n",
    "def parse_resume(text):\n",
    "    experience_years = extract_experience_years(text)\n",
    "    skills = extract_skills(text)\n",
    "    experience_roles = extract_experience_roles(text)\n",
    "    return experience_years, experience_roles, skills\n",
    "\n",
    "# Initialize a list to hold all resume data\n",
    "resume_data = []\n",
    "\n",
    "# Traverse the directory and process each resume file\n",
    "print(\"Processing resumes...\")\n",
    "for root, dirs, files in os.walk(RESUME_DIR):\n",
    "    folder_name = os.path.basename(root)  # Get the folder name\n",
    "    for file in tqdm(files, desc=f\"Processing in {folder_name}\"):\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_extension = os.path.splitext(file)[1].lower()\n",
    "        resume_text = \"\"\n",
    "        \n",
    "        if file_extension == '.pdf':\n",
    "            resume_text = extract_text_from_pdf(file_path)\n",
    "        elif file_extension == '.docx':\n",
    "            resume_text = extract_text_from_docx(file_path)\n",
    "        elif file_extension == '.doc':\n",
    "            resume_text = extract_text_from_doc(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file_path}\")\n",
    "            continue  # Skip unsupported formats\n",
    "        \n",
    "        # If text extraction was successful, parse the resume\n",
    "        if resume_text:\n",
    "            experience_years, experience_roles, skills = parse_resume(resume_text)\n",
    "            resume_data.append({\n",
    "                'File Name': file,\n",
    "                'Folder Name': folder_name,  # Include the folder name\n",
    "                'Resume Text': resume_text,  # Include the full resume text\n",
    "                'Experience Years': experience_years,\n",
    "                'Experience Roles': experience_roles,\n",
    "                'Skills': skills\n",
    "            })\n",
    "        else:\n",
    "            print(f\"No text extracted from: {file_path}\")\n",
    "\n",
    "# Create a DataFrame from the extracted resume data\n",
    "resume_df = pd.DataFrame(resume_data)\n",
    "\n",
    "# Check if DataFrame is empty\n",
    "if resume_df.empty:\n",
    "    print(\"No resume data extracted.\")\n",
    "else:\n",
    "    print(\"Resume data extracted successfully.\")\n",
    "    print(resume_df.head())  # Display the first few rows\n",
    "\n",
    "# Save the resume DataFrame to an Excel file\n",
    "excel_path = os.path.join(RESUME_DIR, 'extracted_resumes(new_new_22).xlsx')\n",
    "resume_df.to_excel(excel_path, index=False)\n",
    "print(f\"Resume data saved to {excel_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
